{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train and Host a Keras Model with Pipe Mode and Horovod on Amazon SageMaker\n",
    "\n",
    "Amazon SageMaker is a fully-managed service that provides developers and data scientists with the ability to build, train, and deploy machine learning (ML) models quickly. Amazon SageMaker removes the heavy lifting from each step of the machine learning process to make it easier to develop high-quality models. The SageMaker Python SDK makes it easy to train and deploy models in Amazon SageMaker with several different machine learning and deep learning frameworks, including TensorFlow and Keras.\n",
    "\n",
    "In this notebook, we train and host a [Keras Sequential model](https://keras.io/getting-started/sequential-model-guide) on SageMaker. The model used for this notebook is a simple deep convolutional neural network (CNN) that was extracted from [the Keras examples](https://github.com/keras-team/keras/blob/master/examples/cifar10_cnn.py).\n",
    "\n",
    "For training our model, we also demonstrate distributed training with [Horovod](https://horovod.readthedocs.io) and Pipe Mode. Amazon SageMaker's Pipe Mode streams your dataset directly to your training instances instead of being downloaded first, which translates to training jobs that start sooner, finish quicker, and need less disk space."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "First, we define a few variables that are be needed later in the example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "from sagemaker import get_execution_role\n",
    "\n",
    "sagemaker_session = sagemaker.Session()\n",
    "\n",
    "role = get_execution_role()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The CIFAR-10 dataset\n",
    "\n",
    "The [CIFAR-10 dataset](https://www.cs.toronto.edu/~kriz/cifar.html) is one of the most popular machine learning datasets. It consists of 60,000 32x32 images belonging to 10 different classes (6,000 images per class). Here are the classes in the dataset, as well as 10 random images from each:\n",
    "\n",
    "![cifar10](https://maet3608.github.io/nuts-ml/_images/cifar10.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare the dataset for training\n",
    "\n",
    "To use the CIFAR-10 dataset, we first download it and convert it to TFRecords. This step takes around 5 minutes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/ec2-user/anaconda3/envs/tensorflow_p36/cpu/lib/python3.6/site-packages/tensorflow_core/__init__.py:1473: The name tf.estimator.inputs is deprecated. Please use tf.compat.v1.estimator.inputs instead.\n",
      "\n",
      "Download from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz and extract.\n",
      "WARNING:tensorflow:\n",
      "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "  * https://github.com/tensorflow/io (for I/O related ops)\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n",
      "WARNING:tensorflow:From generate_cifar10_tfrecords.py:32: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "WARNING:tensorflow:From /home/ec2-user/anaconda3/envs/tensorflow_p36/cpu/lib/python3.6/site-packages/tensorflow_core/contrib/learn/python/learn/datasets/base.py:252: _internal_retry.<locals>.wrap.<locals>.wrapped_fn (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use urllib or similar directly.\n",
      "Successfully downloaded cifar-10-python.tar.gz 170498071 bytes.\n",
      "Generating ./data/train/train.tfrecords\n",
      "Generating ./data/validation/validation.tfrecords\n",
      "Generating ./data/eval/eval.tfrecords\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "!python generate_cifar10_tfrecords.py --data-dir ./data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we upload the data to Amazon S3:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'s3://sagemaker-ap-southeast-2-987959606453/tf-cifar10-example/data'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sagemaker.s3 import S3Uploader\n",
    "\n",
    "bucket = sagemaker_session.default_bucket()\n",
    "dataset_uri = S3Uploader.upload('data', 's3://{}/tf-cifar10-example/data'.format(bucket))\n",
    "\n",
    "display(dataset_uri)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the model\n",
    "\n",
    "In this tutorial, we train a deep CNN to learn a classification task with the CIFAR-10 dataset. We compare three different training jobs: a baseline training job, training with Pipe Mode, and distributed training with Horovod.\n",
    "\n",
    "### Run a baseline training job on SageMaker\n",
    "\n",
    "The SageMaker Python SDK's `sagemaker.tensorflow.TensorFlow` estimator class makes it easy for us to interact with SageMaker. We create one for each of the different training jobs we run in this example. A couple parameters worth noting:\n",
    "\n",
    "* `entry_point`: our training script (adapted from [this Keras example](https://github.com/keras-team/keras/blob/master/examples/cifar10_cnn.py)).\n",
    "* `train_instance_count`: the number of training instances. Here, we set it to 1 for our baseline training job.\n",
    "\n",
    "As we run each of our training jobs, we change different parameters to configure our different training jobs.\n",
    "\n",
    "For more details about the TensorFlow estimator class, see the [API documentation](https://sagemaker.readthedocs.io/en/stable/sagemaker.tensorflow.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Verify the training code\n",
    "\n",
    "Before running the baseline training job, we first use [the SageMaker Python SDK's Local Mode feature](https://sagemaker.readthedocs.io/en/stable/overview.html#local-mode) to check that our code works with SageMaker's TensorFlow environment. Local Mode downloads the [prebuilt Docker image for TensorFlow](https://docs.aws.amazon.com/deep-learning-containers/latest/devguide/deep-learning-containers-images.html) and runs a Docker container locally for a training job. In other words, it simulates the SageMaker environment for a quicker development cycle, so we use it here just to test out our code.\n",
    "\n",
    "We create a TensorFlow estimator, and specify the `instance_type` to be `'local'` or `'local_gpu'`, depending on our local instance type. This tells the estimator to run our training job locally (as opposed to on SageMaker). We also have our training code run for only one epoch because our intent here is to verify the code, not train an accurate model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train_instance_type has been renamed in sagemaker>=2.\n",
      "See: https://sagemaker.readthedocs.io/en/stable/v2.html for details.\n",
      "train_instance_count has been renamed in sagemaker>=2.\n",
      "See: https://sagemaker.readthedocs.io/en/stable/v2.html for details.\n",
      "train_instance_type has been renamed in sagemaker>=2.\n",
      "See: https://sagemaker.readthedocs.io/en/stable/v2.html for details.\n"
     ]
    }
   ],
   "source": [
    "import subprocess\n",
    "\n",
    "from sagemaker.tensorflow import TensorFlow\n",
    "\n",
    "instance_type = 'local'\n",
    "\n",
    "if subprocess.call('nvidia-smi') == 0:\n",
    "    # Set instance type to GPU if one is present\n",
    "    instance_type = 'local_gpu'\n",
    "    \n",
    "local_hyperparameters = {'epochs': 1, 'batch-size' : 64}\n",
    "\n",
    "estimator = TensorFlow(entry_point='cifar10_keras_main.py',\n",
    "                       source_dir='source_dir',\n",
    "                       role=role,\n",
    "                       framework_version='1.15.2',\n",
    "                       py_version='py3',\n",
    "                       hyperparameters=local_hyperparameters,\n",
    "                       train_instance_count=1,\n",
    "                       train_instance_type=instance_type)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we have our estimator, we call `fit()` to start the training job and pass the inputs that we downloaded earlier. We pass the inputs as a dictionary to define different data channels for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating 7828rhrjz9-algo-1-9g2mh ... \n",
      "Creating 7828rhrjz9-algo-1-9g2mh ... done\n",
      "Attaching to 7828rhrjz9-algo-1-9g2mh\n",
      "\u001b[36m7828rhrjz9-algo-1-9g2mh |\u001b[0m WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/__init__.py:1473: The name tf.estimator.inputs is deprecated. Please use tf.compat.v1.estimator.inputs instead.\n",
      "\u001b[36m7828rhrjz9-algo-1-9g2mh |\u001b[0m \n",
      "\u001b[36m7828rhrjz9-algo-1-9g2mh |\u001b[0m 2021-05-14 10:19:51,755 sagemaker-containers INFO     Imported framework sagemaker_tensorflow_container.training\n",
      "\u001b[36m7828rhrjz9-algo-1-9g2mh |\u001b[0m 2021-05-14 10:19:51,771 sagemaker-containers INFO     No GPUs detected (normal if no gpus installed)\n",
      "\u001b[36m7828rhrjz9-algo-1-9g2mh |\u001b[0m 2021-05-14 10:19:52,276 sagemaker-containers INFO     No GPUs detected (normal if no gpus installed)\n",
      "\u001b[36m7828rhrjz9-algo-1-9g2mh |\u001b[0m 2021-05-14 10:19:52,333 sagemaker-containers INFO     No GPUs detected (normal if no gpus installed)\n",
      "\u001b[36m7828rhrjz9-algo-1-9g2mh |\u001b[0m 2021-05-14 10:19:52,408 sagemaker-containers INFO     No GPUs detected (normal if no gpus installed)\n",
      "\u001b[36m7828rhrjz9-algo-1-9g2mh |\u001b[0m 2021-05-14 10:19:52,453 sagemaker-containers INFO     Invoking user script\n",
      "\u001b[36m7828rhrjz9-algo-1-9g2mh |\u001b[0m \n",
      "\u001b[36m7828rhrjz9-algo-1-9g2mh |\u001b[0m Training Env:\n",
      "\u001b[36m7828rhrjz9-algo-1-9g2mh |\u001b[0m \n",
      "\u001b[36m7828rhrjz9-algo-1-9g2mh |\u001b[0m {\n",
      "\u001b[36m7828rhrjz9-algo-1-9g2mh |\u001b[0m     \"additional_framework_parameters\": {},\n",
      "\u001b[36m7828rhrjz9-algo-1-9g2mh |\u001b[0m     \"channel_input_dirs\": {\n",
      "\u001b[36m7828rhrjz9-algo-1-9g2mh |\u001b[0m         \"train\": \"/opt/ml/input/data/train\",\n",
      "\u001b[36m7828rhrjz9-algo-1-9g2mh |\u001b[0m         \"validation\": \"/opt/ml/input/data/validation\",\n",
      "\u001b[36m7828rhrjz9-algo-1-9g2mh |\u001b[0m         \"eval\": \"/opt/ml/input/data/eval\"\n",
      "\u001b[36m7828rhrjz9-algo-1-9g2mh |\u001b[0m     },\n",
      "\u001b[36m7828rhrjz9-algo-1-9g2mh |\u001b[0m     \"current_host\": \"algo-1-9g2mh\",\n",
      "\u001b[36m7828rhrjz9-algo-1-9g2mh |\u001b[0m     \"framework_module\": \"sagemaker_tensorflow_container.training:main\",\n",
      "\u001b[36m7828rhrjz9-algo-1-9g2mh |\u001b[0m     \"hosts\": [\n",
      "\u001b[36m7828rhrjz9-algo-1-9g2mh |\u001b[0m         \"algo-1-9g2mh\"\n",
      "\u001b[36m7828rhrjz9-algo-1-9g2mh |\u001b[0m     ],\n",
      "\u001b[36m7828rhrjz9-algo-1-9g2mh |\u001b[0m     \"hyperparameters\": {\n",
      "\u001b[36m7828rhrjz9-algo-1-9g2mh |\u001b[0m         \"epochs\": 1,\n",
      "\u001b[36m7828rhrjz9-algo-1-9g2mh |\u001b[0m         \"batch-size\": 64,\n",
      "\u001b[36m7828rhrjz9-algo-1-9g2mh |\u001b[0m         \"model_dir\": \"s3://sagemaker-ap-southeast-2-987959606453/tensorflow-training-2021-05-14-10-19-37-516/model\"\n",
      "\u001b[36m7828rhrjz9-algo-1-9g2mh |\u001b[0m     },\n",
      "\u001b[36m7828rhrjz9-algo-1-9g2mh |\u001b[0m     \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "\u001b[36m7828rhrjz9-algo-1-9g2mh |\u001b[0m     \"input_data_config\": {\n",
      "\u001b[36m7828rhrjz9-algo-1-9g2mh |\u001b[0m         \"train\": {\n",
      "\u001b[36m7828rhrjz9-algo-1-9g2mh |\u001b[0m             \"TrainingInputMode\": \"File\"\n",
      "\u001b[36m7828rhrjz9-algo-1-9g2mh |\u001b[0m         },\n",
      "\u001b[36m7828rhrjz9-algo-1-9g2mh |\u001b[0m         \"validation\": {\n",
      "\u001b[36m7828rhrjz9-algo-1-9g2mh |\u001b[0m             \"TrainingInputMode\": \"File\"\n",
      "\u001b[36m7828rhrjz9-algo-1-9g2mh |\u001b[0m         },\n",
      "\u001b[36m7828rhrjz9-algo-1-9g2mh |\u001b[0m         \"eval\": {\n",
      "\u001b[36m7828rhrjz9-algo-1-9g2mh |\u001b[0m             \"TrainingInputMode\": \"File\"\n",
      "\u001b[36m7828rhrjz9-algo-1-9g2mh |\u001b[0m         }\n",
      "\u001b[36m7828rhrjz9-algo-1-9g2mh |\u001b[0m     },\n",
      "\u001b[36m7828rhrjz9-algo-1-9g2mh |\u001b[0m     \"input_dir\": \"/opt/ml/input\",\n",
      "\u001b[36m7828rhrjz9-algo-1-9g2mh |\u001b[0m     \"is_master\": true,\n",
      "\u001b[36m7828rhrjz9-algo-1-9g2mh |\u001b[0m     \"job_name\": \"tensorflow-training-2021-05-14-10-19-37-516\",\n",
      "\u001b[36m7828rhrjz9-algo-1-9g2mh |\u001b[0m     \"log_level\": 20,\n",
      "\u001b[36m7828rhrjz9-algo-1-9g2mh |\u001b[0m     \"master_hostname\": \"algo-1-9g2mh\",\n",
      "\u001b[36m7828rhrjz9-algo-1-9g2mh |\u001b[0m     \"model_dir\": \"/opt/ml/model\",\n",
      "\u001b[36m7828rhrjz9-algo-1-9g2mh |\u001b[0m     \"module_dir\": \"s3://sagemaker-ap-southeast-2-987959606453/tensorflow-training-2021-05-14-10-19-37-516/source/sourcedir.tar.gz\",\n",
      "\u001b[36m7828rhrjz9-algo-1-9g2mh |\u001b[0m     \"module_name\": \"cifar10_keras_main\",\n",
      "\u001b[36m7828rhrjz9-algo-1-9g2mh |\u001b[0m     \"network_interface_name\": \"eth0\",\n",
      "\u001b[36m7828rhrjz9-algo-1-9g2mh |\u001b[0m     \"num_cpus\": 2,\n",
      "\u001b[36m7828rhrjz9-algo-1-9g2mh |\u001b[0m     \"num_gpus\": 0,\n",
      "\u001b[36m7828rhrjz9-algo-1-9g2mh |\u001b[0m     \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "\u001b[36m7828rhrjz9-algo-1-9g2mh |\u001b[0m     \"output_dir\": \"/opt/ml/output\",\n",
      "\u001b[36m7828rhrjz9-algo-1-9g2mh |\u001b[0m     \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "\u001b[36m7828rhrjz9-algo-1-9g2mh |\u001b[0m     \"resource_config\": {\n",
      "\u001b[36m7828rhrjz9-algo-1-9g2mh |\u001b[0m         \"current_host\": \"algo-1-9g2mh\",\n",
      "\u001b[36m7828rhrjz9-algo-1-9g2mh |\u001b[0m         \"hosts\": [\n",
      "\u001b[36m7828rhrjz9-algo-1-9g2mh |\u001b[0m             \"algo-1-9g2mh\"\n",
      "\u001b[36m7828rhrjz9-algo-1-9g2mh |\u001b[0m         ]\n",
      "\u001b[36m7828rhrjz9-algo-1-9g2mh |\u001b[0m     },\n",
      "\u001b[36m7828rhrjz9-algo-1-9g2mh |\u001b[0m     \"user_entry_point\": \"cifar10_keras_main.py\"\n",
      "\u001b[36m7828rhrjz9-algo-1-9g2mh |\u001b[0m }\n",
      "\u001b[36m7828rhrjz9-algo-1-9g2mh |\u001b[0m \n",
      "\u001b[36m7828rhrjz9-algo-1-9g2mh |\u001b[0m Environment variables:\n",
      "\u001b[36m7828rhrjz9-algo-1-9g2mh |\u001b[0m \n",
      "\u001b[36m7828rhrjz9-algo-1-9g2mh |\u001b[0m SM_HOSTS=[\"algo-1-9g2mh\"]\n",
      "\u001b[36m7828rhrjz9-algo-1-9g2mh |\u001b[0m SM_NETWORK_INTERFACE_NAME=eth0\n",
      "\u001b[36m7828rhrjz9-algo-1-9g2mh |\u001b[0m SM_HPS={\"batch-size\":64,\"epochs\":1,\"model_dir\":\"s3://sagemaker-ap-southeast-2-987959606453/tensorflow-training-2021-05-14-10-19-37-516/model\"}\n",
      "\u001b[36m7828rhrjz9-algo-1-9g2mh |\u001b[0m SM_USER_ENTRY_POINT=cifar10_keras_main.py\n",
      "\u001b[36m7828rhrjz9-algo-1-9g2mh |\u001b[0m SM_FRAMEWORK_PARAMS={}\n",
      "\u001b[36m7828rhrjz9-algo-1-9g2mh |\u001b[0m SM_RESOURCE_CONFIG={\"current_host\":\"algo-1-9g2mh\",\"hosts\":[\"algo-1-9g2mh\"]}\n",
      "\u001b[36m7828rhrjz9-algo-1-9g2mh |\u001b[0m SM_INPUT_DATA_CONFIG={\"eval\":{\"TrainingInputMode\":\"File\"},\"train\":{\"TrainingInputMode\":\"File\"},\"validation\":{\"TrainingInputMode\":\"File\"}}\n",
      "\u001b[36m7828rhrjz9-algo-1-9g2mh |\u001b[0m SM_OUTPUT_DATA_DIR=/opt/ml/output/data\n",
      "\u001b[36m7828rhrjz9-algo-1-9g2mh |\u001b[0m SM_CHANNELS=[\"eval\",\"train\",\"validation\"]\n",
      "\u001b[36m7828rhrjz9-algo-1-9g2mh |\u001b[0m SM_CURRENT_HOST=algo-1-9g2mh\n",
      "\u001b[36m7828rhrjz9-algo-1-9g2mh |\u001b[0m SM_MODULE_NAME=cifar10_keras_main\n",
      "\u001b[36m7828rhrjz9-algo-1-9g2mh |\u001b[0m SM_LOG_LEVEL=20\n",
      "\u001b[36m7828rhrjz9-algo-1-9g2mh |\u001b[0m SM_FRAMEWORK_MODULE=sagemaker_tensorflow_container.training:main\n",
      "\u001b[36m7828rhrjz9-algo-1-9g2mh |\u001b[0m SM_INPUT_DIR=/opt/ml/input\n",
      "\u001b[36m7828rhrjz9-algo-1-9g2mh |\u001b[0m SM_INPUT_CONFIG_DIR=/opt/ml/input/config\n",
      "\u001b[36m7828rhrjz9-algo-1-9g2mh |\u001b[0m SM_OUTPUT_DIR=/opt/ml/output\n",
      "\u001b[36m7828rhrjz9-algo-1-9g2mh |\u001b[0m SM_NUM_CPUS=2\n",
      "\u001b[36m7828rhrjz9-algo-1-9g2mh |\u001b[0m SM_NUM_GPUS=0\n",
      "\u001b[36m7828rhrjz9-algo-1-9g2mh |\u001b[0m SM_MODEL_DIR=/opt/ml/model\n",
      "\u001b[36m7828rhrjz9-algo-1-9g2mh |\u001b[0m SM_MODULE_DIR=s3://sagemaker-ap-southeast-2-987959606453/tensorflow-training-2021-05-14-10-19-37-516/source/sourcedir.tar.gz\n",
      "\u001b[36m7828rhrjz9-algo-1-9g2mh |\u001b[0m SM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"eval\":\"/opt/ml/input/data/eval\",\"train\":\"/opt/ml/input/data/train\",\"validation\":\"/opt/ml/input/data/validation\"},\"current_host\":\"algo-1-9g2mh\",\"framework_module\":\"sagemaker_tensorflow_container.training:main\",\"hosts\":[\"algo-1-9g2mh\"],\"hyperparameters\":{\"batch-size\":64,\"epochs\":1,\"model_dir\":\"s3://sagemaker-ap-southeast-2-987959606453/tensorflow-training-2021-05-14-10-19-37-516/model\"},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"eval\":{\"TrainingInputMode\":\"File\"},\"train\":{\"TrainingInputMode\":\"File\"},\"validation\":{\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"is_master\":true,\"job_name\":\"tensorflow-training-2021-05-14-10-19-37-516\",\"log_level\":20,\"master_hostname\":\"algo-1-9g2mh\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-ap-southeast-2-987959606453/tensorflow-training-2021-05-14-10-19-37-516/source/sourcedir.tar.gz\",\"module_name\":\"cifar10_keras_main\",\"network_interface_name\":\"eth0\",\"num_cpus\":2,\"num_gpus\":0,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_host\":\"algo-1-9g2mh\",\"hosts\":[\"algo-1-9g2mh\"]},\"user_entry_point\":\"cifar10_keras_main.py\"}\n",
      "\u001b[36m7828rhrjz9-algo-1-9g2mh |\u001b[0m SM_USER_ARGS=[\"--batch-size\",\"64\",\"--epochs\",\"1\",\"--model_dir\",\"s3://sagemaker-ap-southeast-2-987959606453/tensorflow-training-2021-05-14-10-19-37-516/model\"]\n",
      "\u001b[36m7828rhrjz9-algo-1-9g2mh |\u001b[0m SM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\n",
      "\u001b[36m7828rhrjz9-algo-1-9g2mh |\u001b[0m SM_CHANNEL_TRAIN=/opt/ml/input/data/train\n",
      "\u001b[36m7828rhrjz9-algo-1-9g2mh |\u001b[0m SM_CHANNEL_VALIDATION=/opt/ml/input/data/validation\n",
      "\u001b[36m7828rhrjz9-algo-1-9g2mh |\u001b[0m SM_CHANNEL_EVAL=/opt/ml/input/data/eval\n",
      "\u001b[36m7828rhrjz9-algo-1-9g2mh |\u001b[0m SM_HP_EPOCHS=1\n",
      "\u001b[36m7828rhrjz9-algo-1-9g2mh |\u001b[0m SM_HP_BATCH-SIZE=64\n",
      "\u001b[36m7828rhrjz9-algo-1-9g2mh |\u001b[0m SM_HP_MODEL_DIR=s3://sagemaker-ap-southeast-2-987959606453/tensorflow-training-2021-05-14-10-19-37-516/model\n",
      "\u001b[36m7828rhrjz9-algo-1-9g2mh |\u001b[0m PYTHONPATH=/opt/ml/code:/usr/local/bin:/usr/lib/python36.zip:/usr/lib/python3.6:/usr/lib/python3.6/lib-dynload:/usr/local/lib/python3.6/dist-packages:/usr/lib/python3/dist-packages\n",
      "\u001b[36m7828rhrjz9-algo-1-9g2mh |\u001b[0m \n",
      "\u001b[36m7828rhrjz9-algo-1-9g2mh |\u001b[0m Invoking script with the following command:\n",
      "\u001b[36m7828rhrjz9-algo-1-9g2mh |\u001b[0m \n",
      "\u001b[36m7828rhrjz9-algo-1-9g2mh |\u001b[0m /usr/bin/python3 cifar10_keras_main.py --batch-size 64 --epochs 1 --model_dir s3://sagemaker-ap-southeast-2-987959606453/tensorflow-training-2021-05-14-10-19-37-516/model\n",
      "\u001b[36m7828rhrjz9-algo-1-9g2mh |\u001b[0m \n",
      "\u001b[36m7828rhrjz9-algo-1-9g2mh |\u001b[0m \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m7828rhrjz9-algo-1-9g2mh |\u001b[0m Using TensorFlow backend.\n",
      "\u001b[36m7828rhrjz9-algo-1-9g2mh |\u001b[0m WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/__init__.py:1473: The name tf.estimator.inputs is deprecated. Please use tf.compat.v1.estimator.inputs instead.\n",
      "\u001b[36m7828rhrjz9-algo-1-9g2mh |\u001b[0m \n",
      "\u001b[36m7828rhrjz9-algo-1-9g2mh |\u001b[0m WARNING:tensorflow:From cifar10_keras_main.py:30: The name tf.logging.set_verbosity is deprecated. Please use tf.compat.v1.logging.set_verbosity instead.\n",
      "\u001b[36m7828rhrjz9-algo-1-9g2mh |\u001b[0m \n",
      "\u001b[36m7828rhrjz9-algo-1-9g2mh |\u001b[0m WARNING:tensorflow:From cifar10_keras_main.py:30: The name tf.logging.INFO is deprecated. Please use tf.compat.v1.logging.INFO instead.\n",
      "\u001b[36m7828rhrjz9-algo-1-9g2mh |\u001b[0m \n",
      "\u001b[36m7828rhrjz9-algo-1-9g2mh |\u001b[0m INFO:root:Writing TensorBoard logs to s3://sagemaker-ap-southeast-2-987959606453/tensorflow-training-2021-05-14-10-19-37-516/model\n",
      "\u001b[36m7828rhrjz9-algo-1-9g2mh |\u001b[0m INFO:root:Running with MPI=False\n",
      "\u001b[36m7828rhrjz9-algo-1-9g2mh |\u001b[0m INFO:root:getting data\n",
      "\u001b[36m7828rhrjz9-algo-1-9g2mh |\u001b[0m INFO:root:Running train in File mode\n",
      "\u001b[36m7828rhrjz9-algo-1-9g2mh |\u001b[0m WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.FixedLenFeature is deprecated. Please use tf.io.FixedLenFeature instead.\n",
      "\u001b[36m7828rhrjz9-algo-1-9g2mh |\u001b[0m \n",
      "\u001b[36m7828rhrjz9-algo-1-9g2mh |\u001b[0m WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.FixedLenFeature is deprecated. Please use tf.io.FixedLenFeature instead.\n",
      "\u001b[36m7828rhrjz9-algo-1-9g2mh |\u001b[0m \n",
      "\u001b[36m7828rhrjz9-algo-1-9g2mh |\u001b[0m WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.parse_single_example is deprecated. Please use tf.io.parse_single_example instead.\n",
      "\u001b[36m7828rhrjz9-algo-1-9g2mh |\u001b[0m \n",
      "\u001b[36m7828rhrjz9-algo-1-9g2mh |\u001b[0m WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.parse_single_example is deprecated. Please use tf.io.parse_single_example instead.\n",
      "\u001b[36m7828rhrjz9-algo-1-9g2mh |\u001b[0m \n",
      "\u001b[36m7828rhrjz9-algo-1-9g2mh |\u001b[0m WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.image.resize_image_with_crop_or_pad is deprecated. Please use tf.image.resize_with_crop_or_pad instead.\n",
      "\u001b[36m7828rhrjz9-algo-1-9g2mh |\u001b[0m \n",
      "\u001b[36m7828rhrjz9-algo-1-9g2mh |\u001b[0m WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.image.resize_image_with_crop_or_pad is deprecated. Please use tf.image.resize_with_crop_or_pad instead.\n",
      "\u001b[36m7828rhrjz9-algo-1-9g2mh |\u001b[0m \n",
      "\u001b[36m7828rhrjz9-algo-1-9g2mh |\u001b[0m WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.random_crop is deprecated. Please use tf.image.random_crop instead.\n",
      "\u001b[36m7828rhrjz9-algo-1-9g2mh |\u001b[0m \n",
      "\u001b[36m7828rhrjz9-algo-1-9g2mh |\u001b[0m WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.random_crop is deprecated. Please use tf.image.random_crop instead.\n",
      "\u001b[36m7828rhrjz9-algo-1-9g2mh |\u001b[0m \n",
      "\u001b[36m7828rhrjz9-algo-1-9g2mh |\u001b[0m INFO:root:Running eval in File mode\n",
      "\u001b[36m7828rhrjz9-algo-1-9g2mh |\u001b[0m INFO:root:Running validation in File mode\n",
      "\u001b[36m7828rhrjz9-algo-1-9g2mh |\u001b[0m INFO:root:configuring model\n",
      "\u001b[36m7828rhrjz9-algo-1-9g2mh |\u001b[0m WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "\u001b[36m7828rhrjz9-algo-1-9g2mh |\u001b[0m Instructions for updating:\n",
      "\u001b[36m7828rhrjz9-algo-1-9g2mh |\u001b[0m If using Keras pass *_constraint arguments to layers.\n",
      "\u001b[36m7828rhrjz9-algo-1-9g2mh |\u001b[0m WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "\u001b[36m7828rhrjz9-algo-1-9g2mh |\u001b[0m Instructions for updating:\n",
      "\u001b[36m7828rhrjz9-algo-1-9g2mh |\u001b[0m If using Keras pass *_constraint arguments to layers.\n",
      "\u001b[36m7828rhrjz9-algo-1-9g2mh |\u001b[0m WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4070: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\u001b[36m7828rhrjz9-algo-1-9g2mh |\u001b[0m \n",
      "\u001b[36m7828rhrjz9-algo-1-9g2mh |\u001b[0m WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4070: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\u001b[36m7828rhrjz9-algo-1-9g2mh |\u001b[0m \n",
      "\u001b[36m7828rhrjz9-algo-1-9g2mh |\u001b[0m INFO:root:Starting training\n",
      "\u001b[36m7828rhrjz9-algo-1-9g2mh |\u001b[0m WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\u001b[36m7828rhrjz9-algo-1-9g2mh |\u001b[0m \n",
      "\u001b[36m7828rhrjz9-algo-1-9g2mh |\u001b[0m WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\u001b[36m7828rhrjz9-algo-1-9g2mh |\u001b[0m \n",
      "\u001b[36m7828rhrjz9-algo-1-9g2mh |\u001b[0m Train on 64 samples, validate on 64 samples\n",
      "\u001b[36m7828rhrjz9-algo-1-9g2mh |\u001b[0m WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/callbacks/tensorboard_v1.py:200: The name tf.summary.merge_all is deprecated. Please use tf.compat.v1.summary.merge_all instead.\n",
      "\u001b[36m7828rhrjz9-algo-1-9g2mh |\u001b[0m \n",
      "\u001b[36m7828rhrjz9-algo-1-9g2mh |\u001b[0m WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/callbacks/tensorboard_v1.py:200: The name tf.summary.merge_all is deprecated. Please use tf.compat.v1.summary.merge_all instead.\n",
      "\u001b[36m7828rhrjz9-algo-1-9g2mh |\u001b[0m \n",
      "\u001b[36m7828rhrjz9-algo-1-9g2mh |\u001b[0m WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/callbacks/tensorboard_v1.py:203: The name tf.summary.FileWriter is deprecated. Please use tf.compat.v1.summary.FileWriter instead.\n",
      "\u001b[36m7828rhrjz9-algo-1-9g2mh |\u001b[0m \n",
      "\u001b[36m7828rhrjz9-algo-1-9g2mh |\u001b[0m WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/callbacks/tensorboard_v1.py:203: The name tf.summary.FileWriter is deprecated. Please use tf.compat.v1.summary.FileWriter instead.\n",
      "\u001b[36m7828rhrjz9-algo-1-9g2mh |\u001b[0m \n",
      "\u001b[36m7828rhrjz9-algo-1-9g2mh |\u001b[0m Epoch 1/1\n",
      "625/625 [==============================] - 485s 775ms/step - loss: 0.0150 - accuracy: 0.9959 - val_loss: 0.0138 - val_accuracy: 93.4043\n",
      "\u001b[36m7828rhrjz9-algo-1-9g2mh |\u001b[0m WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/callbacks/tensorboard_v1.py:343: The name tf.Summary is deprecated. Please use tf.compat.v1.Summary instead.\n",
      "\u001b[36m7828rhrjz9-algo-1-9g2mh |\u001b[0m \n",
      "\u001b[36m7828rhrjz9-algo-1-9g2mh |\u001b[0m WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/callbacks/tensorboard_v1.py:343: The name tf.Summary is deprecated. Please use tf.compat.v1.Summary instead.\n",
      "\u001b[36m7828rhrjz9-algo-1-9g2mh |\u001b[0m \n",
      "\u001b[36m7828rhrjz9-algo-1-9g2mh |\u001b[0m INFO:root:Test loss:0.10140141462668395\n",
      "\u001b[36m7828rhrjz9-algo-1-9g2mh |\u001b[0m INFO:root:Test accuracy:0.0\n",
      "\u001b[36m7828rhrjz9-algo-1-9g2mh |\u001b[0m WARNING:tensorflow:From cifar10_keras_main.py:189: The name tf.saved_model.signature_def_utils.predict_signature_def is deprecated. Please use tf.compat.v1.saved_model.signature_def_utils.predict_signature_def instead.\n",
      "\u001b[36m7828rhrjz9-algo-1-9g2mh |\u001b[0m \n",
      "\u001b[36m7828rhrjz9-algo-1-9g2mh |\u001b[0m WARNING:tensorflow:From cifar10_keras_main.py:189: The name tf.saved_model.signature_def_utils.predict_signature_def is deprecated. Please use tf.compat.v1.saved_model.signature_def_utils.predict_signature_def instead.\n",
      "\u001b[36m7828rhrjz9-algo-1-9g2mh |\u001b[0m \n",
      "\u001b[36m7828rhrjz9-algo-1-9g2mh |\u001b[0m WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/saved_model/signature_def_utils_impl.py:201: build_tensor_info (from tensorflow.python.saved_model.utils_impl) is deprecated and will be removed in a future version.\n",
      "\u001b[36m7828rhrjz9-algo-1-9g2mh |\u001b[0m Instructions for updating:\n",
      "\u001b[36m7828rhrjz9-algo-1-9g2mh |\u001b[0m This function will only be available through the v1 compatibility library as tf.compat.v1.saved_model.utils.build_tensor_info or tf.compat.v1.saved_model.build_tensor_info.\n",
      "\u001b[36m7828rhrjz9-algo-1-9g2mh |\u001b[0m WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/saved_model/signature_def_utils_impl.py:201: build_tensor_info (from tensorflow.python.saved_model.utils_impl) is deprecated and will be removed in a future version.\n",
      "\u001b[36m7828rhrjz9-algo-1-9g2mh |\u001b[0m Instructions for updating:\n",
      "\u001b[36m7828rhrjz9-algo-1-9g2mh |\u001b[0m This function will only be available through the v1 compatibility library as tf.compat.v1.saved_model.utils.build_tensor_info or tf.compat.v1.saved_model.build_tensor_info.\n",
      "\u001b[36m7828rhrjz9-algo-1-9g2mh |\u001b[0m WARNING:tensorflow:From cifar10_keras_main.py:193: The name tf.saved_model.builder.SavedModelBuilder is deprecated. Please use tf.compat.v1.saved_model.builder.SavedModelBuilder instead.\n",
      "\u001b[36m7828rhrjz9-algo-1-9g2mh |\u001b[0m \n",
      "\u001b[36m7828rhrjz9-algo-1-9g2mh |\u001b[0m WARNING:tensorflow:From cifar10_keras_main.py:193: The name tf.saved_model.builder.SavedModelBuilder is deprecated. Please use tf.compat.v1.saved_model.builder.SavedModelBuilder instead.\n",
      "\u001b[36m7828rhrjz9-algo-1-9g2mh |\u001b[0m \n",
      "\u001b[36m7828rhrjz9-algo-1-9g2mh |\u001b[0m WARNING:tensorflow:From cifar10_keras_main.py:196: The name tf.saved_model.tag_constants.SERVING is deprecated. Please use tf.saved_model.SERVING instead.\n",
      "\u001b[36m7828rhrjz9-algo-1-9g2mh |\u001b[0m \n",
      "\u001b[36m7828rhrjz9-algo-1-9g2mh |\u001b[0m WARNING:tensorflow:From cifar10_keras_main.py:196: The name tf.saved_model.tag_constants.SERVING is deprecated. Please use tf.saved_model.SERVING instead.\n",
      "\u001b[36m7828rhrjz9-algo-1-9g2mh |\u001b[0m \n",
      "\u001b[36m7828rhrjz9-algo-1-9g2mh |\u001b[0m WARNING:tensorflow:From cifar10_keras_main.py:198: The name tf.saved_model.signature_constants.DEFAULT_SERVING_SIGNATURE_DEF_KEY is deprecated. Please use tf.saved_model.DEFAULT_SERVING_SIGNATURE_DEF_KEY instead.\n",
      "\u001b[36m7828rhrjz9-algo-1-9g2mh |\u001b[0m \n",
      "\u001b[36m7828rhrjz9-algo-1-9g2mh |\u001b[0m WARNING:tensorflow:From cifar10_keras_main.py:198: The name tf.saved_model.signature_constants.DEFAULT_SERVING_SIGNATURE_DEF_KEY is deprecated. Please use tf.saved_model.DEFAULT_SERVING_SIGNATURE_DEF_KEY instead.\n",
      "\u001b[36m7828rhrjz9-algo-1-9g2mh |\u001b[0m \n",
      "\u001b[36m7828rhrjz9-algo-1-9g2mh |\u001b[0m INFO:tensorflow:No assets to save.\n",
      "\u001b[36m7828rhrjz9-algo-1-9g2mh |\u001b[0m INFO:tensorflow:No assets to save.\n",
      "\u001b[36m7828rhrjz9-algo-1-9g2mh |\u001b[0m INFO:tensorflow:No assets to write.\n",
      "\u001b[36m7828rhrjz9-algo-1-9g2mh |\u001b[0m INFO:tensorflow:No assets to write.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m7828rhrjz9-algo-1-9g2mh |\u001b[0m INFO:tensorflow:SavedModel written to: /opt/ml/model/1/saved_model.pb\n",
      "\u001b[36m7828rhrjz9-algo-1-9g2mh |\u001b[0m INFO:tensorflow:SavedModel written to: /opt/ml/model/1/saved_model.pb\n",
      "\u001b[36m7828rhrjz9-algo-1-9g2mh |\u001b[0m INFO:root:Model successfully saved at: /opt/ml/model\n",
      "\u001b[36m7828rhrjz9-algo-1-9g2mh |\u001b[0m 2021-05-14 10:29:48,019 sagemaker-containers INFO     Reporting training SUCCESS\n",
      "\u001b[36m7828rhrjz9-algo-1-9g2mh exited with code 0\n",
      "\u001b[0mAborting on container exit...\n",
      "===== Job Complete =====\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "data_path = os.path.join(os.getcwd(), 'data')\n",
    "\n",
    "local_inputs = {\n",
    "    'train': 'file://{}/train'.format(data_path),\n",
    "    'validation': 'file://{}/validation'.format(data_path),\n",
    "    'eval': 'file://{}/eval'.format(data_path),\n",
    "}\n",
    "estimator.fit(local_inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run a baseline training job on SageMaker\n",
    "\n",
    "Now we run training jobs on SageMaker, starting with our baseline training job."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configure metrics\n",
    "\n",
    "In addition to running the training job, Amazon SageMaker can retrieve training metrics directly from the logs and send them to CloudWatch metrics. Here, we define metrics we would like to observe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_definitions = [\n",
    "    {'Name': 'train:loss', 'Regex': '.*loss: ([0-9\\\\.]+) - accuracy: [0-9\\\\.]+.*'},\n",
    "    {'Name': 'train:accuracy', 'Regex': '.*loss: [0-9\\\\.]+ - accuracy: ([0-9\\\\.]+).*'},\n",
    "    {'Name': 'validation:accuracy', 'Regex': '.*step - loss: [0-9\\\\.]+ - accuracy: [0-9\\\\.]+ - val_loss: [0-9\\\\.]+ - val_accuracy: ([0-9\\\\.]+).*'},\n",
    "    {'Name': 'validation:loss', 'Regex': '.*step - loss: [0-9\\\\.]+ - accuracy: [0-9\\\\.]+ - val_loss: ([0-9\\\\.]+) - val_accuracy: [0-9\\\\.]+.*'},\n",
    "    {'Name': 'sec/steps', 'Regex': '.* - \\d+s (\\d+)[mu]s/step - loss: [0-9\\\\.]+ - accuracy: [0-9\\\\.]+ - val_loss: [0-9\\\\.]+ - val_accuracy: [0-9\\\\.]+'}\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once again, we create a TensorFlow estimator, with a couple key modfications from last time:\n",
    "\n",
    "* `train_instance_type`: the instance type for training. We set this to `ml.p2.xlarge` because we are training on SageMaker now. For a list of available instance types, see [the AWS documentation](https://aws.amazon.com/sagemaker/pricing/instance-types).\n",
    "* `metric_definitions`: the metrics (defined above) that we want sent to CloudWatch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train_instance_type has been renamed in sagemaker>=2.\n",
      "See: https://sagemaker.readthedocs.io/en/stable/v2.html for details.\n",
      "train_instance_count has been renamed in sagemaker>=2.\n",
      "See: https://sagemaker.readthedocs.io/en/stable/v2.html for details.\n",
      "train_instance_type has been renamed in sagemaker>=2.\n",
      "See: https://sagemaker.readthedocs.io/en/stable/v2.html for details.\n"
     ]
    }
   ],
   "source": [
    "from sagemaker.tensorflow import TensorFlow\n",
    "\n",
    "hyperparameters = {'epochs': 10, 'batch-size': 256}\n",
    "tags = [{'Key': 'Project', 'Value': 'cifar10'}, {'Key': 'TensorBoard', 'Value': 'file'}]\n",
    "\n",
    "estimator = TensorFlow(entry_point='cifar10_keras_main.py',\n",
    "                       source_dir='source_dir',\n",
    "                       metric_definitions=metric_definitions,\n",
    "                       hyperparameters=hyperparameters,\n",
    "                       role=role,\n",
    "                       framework_version='1.15.2',\n",
    "                       py_version='py3',\n",
    "                       train_instance_count=1,\n",
    "                       train_instance_type='ml.m4.xlarge', # changed from ml.p2.xlarge to ml.m4.xlarge due to \n",
    "                                                           # Free Tier allowances\n",
    "                       base_job_name='cifar10-tf',\n",
    "                       tags=tags)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Like before, we call `fit()` to start the SageMaker training job and pass the inputs in a dictionary to define different data channels for training. This time, we use the S3 URI from uploading our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-14 10:37:03 Starting - Starting the training job...\n",
      "2021-05-14 10:37:27 Starting - Launching requested ML instancesProfilerReport-1620988623: InProgress\n",
      "......\n",
      "2021-05-14 10:38:29 Starting - Preparing the instances for training.........\n",
      "2021-05-14 10:39:55 Downloading - Downloading input data\n",
      "2021-05-14 10:39:55 Training - Downloading the training image...\n",
      "2021-05-14 10:40:28 Training - Training image download completed. Training in progress.\u001b[34mWARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/__init__.py:1473: The name tf.estimator.inputs is deprecated. Please use tf.compat.v1.estimator.inputs instead.\n",
      "\u001b[0m\n",
      "\u001b[34m2021-05-14 10:40:21,562 sagemaker-containers INFO     Imported framework sagemaker_tensorflow_container.training\u001b[0m\n",
      "\u001b[34m2021-05-14 10:40:21,570 sagemaker-containers INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2021-05-14 10:40:22,032 sagemaker-containers INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2021-05-14 10:40:22,053 sagemaker-containers INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2021-05-14 10:40:22,074 sagemaker-containers INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2021-05-14 10:40:22,087 sagemaker-containers INFO     Invoking user script\n",
      "\u001b[0m\n",
      "\u001b[34mTraining Env:\n",
      "\u001b[0m\n",
      "\u001b[34m{\n",
      "    \"additional_framework_parameters\": {},\n",
      "    \"channel_input_dirs\": {\n",
      "        \"eval\": \"/opt/ml/input/data/eval\",\n",
      "        \"validation\": \"/opt/ml/input/data/validation\",\n",
      "        \"train\": \"/opt/ml/input/data/train\"\n",
      "    },\n",
      "    \"current_host\": \"algo-1\",\n",
      "    \"framework_module\": \"sagemaker_tensorflow_container.training:main\",\n",
      "    \"hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"hyperparameters\": {\n",
      "        \"batch-size\": 256,\n",
      "        \"model_dir\": \"s3://sagemaker-ap-southeast-2-987959606453/cifar10-tf-2021-05-14-10-37-03-005/model\",\n",
      "        \"epochs\": 10\n",
      "    },\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"input_data_config\": {\n",
      "        \"eval\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        },\n",
      "        \"validation\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        },\n",
      "        \"train\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        }\n",
      "    },\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"is_master\": true,\n",
      "    \"job_name\": \"cifar10-tf-2021-05-14-10-37-03-005\",\n",
      "    \"log_level\": 20,\n",
      "    \"master_hostname\": \"algo-1\",\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"module_dir\": \"s3://sagemaker-ap-southeast-2-987959606453/cifar10-tf-2021-05-14-10-37-03-005/source/sourcedir.tar.gz\",\n",
      "    \"module_name\": \"cifar10_keras_main\",\n",
      "    \"network_interface_name\": \"eth0\",\n",
      "    \"num_cpus\": 4,\n",
      "    \"num_gpus\": 0,\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"resource_config\": {\n",
      "        \"current_host\": \"algo-1\",\n",
      "        \"hosts\": [\n",
      "            \"algo-1\"\n",
      "        ],\n",
      "        \"network_interface_name\": \"eth0\"\n",
      "    },\n",
      "    \"user_entry_point\": \"cifar10_keras_main.py\"\u001b[0m\n",
      "\u001b[34m}\n",
      "\u001b[0m\n",
      "\u001b[34mEnvironment variables:\n",
      "\u001b[0m\n",
      "\u001b[34mSM_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[34mSM_NETWORK_INTERFACE_NAME=eth0\u001b[0m\n",
      "\u001b[34mSM_HPS={\"batch-size\":256,\"epochs\":10,\"model_dir\":\"s3://sagemaker-ap-southeast-2-987959606453/cifar10-tf-2021-05-14-10-37-03-005/model\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ENTRY_POINT=cifar10_keras_main.py\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_PARAMS={}\u001b[0m\n",
      "\u001b[34mSM_RESOURCE_CONFIG={\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"eth0\"}\u001b[0m\n",
      "\u001b[34mSM_INPUT_DATA_CONFIG={\"eval\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"train\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"validation\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}}\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DATA_DIR=/opt/ml/output/data\u001b[0m\n",
      "\u001b[34mSM_CHANNELS=[\"eval\",\"train\",\"validation\"]\u001b[0m\n",
      "\u001b[34mSM_CURRENT_HOST=algo-1\u001b[0m\n",
      "\u001b[34mSM_MODULE_NAME=cifar10_keras_main\u001b[0m\n",
      "\u001b[34mSM_LOG_LEVEL=20\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_MODULE=sagemaker_tensorflow_container.training:main\u001b[0m\n",
      "\u001b[34mSM_INPUT_DIR=/opt/ml/input\u001b[0m\n",
      "\u001b[34mSM_INPUT_CONFIG_DIR=/opt/ml/input/config\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DIR=/opt/ml/output\u001b[0m\n",
      "\u001b[34mSM_NUM_CPUS=4\u001b[0m\n",
      "\u001b[34mSM_NUM_GPUS=0\u001b[0m\n",
      "\u001b[34mSM_MODEL_DIR=/opt/ml/model\u001b[0m\n",
      "\u001b[34mSM_MODULE_DIR=s3://sagemaker-ap-southeast-2-987959606453/cifar10-tf-2021-05-14-10-37-03-005/source/sourcedir.tar.gz\u001b[0m\n",
      "\u001b[34mSM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"eval\":\"/opt/ml/input/data/eval\",\"train\":\"/opt/ml/input/data/train\",\"validation\":\"/opt/ml/input/data/validation\"},\"current_host\":\"algo-1\",\"framework_module\":\"sagemaker_tensorflow_container.training:main\",\"hosts\":[\"algo-1\"],\"hyperparameters\":{\"batch-size\":256,\"epochs\":10,\"model_dir\":\"s3://sagemaker-ap-southeast-2-987959606453/cifar10-tf-2021-05-14-10-37-03-005/model\"},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"eval\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"train\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"validation\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"is_master\":true,\"job_name\":\"cifar10-tf-2021-05-14-10-37-03-005\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-ap-southeast-2-987959606453/cifar10-tf-2021-05-14-10-37-03-005/source/sourcedir.tar.gz\",\"module_name\":\"cifar10_keras_main\",\"network_interface_name\":\"eth0\",\"num_cpus\":4,\"num_gpus\":0,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"cifar10_keras_main.py\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ARGS=[\"--batch-size\",\"256\",\"--epochs\",\"10\",\"--model_dir\",\"s3://sagemaker-ap-southeast-2-987959606453/cifar10-tf-2021-05-14-10-37-03-005/model\"]\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_EVAL=/opt/ml/input/data/eval\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_VALIDATION=/opt/ml/input/data/validation\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_TRAIN=/opt/ml/input/data/train\u001b[0m\n",
      "\u001b[34mSM_HP_BATCH-SIZE=256\u001b[0m\n",
      "\u001b[34mSM_HP_MODEL_DIR=s3://sagemaker-ap-southeast-2-987959606453/cifar10-tf-2021-05-14-10-37-03-005/model\u001b[0m\n",
      "\u001b[34mSM_HP_EPOCHS=10\u001b[0m\n",
      "\u001b[34mPYTHONPATH=/opt/ml/code:/usr/local/bin:/usr/lib/python36.zip:/usr/lib/python3.6:/usr/lib/python3.6/lib-dynload:/usr/local/lib/python3.6/dist-packages:/usr/lib/python3/dist-packages\n",
      "\u001b[0m\n",
      "\u001b[34mInvoking script with the following command:\n",
      "\u001b[0m\n",
      "\u001b[34m/usr/bin/python3 cifar10_keras_main.py --batch-size 256 --epochs 10 --model_dir s3://sagemaker-ap-southeast-2-987959606453/cifar10-tf-2021-05-14-10-37-03-005/model\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[34mUsing TensorFlow backend.\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/__init__.py:1473: The name tf.estimator.inputs is deprecated. Please use tf.compat.v1.estimator.inputs instead.\n",
      "\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:From cifar10_keras_main.py:30: The name tf.logging.set_verbosity is deprecated. Please use tf.compat.v1.logging.set_verbosity instead.\n",
      "\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:From cifar10_keras_main.py:30: The name tf.logging.INFO is deprecated. Please use tf.compat.v1.logging.INFO instead.\n",
      "\u001b[0m\n",
      "\u001b[34mINFO:root:Writing TensorBoard logs to s3://sagemaker-ap-southeast-2-987959606453/cifar10-tf-2021-05-14-10-37-03-005/model\u001b[0m\n",
      "\u001b[34mINFO:root:Running with MPI=False\u001b[0m\n",
      "\u001b[34mINFO:root:getting data\u001b[0m\n",
      "\u001b[34mINFO:root:Running train in File mode\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.FixedLenFeature is deprecated. Please use tf.io.FixedLenFeature instead.\n",
      "\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.FixedLenFeature is deprecated. Please use tf.io.FixedLenFeature instead.\n",
      "\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.parse_single_example is deprecated. Please use tf.io.parse_single_example instead.\n",
      "\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.parse_single_example is deprecated. Please use tf.io.parse_single_example instead.\n",
      "\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.image.resize_image_with_crop_or_pad is deprecated. Please use tf.image.resize_with_crop_or_pad instead.\n",
      "\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.image.resize_image_with_crop_or_pad is deprecated. Please use tf.image.resize_with_crop_or_pad instead.\n",
      "\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.random_crop is deprecated. Please use tf.image.random_crop instead.\n",
      "\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.random_crop is deprecated. Please use tf.image.random_crop instead.\n",
      "\u001b[0m\n",
      "\u001b[34mINFO:root:Running eval in File mode\u001b[0m\n",
      "\u001b[34mINFO:root:Running validation in File mode\u001b[0m\n",
      "\u001b[34mINFO:root:configuring model\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34mInstructions for updating:\u001b[0m\n",
      "\u001b[34mIf using Keras pass *_constraint arguments to layers.\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34mInstructions for updating:\u001b[0m\n",
      "\u001b[34mIf using Keras pass *_constraint arguments to layers.\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4070: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4070: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\u001b[0m\n",
      "\u001b[34mINFO:root:Starting training\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\u001b[0m\n",
      "\u001b[34mTrain on 256 samples, validate on 256 samples\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/callbacks/tensorboard_v1.py:200: The name tf.summary.merge_all is deprecated. Please use tf.compat.v1.summary.merge_all instead.\n",
      "\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/callbacks/tensorboard_v1.py:200: The name tf.summary.merge_all is deprecated. Please use tf.compat.v1.summary.merge_all instead.\n",
      "\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/callbacks/tensorboard_v1.py:203: The name tf.summary.FileWriter is deprecated. Please use tf.compat.v1.summary.FileWriter instead.\n",
      "\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/callbacks/tensorboard_v1.py:203: The name tf.summary.FileWriter is deprecated. Please use tf.compat.v1.summary.FileWriter instead.\n",
      "\u001b[0m\n",
      "\u001b[34mEpoch 1/10\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m  1/156 [..............................] - ETA: 25:45 - loss: 4.5213 - accuracy: 0.0859\u001b[0m\n",
      "\u001b[34m  2/156 [..............................] - ETA: 13:49 - loss: 2.9989 - accuracy: 0.2734\u001b[0m\n",
      "\u001b[34m  3/156 [..............................] - ETA: 9:50 - loss: 2.2958 - accuracy: 0.4258 \u001b[0m\n",
      "\u001b[34m  4/156 [..............................] - ETA: 7:52 - loss: 1.8657 - accuracy: 0.5068\u001b[0m\n",
      "\u001b[34m  5/156 [..............................] - ETA: 6:43 - loss: 1.5480 - accuracy: 0.5836\n",
      "  6/156 [>.............................] - ETA: 5:55 - loss: 1.3169 - accuracy: 0.6432\u001b[0m\n",
      "\u001b[34m  7/156 [>.............................] - ETA: 5:22 - loss: 1.1484 - accuracy: 0.6864\u001b[0m\n",
      "\u001b[34m  8/156 [>.............................] - ETA: 4:59 - loss: 1.0127 - accuracy: 0.7236\u001b[0m\n",
      "\u001b[34m  9/156 [>.............................] - ETA: 4:38 - loss: 0.9032 - accuracy: 0.7543\u001b[0m\n",
      "\u001b[34m 10/156 [>.............................] - ETA: 4:22 - loss: 0.8153 - accuracy: 0.7781\u001b[0m\n",
      "\u001b[34m 11/156 [=>............................] - ETA: 4:08 - loss: 0.7423 - accuracy: 0.7983\u001b[0m\n",
      "\u001b[34m 12/156 [=>............................] - ETA: 3:57 - loss: 0.6813 - accuracy: 0.8151\u001b[0m\n",
      "\u001b[34m 13/156 [=>............................] - ETA: 3:46 - loss: 0.6295 - accuracy: 0.8293\u001b[0m\n",
      "\u001b[34m 14/156 [=>............................] - ETA: 3:37 - loss: 0.5851 - accuracy: 0.8415\n",
      " 15/156 [=>............................] - ETA: 3:29 - loss: 0.5465 - accuracy: 0.8521\u001b[0m\n",
      "\u001b[34m 16/156 [==>...........................] - ETA: 3:22 - loss: 0.5129 - accuracy: 0.8613\u001b[0m\n",
      "\u001b[34m 17/156 [==>...........................] - ETA: 3:16 - loss: 0.4830 - accuracy: 0.8695\u001b[0m\n",
      "\u001b[34m 18/156 [==>...........................] - ETA: 3:10 - loss: 0.4566 - accuracy: 0.8767\u001b[0m\n",
      "\u001b[34m 19/156 [==>...........................] - ETA: 3:05 - loss: 0.4328 - accuracy: 0.8832\u001b[0m\n",
      "\u001b[34m 20/156 [==>...........................] - ETA: 3:01 - loss: 0.4115 - accuracy: 0.8891\u001b[0m\n",
      "\u001b[34m 21/156 [===>..........................] - ETA: 2:56 - loss: 0.3920 - accuracy: 0.8943\u001b[0m\n",
      "\u001b[34m 22/156 [===>..........................] - ETA: 2:53 - loss: 0.3743 - accuracy: 0.8991\n",
      " 23/156 [===>..........................] - ETA: 2:49 - loss: 0.3583 - accuracy: 0.9035\u001b[0m\n",
      "\u001b[34m 24/156 [===>..........................] - ETA: 2:45 - loss: 0.3435 - accuracy: 0.9076\u001b[0m\n",
      "\u001b[34m 25/156 [===>..........................] - ETA: 2:42 - loss: 0.3300 - accuracy: 0.9112\u001b[0m\n",
      "\u001b[34m 26/156 [====>.........................] - ETA: 2:40 - loss: 0.3174 - accuracy: 0.9147\u001b[0m\n",
      "\u001b[34m 27/156 [====>.........................] - ETA: 2:37 - loss: 0.3057 - accuracy: 0.9178\u001b[0m\n",
      "\u001b[34m 28/156 [====>.........................] - ETA: 2:34 - loss: 0.2949 - accuracy: 0.9208\u001b[0m\n",
      "\u001b[34m 29/156 [====>.........................] - ETA: 2:32 - loss: 0.2848 - accuracy: 0.9235\u001b[0m\n",
      "\u001b[34m 30/156 [====>.........................] - ETA: 2:29 - loss: 0.2753 - accuracy: 0.9260\u001b[0m\n",
      "\u001b[34m 31/156 [====>.........................] - ETA: 2:27 - loss: 0.2665 - accuracy: 0.9284\u001b[0m\n",
      "\u001b[34m 32/156 [=====>........................] - ETA: 2:24 - loss: 0.2582 - accuracy: 0.9307\u001b[0m\n",
      "\u001b[34m 33/156 [=====>........................] - ETA: 2:23 - loss: 0.2504 - accuracy: 0.9328\u001b[0m\n",
      "\u001b[34m 34/156 [=====>........................] - ETA: 2:22 - loss: 0.2431 - accuracy: 0.9347\u001b[0m\n",
      "\u001b[34m 35/156 [=====>........................] - ETA: 2:21 - loss: 0.2362 - accuracy: 0.9366\u001b[0m\n",
      "\u001b[34m 36/156 [=====>........................] - ETA: 2:19 - loss: 0.2296 - accuracy: 0.9384\u001b[0m\n",
      "\u001b[34m 37/156 [======>.......................] - ETA: 2:17 - loss: 0.2234 - accuracy: 0.9400\u001b[0m\n",
      "\u001b[34m 38/156 [======>.......................] - ETA: 2:14 - loss: 0.2176 - accuracy: 0.9416\n",
      " 39/156 [======>.......................] - ETA: 2:12 - loss: 0.2120 - accuracy: 0.9431\u001b[0m\n",
      "\u001b[34m 40/156 [======>.......................] - ETA: 2:11 - loss: 0.2067 - accuracy: 0.9445\u001b[0m\n",
      "\u001b[34m 41/156 [======>.......................] - ETA: 2:09 - loss: 0.2017 - accuracy: 0.9459\u001b[0m\n",
      "\u001b[34m 42/156 [=======>......................] - ETA: 2:07 - loss: 0.1969 - accuracy: 0.9472\u001b[0m\n",
      "\u001b[34m 43/156 [=======>......................] - ETA: 2:05 - loss: 0.1923 - accuracy: 0.9484\u001b[0m\n",
      "\u001b[34m 44/156 [=======>......................] - ETA: 2:04 - loss: 0.1880 - accuracy: 0.9496\u001b[0m\n",
      "\u001b[34m 45/156 [=======>......................] - ETA: 2:02 - loss: 0.1838 - accuracy: 0.9507\n",
      " 46/156 [=======>......................] - ETA: 2:00 - loss: 0.1798 - accuracy: 0.9518\u001b[0m\n",
      "\u001b[34m 47/156 [========>.....................] - ETA: 1:58 - loss: 0.1760 - accuracy: 0.9528\u001b[0m\n",
      "\u001b[34m 48/156 [========>.....................] - ETA: 1:57 - loss: 0.1723 - accuracy: 0.9538\u001b[0m\n",
      "\u001b[34m 49/156 [========>.....................] - ETA: 1:55 - loss: 0.1688 - accuracy: 0.9547\u001b[0m\n",
      "\u001b[34m 50/156 [========>.....................] - ETA: 1:54 - loss: 0.1654 - accuracy: 0.9556\u001b[0m\n",
      "\u001b[34m 51/156 [========>.....................] - ETA: 1:52 - loss: 0.1622 - accuracy: 0.9565\u001b[0m\n",
      "\u001b[34m 52/156 [=========>....................] - ETA: 1:51 - loss: 0.1591 - accuracy: 0.9573\u001b[0m\n",
      "\u001b[34m 53/156 [=========>....................] - ETA: 1:49 - loss: 0.1561 - accuracy: 0.9581\n",
      " 54/156 [=========>....................] - ETA: 1:48 - loss: 0.1532 - accuracy: 0.9589\u001b[0m\n",
      "\u001b[34m 55/156 [=========>....................] - ETA: 1:46 - loss: 0.1504 - accuracy: 0.9597\u001b[0m\n",
      "\u001b[34m 56/156 [=========>....................] - ETA: 1:45 - loss: 0.1477 - accuracy: 0.9604\u001b[0m\n",
      "\u001b[34m 57/156 [=========>....................] - ETA: 1:44 - loss: 0.1451 - accuracy: 0.9611\u001b[0m\n",
      "\u001b[34m 58/156 [==========>...................] - ETA: 1:42 - loss: 0.1426 - accuracy: 0.9617\u001b[0m\n",
      "\u001b[34m 59/156 [==========>...................] - ETA: 1:41 - loss: 0.1402 - accuracy: 0.9624\n",
      " 60/156 [==========>...................] - ETA: 1:39 - loss: 0.1379 - accuracy: 0.9630\u001b[0m\n",
      "\u001b[34m 61/156 [==========>...................] - ETA: 1:38 - loss: 0.1356 - accuracy: 0.9636\u001b[0m\n",
      "\u001b[34m 62/156 [==========>...................] - ETA: 1:37 - loss: 0.1334 - accuracy: 0.9642\u001b[0m\n",
      "\u001b[34m 63/156 [===========>..................] - ETA: 1:36 - loss: 0.1313 - accuracy: 0.9648\u001b[0m\n",
      "\u001b[34m 64/156 [===========>..................] - ETA: 1:34 - loss: 0.1293 - accuracy: 0.9653\u001b[0m\n",
      "\u001b[34m 65/156 [===========>..................] - ETA: 1:33 - loss: 0.1273 - accuracy: 0.9659\u001b[0m\n",
      "\u001b[34m 66/156 [===========>..................] - ETA: 1:32 - loss: 0.1254 - accuracy: 0.9664\u001b[0m\n",
      "\u001b[34m 67/156 [===========>..................] - ETA: 1:31 - loss: 0.1235 - accuracy: 0.9669\u001b[0m\n",
      "\u001b[34m 68/156 [============>.................] - ETA: 1:30 - loss: 0.1217 - accuracy: 0.9674\u001b[0m\n",
      "\u001b[34m 69/156 [============>.................] - ETA: 1:29 - loss: 0.1199 - accuracy: 0.9678\n",
      " 70/156 [============>.................] - ETA: 1:27 - loss: 0.1182 - accuracy: 0.9683\u001b[0m\n",
      "\u001b[34m 71/156 [============>.................] - ETA: 1:26 - loss: 0.1165 - accuracy: 0.9688\u001b[0m\n",
      "\u001b[34m 72/156 [============>.................] - ETA: 1:25 - loss: 0.1149 - accuracy: 0.9692\u001b[0m\n",
      "\u001b[34m 73/156 [=============>................] - ETA: 1:24 - loss: 0.1134 - accuracy: 0.9696\u001b[0m\n",
      "\u001b[34m 74/156 [=============>................] - ETA: 1:22 - loss: 0.1118 - accuracy: 0.9700\u001b[0m\n",
      "\u001b[34m 75/156 [=============>................] - ETA: 1:21 - loss: 0.1103 - accuracy: 0.9704\n",
      " 76/156 [=============>................] - ETA: 1:20 - loss: 0.1089 - accuracy: 0.9708\u001b[0m\n",
      "\u001b[34m 77/156 [=============>................] - ETA: 1:19 - loss: 0.1075 - accuracy: 0.9712\u001b[0m\n",
      "\u001b[34m 78/156 [==============>...............] - ETA: 1:18 - loss: 0.1061 - accuracy: 0.9716\u001b[0m\n",
      "\u001b[34m 79/156 [==============>...............] - ETA: 1:17 - loss: 0.1048 - accuracy: 0.9719\u001b[0m\n",
      "\u001b[34m 80/156 [==============>...............] - ETA: 1:16 - loss: 0.1034 - accuracy: 0.9723\u001b[0m\n",
      "\u001b[34m 81/156 [==============>...............] - ETA: 1:14 - loss: 0.1022 - accuracy: 0.9726\u001b[0m\n",
      "\u001b[34m 82/156 [==============>...............] - ETA: 1:13 - loss: 0.1009 - accuracy: 0.9729\n",
      " 83/156 [==============>...............] - ETA: 1:12 - loss: 0.0997 - accuracy: 0.9733\u001b[0m\n",
      "\u001b[34m 84/156 [===============>..............] - ETA: 1:11 - loss: 0.0985 - accuracy: 0.9736\u001b[0m\n",
      "\u001b[34m 85/156 [===============>..............] - ETA: 1:10 - loss: 0.0974 - accuracy: 0.9739\u001b[0m\n",
      "\u001b[34m 86/156 [===============>..............] - ETA: 1:09 - loss: 0.0962 - accuracy: 0.9742\u001b[0m\n",
      "\u001b[34m 87/156 [===============>..............] - ETA: 1:08 - loss: 0.0951 - accuracy: 0.9745\u001b[0m\n",
      "\u001b[34m 88/156 [===============>..............] - ETA: 1:07 - loss: 0.0941 - accuracy: 0.9748\n",
      " 89/156 [================>.............] - ETA: 1:05 - loss: 0.0930 - accuracy: 0.9751\u001b[0m\n",
      "\u001b[34m 90/156 [================>.............] - ETA: 1:04 - loss: 0.0920 - accuracy: 0.9753\u001b[0m\n",
      "\u001b[34m 91/156 [================>.............] - ETA: 1:03 - loss: 0.0910 - accuracy: 0.9756\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m 92/156 [================>.............] - ETA: 1:02 - loss: 0.0900 - accuracy: 0.9759\u001b[0m\n",
      "\u001b[34m 93/156 [================>.............] - ETA: 1:01 - loss: 0.0890 - accuracy: 0.9761\u001b[0m\n",
      "\u001b[34m 94/156 [=================>............] - ETA: 1:00 - loss: 0.0881 - accuracy: 0.9764\u001b[0m\n",
      "\u001b[34m 95/156 [=================>............] - ETA: 59s - loss: 0.0871 - accuracy: 0.9766 \u001b[0m\n",
      "\u001b[34m 96/156 [=================>............] - ETA: 58s - loss: 0.0862 - accuracy: 0.9769\u001b[0m\n",
      "\u001b[34m 97/156 [=================>............] - ETA: 57s - loss: 0.0853 - accuracy: 0.9771\u001b[0m\n",
      "\u001b[34m 98/156 [=================>............] - ETA: 57s - loss: 0.0845 - accuracy: 0.9774\u001b[0m\n",
      "\u001b[34m 99/156 [==================>...........] - ETA: 56s - loss: 0.0836 - accuracy: 0.9776\u001b[0m\n",
      "\u001b[34m100/156 [==================>...........] - ETA: 55s - loss: 0.0828 - accuracy: 0.9778\u001b[0m\n",
      "\u001b[34m101/156 [==================>...........] - ETA: 54s - loss: 0.0820 - accuracy: 0.9780\u001b[0m\n",
      "\u001b[34m102/156 [==================>...........] - ETA: 53s - loss: 0.0812 - accuracy: 0.9782\u001b[0m\n",
      "\u001b[34m103/156 [==================>...........] - ETA: 51s - loss: 0.0804 - accuracy: 0.9785\u001b[0m\n",
      "\u001b[34m104/156 [===================>..........] - ETA: 50s - loss: 0.0796 - accuracy: 0.9787\u001b[0m\n",
      "\u001b[34m105/156 [===================>..........] - ETA: 49s - loss: 0.0788 - accuracy: 0.9789\u001b[0m\n",
      "\u001b[34m106/156 [===================>..........] - ETA: 48s - loss: 0.0781 - accuracy: 0.9791\u001b[0m\n",
      "\u001b[34m107/156 [===================>..........] - ETA: 47s - loss: 0.0774 - accuracy: 0.9793\u001b[0m\n",
      "\u001b[34m108/156 [===================>..........] - ETA: 46s - loss: 0.0767 - accuracy: 0.9795\u001b[0m\n",
      "\u001b[34m109/156 [===================>..........] - ETA: 45s - loss: 0.0760 - accuracy: 0.9796\u001b[0m\n",
      "\u001b[34m110/156 [====================>.........] - ETA: 44s - loss: 0.0753 - accuracy: 0.9798\u001b[0m\n",
      "\u001b[34m111/156 [====================>.........] - ETA: 43s - loss: 0.0746 - accuracy: 0.9800\u001b[0m\n",
      "\u001b[34m112/156 [====================>.........] - ETA: 42s - loss: 0.0739 - accuracy: 0.9802\u001b[0m\n",
      "\u001b[34m113/156 [====================>.........] - ETA: 41s - loss: 0.0733 - accuracy: 0.9804\u001b[0m\n",
      "\u001b[34m114/156 [====================>.........] - ETA: 40s - loss: 0.0726 - accuracy: 0.9805\u001b[0m\n",
      "\u001b[34m115/156 [=====================>........] - ETA: 39s - loss: 0.0720 - accuracy: 0.9807\u001b[0m\n",
      "\u001b[34m116/156 [=====================>........] - ETA: 38s - loss: 0.0714 - accuracy: 0.9809\u001b[0m\n",
      "\u001b[34m117/156 [=====================>........] - ETA: 37s - loss: 0.0708 - accuracy: 0.9810\u001b[0m\n",
      "\u001b[34m118/156 [=====================>........] - ETA: 36s - loss: 0.0702 - accuracy: 0.9812\u001b[0m\n",
      "\u001b[34m119/156 [=====================>........] - ETA: 35s - loss: 0.0696 - accuracy: 0.9814\u001b[0m\n",
      "\u001b[34m120/156 [======================>.......] - ETA: 34s - loss: 0.0690 - accuracy: 0.9815\u001b[0m\n",
      "\u001b[34m121/156 [======================>.......] - ETA: 33s - loss: 0.0684 - accuracy: 0.9817\u001b[0m\n",
      "\u001b[34m122/156 [======================>.......] - ETA: 32s - loss: 0.0679 - accuracy: 0.9818\u001b[0m\n",
      "\u001b[34m123/156 [======================>.......] - ETA: 31s - loss: 0.0673 - accuracy: 0.9820\u001b[0m\n",
      "\u001b[34m124/156 [======================>.......] - ETA: 30s - loss: 0.0668 - accuracy: 0.9821\u001b[0m\n",
      "\u001b[34m125/156 [=======================>......] - ETA: 29s - loss: 0.0662 - accuracy: 0.9822\u001b[0m\n",
      "\u001b[34m126/156 [=======================>......] - ETA: 28s - loss: 0.0657 - accuracy: 0.9824\u001b[0m\n",
      "\u001b[34m127/156 [=======================>......] - ETA: 27s - loss: 0.0652 - accuracy: 0.9825\u001b[0m\n",
      "\u001b[34m128/156 [=======================>......] - ETA: 26s - loss: 0.0647 - accuracy: 0.9827\u001b[0m\n",
      "\u001b[34m129/156 [=======================>......] - ETA: 25s - loss: 0.0642 - accuracy: 0.9828\u001b[0m\n",
      "\u001b[34m130/156 [========================>.....] - ETA: 24s - loss: 0.0637 - accuracy: 0.9829\u001b[0m\n",
      "\u001b[34m131/156 [========================>.....] - ETA: 23s - loss: 0.0632 - accuracy: 0.9831\u001b[0m\n",
      "\u001b[34m132/156 [========================>.....] - ETA: 22s - loss: 0.0627 - accuracy: 0.9832\u001b[0m\n",
      "\u001b[34m133/156 [========================>.....] - ETA: 22s - loss: 0.0623 - accuracy: 0.9833\u001b[0m\n",
      "\u001b[34m134/156 [========================>.....] - ETA: 21s - loss: 0.0618 - accuracy: 0.9834\u001b[0m\n",
      "\u001b[34m135/156 [========================>.....] - ETA: 20s - loss: 0.0613 - accuracy: 0.9836\u001b[0m\n",
      "\u001b[34m136/156 [=========================>....] - ETA: 19s - loss: 0.0609 - accuracy: 0.9837\u001b[0m\n",
      "\u001b[34m137/156 [=========================>....] - ETA: 18s - loss: 0.0604 - accuracy: 0.9838\u001b[0m\n",
      "\u001b[34m138/156 [=========================>....] - ETA: 17s - loss: 0.0600 - accuracy: 0.9839\u001b[0m\n",
      "\u001b[34m139/156 [=========================>....] - ETA: 16s - loss: 0.0596 - accuracy: 0.9840\u001b[0m\n",
      "\u001b[34m140/156 [=========================>....] - ETA: 15s - loss: 0.0592 - accuracy: 0.9842\u001b[0m\n",
      "\u001b[34m141/156 [==========================>...] - ETA: 14s - loss: 0.0587 - accuracy: 0.9843\u001b[0m\n",
      "\u001b[34m142/156 [==========================>...] - ETA: 13s - loss: 0.0583 - accuracy: 0.9844\u001b[0m\n",
      "\u001b[34m143/156 [==========================>...] - ETA: 12s - loss: 0.0579 - accuracy: 0.9845\u001b[0m\n",
      "\u001b[34m144/156 [==========================>...] - ETA: 11s - loss: 0.0575 - accuracy: 0.9846\u001b[0m\n",
      "\u001b[34m145/156 [==========================>...] - ETA: 10s - loss: 0.0571 - accuracy: 0.9847\u001b[0m\n",
      "\u001b[34m146/156 [===========================>..] - ETA: 9s - loss: 0.0567 - accuracy: 0.9848 \u001b[0m\n",
      "\u001b[34m147/156 [===========================>..] - ETA: 8s - loss: 0.0563 - accuracy: 0.9849\u001b[0m\n",
      "\u001b[34m148/156 [===========================>..] - ETA: 7s - loss: 0.0560 - accuracy: 0.9850\u001b[0m\n",
      "\u001b[34m149/156 [===========================>..] - ETA: 6s - loss: 0.0556 - accuracy: 0.9851\u001b[0m\n",
      "\u001b[34m150/156 [===========================>..] - ETA: 5s - loss: 0.0552 - accuracy: 0.9852\u001b[0m\n",
      "\u001b[34m151/156 [============================>.] - ETA: 4s - loss: 0.0548 - accuracy: 0.9853\u001b[0m\n",
      "\u001b[34m152/156 [============================>.] - ETA: 3s - loss: 0.0545 - accuracy: 0.9854\u001b[0m\n",
      "\u001b[34m153/156 [============================>.] - ETA: 2s - loss: 0.0541 - accuracy: 0.9855\u001b[0m\n",
      "\u001b[34m154/156 [============================>.] - ETA: 1s - loss: 0.0538 - accuracy: 0.9856\u001b[0m\n",
      "\u001b[34m155/156 [============================>.] - ETA: 0s - loss: 0.0534 - accuracy: 0.9857\u001b[0m\n",
      "\u001b[34m156/156 [==============================] - 165s 1s/step - loss: 0.0531 - accuracy: 0.9858 - val_loss: 0.2961 - val_accuracy: 0.0000e+00\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/callbacks/tensorboard_v1.py:343: The name tf.Summary is deprecated. Please use tf.compat.v1.Summary instead.\n",
      "\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/callbacks/tensorboard_v1.py:343: The name tf.Summary is deprecated. Please use tf.compat.v1.Summary instead.\n",
      "\u001b[0m\n",
      "\u001b[34mEpoch 2/10\u001b[0m\n",
      "\u001b[34m  1/156 [..............................] - ETA: 2:25 - loss: 4.9345e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m  2/156 [..............................] - ETA: 2:20 - loss: 4.9841e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m  3/156 [..............................] - ETA: 2:15 - loss: 4.8553e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m  4/156 [..............................] - ETA: 2:12 - loss: 4.4458e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m  5/156 [..............................] - ETA: 2:16 - loss: 4.0583e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m  6/156 [>.............................] - ETA: 2:15 - loss: 4.9679e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m  7/156 [>.............................] - ETA: 2:15 - loss: 5.1140e-05 - accuracy: 1.0000\n",
      "  8/156 [>.............................] - ETA: 2:13 - loss: 5.1411e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m  9/156 [>.............................] - ETA: 2:13 - loss: 5.1401e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 10/156 [>.............................] - ETA: 2:11 - loss: 4.8669e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 11/156 [=>............................] - ETA: 2:09 - loss: 4.8908e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 12/156 [=>............................] - ETA: 2:08 - loss: 4.6843e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 13/156 [=>............................] - ETA: 2:08 - loss: 4.7450e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 14/156 [=>............................] - ETA: 2:06 - loss: 5.5371e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 15/156 [=>............................] - ETA: 2:05 - loss: 5.3301e-05 - accuracy: 1.0000\n",
      " 16/156 [==>...........................] - ETA: 2:04 - loss: 5.5950e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 17/156 [==>...........................] - ETA: 2:03 - loss: 5.4584e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 18/156 [==>...........................] - ETA: 2:02 - loss: 5.3562e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 19/156 [==>...........................] - ETA: 2:01 - loss: 5.2609e-05 - accuracy: 1.0000\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m 20/156 [==>...........................] - ETA: 2:00 - loss: 5.2773e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 21/156 [===>..........................] - ETA: 1:58 - loss: 5.1198e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 22/156 [===>..........................] - ETA: 1:58 - loss: 5.2401e-05 - accuracy: 1.0000\n",
      " 23/156 [===>..........................] - ETA: 1:56 - loss: 5.1504e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 24/156 [===>..........................] - ETA: 1:56 - loss: 5.0386e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 25/156 [===>..........................] - ETA: 1:55 - loss: 4.9855e-05 - accuracy: 1.0000\n",
      " 26/156 [====>.........................] - ETA: 1:56 - loss: 4.9602e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 27/156 [====>.........................] - ETA: 1:54 - loss: 4.9014e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 28/156 [====>.........................] - ETA: 1:53 - loss: 4.9985e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 29/156 [====>.........................] - ETA: 1:52 - loss: 5.0469e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 30/156 [====>.........................] - ETA: 1:52 - loss: 5.0786e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 31/156 [====>.........................] - ETA: 1:51 - loss: 5.1047e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 32/156 [=====>........................] - ETA: 1:50 - loss: 5.1145e-05 - accuracy: 1.0000\n",
      " 33/156 [=====>........................] - ETA: 1:49 - loss: 5.2062e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 34/156 [=====>........................] - ETA: 1:48 - loss: 5.2293e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 35/156 [=====>........................] - ETA: 1:47 - loss: 5.1863e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 36/156 [=====>........................] - ETA: 1:46 - loss: 5.1322e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 37/156 [======>.......................] - ETA: 1:45 - loss: 5.0645e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 38/156 [======>.......................] - ETA: 1:44 - loss: 4.9975e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 39/156 [======>.......................] - ETA: 1:43 - loss: 5.2108e-05 - accuracy: 1.0000\n",
      " 40/156 [======>.......................] - ETA: 1:42 - loss: 5.1534e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 41/156 [======>.......................] - ETA: 1:41 - loss: 5.1502e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 42/156 [=======>......................] - ETA: 1:40 - loss: 5.1872e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 43/156 [=======>......................] - ETA: 1:39 - loss: 5.2540e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 44/156 [=======>......................] - ETA: 1:38 - loss: 5.2049e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 45/156 [=======>......................] - ETA: 1:37 - loss: 5.2586e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 46/156 [=======>......................] - ETA: 1:36 - loss: 5.2516e-05 - accuracy: 1.0000\n",
      " 47/156 [========>.....................] - ETA: 1:35 - loss: 5.1684e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 48/156 [========>.....................] - ETA: 1:34 - loss: 5.1484e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 49/156 [========>.....................] - ETA: 1:33 - loss: 5.2948e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 50/156 [========>.....................] - ETA: 1:32 - loss: 5.2496e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 51/156 [========>.....................] - ETA: 1:32 - loss: 5.2078e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 52/156 [=========>....................] - ETA: 1:31 - loss: 5.1398e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 53/156 [=========>....................] - ETA: 1:30 - loss: 5.1284e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 54/156 [=========>....................] - ETA: 1:30 - loss: 5.1081e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 55/156 [=========>....................] - ETA: 1:29 - loss: 5.0703e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 56/156 [=========>....................] - ETA: 1:29 - loss: 5.0935e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 57/156 [=========>....................] - ETA: 1:28 - loss: 5.0511e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 58/156 [==========>...................] - ETA: 1:27 - loss: 5.0096e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 59/156 [==========>...................] - ETA: 1:26 - loss: 5.4548e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 60/156 [==========>...................] - ETA: 1:26 - loss: 5.4491e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 61/156 [==========>...................] - ETA: 1:25 - loss: 5.3964e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 62/156 [==========>...................] - ETA: 1:24 - loss: 5.5153e-05 - accuracy: 1.0000\n",
      " 63/156 [===========>..................] - ETA: 1:23 - loss: 5.4815e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 64/156 [===========>..................] - ETA: 1:22 - loss: 5.5084e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 65/156 [===========>..................] - ETA: 1:21 - loss: 5.4475e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 66/156 [===========>..................] - ETA: 1:20 - loss: 5.4363e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 67/156 [===========>..................] - ETA: 1:19 - loss: 5.4168e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 68/156 [============>.................] - ETA: 1:18 - loss: 5.3739e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 69/156 [============>.................] - ETA: 1:17 - loss: 5.3293e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 70/156 [============>.................] - ETA: 1:17 - loss: 5.3213e-05 - accuracy: 1.0000\n",
      " 71/156 [============>.................] - ETA: 1:16 - loss: 5.2853e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 72/156 [============>.................] - ETA: 1:15 - loss: 5.2642e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 73/156 [=============>................] - ETA: 1:14 - loss: 5.2574e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 74/156 [=============>................] - ETA: 1:13 - loss: 5.3980e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 75/156 [=============>................] - ETA: 1:12 - loss: 5.4296e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 76/156 [=============>................] - ETA: 1:11 - loss: 5.4068e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 77/156 [=============>................] - ETA: 1:10 - loss: 5.3600e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 78/156 [==============>...............] - ETA: 1:09 - loss: 5.3134e-05 - accuracy: 1.0000\n",
      " 79/156 [==============>...............] - ETA: 1:08 - loss: 5.2969e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 80/156 [==============>...............] - ETA: 1:07 - loss: 5.3067e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 81/156 [==============>...............] - ETA: 1:06 - loss: 5.2917e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 82/156 [==============>...............] - ETA: 1:05 - loss: 5.2810e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 83/156 [==============>...............] - ETA: 1:04 - loss: 5.2448e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 84/156 [===============>..............] - ETA: 1:04 - loss: 5.2220e-05 - accuracy: 1.0000\n",
      " 85/156 [===============>..............] - ETA: 1:03 - loss: 5.2208e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 86/156 [===============>..............] - ETA: 1:02 - loss: 5.1760e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 87/156 [===============>..............] - ETA: 1:01 - loss: 5.1546e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 88/156 [===============>..............] - ETA: 1:00 - loss: 5.1122e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 89/156 [================>.............] - ETA: 59s - loss: 5.1019e-05 - accuracy: 1.0000 \u001b[0m\n",
      "\u001b[34m 90/156 [================>.............] - ETA: 58s - loss: 5.0897e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 91/156 [================>.............] - ETA: 57s - loss: 5.0785e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 92/156 [================>.............] - ETA: 56s - loss: 5.0647e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 93/156 [================>.............] - ETA: 55s - loss: 5.0601e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 94/156 [=================>............] - ETA: 55s - loss: 5.0378e-05 - accuracy: 1.0000\n",
      " 95/156 [=================>............] - ETA: 54s - loss: 5.0053e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 96/156 [=================>............] - ETA: 53s - loss: 4.9719e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 97/156 [=================>............] - ETA: 52s - loss: 4.9927e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 98/156 [=================>............] - ETA: 51s - loss: 4.9601e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 99/156 [==================>...........] - ETA: 50s - loss: 4.9423e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m100/156 [==================>...........] - ETA: 49s - loss: 4.9182e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m101/156 [==================>...........] - ETA: 48s - loss: 4.9426e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m102/156 [==================>...........] - ETA: 47s - loss: 4.9219e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m103/156 [==================>...........] - ETA: 47s - loss: 4.8940e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m104/156 [===================>..........] - ETA: 46s - loss: 4.9252e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m105/156 [===================>..........] - ETA: 45s - loss: 4.9134e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m106/156 [===================>..........] - ETA: 44s - loss: 4.8933e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m107/156 [===================>..........] - ETA: 43s - loss: 4.8703e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m108/156 [===================>..........] - ETA: 42s - loss: 4.8622e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m109/156 [===================>..........] - ETA: 41s - loss: 4.8339e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m110/156 [====================>.........] - ETA: 40s - loss: 4.8070e-05 - accuracy: 1.0000\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m111/156 [====================>.........] - ETA: 39s - loss: 5.0048e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m112/156 [====================>.........] - ETA: 38s - loss: 4.9888e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m113/156 [====================>.........] - ETA: 38s - loss: 5.0307e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m114/156 [====================>.........] - ETA: 37s - loss: 5.0010e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m115/156 [=====================>........] - ETA: 36s - loss: 4.9743e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m116/156 [=====================>........] - ETA: 35s - loss: 4.9613e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m117/156 [=====================>........] - ETA: 34s - loss: 4.9351e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m118/156 [=====================>........] - ETA: 33s - loss: 4.9258e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m119/156 [=====================>........] - ETA: 32s - loss: 4.9035e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m120/156 [======================>.......] - ETA: 31s - loss: 4.8849e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m121/156 [======================>.......] - ETA: 31s - loss: 4.8632e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m122/156 [======================>.......] - ETA: 30s - loss: 4.8544e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m123/156 [======================>.......] - ETA: 29s - loss: 4.8323e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m124/156 [======================>.......] - ETA: 28s - loss: 4.8106e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m125/156 [=======================>......] - ETA: 27s - loss: 4.8004e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m126/156 [=======================>......] - ETA: 26s - loss: 4.7977e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m127/156 [=======================>......] - ETA: 25s - loss: 4.8026e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m128/156 [=======================>......] - ETA: 25s - loss: 4.7930e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m129/156 [=======================>......] - ETA: 24s - loss: 4.7837e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m130/156 [========================>.....] - ETA: 23s - loss: 4.7614e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m131/156 [========================>.....] - ETA: 22s - loss: 4.7409e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m132/156 [========================>.....] - ETA: 21s - loss: 4.7197e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m133/156 [========================>.....] - ETA: 20s - loss: 4.7296e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m134/156 [========================>.....] - ETA: 19s - loss: 4.7081e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m135/156 [========================>.....] - ETA: 18s - loss: 4.6881e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m136/156 [=========================>....] - ETA: 17s - loss: 4.6650e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m137/156 [=========================>....] - ETA: 16s - loss: 4.6480e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m138/156 [=========================>....] - ETA: 16s - loss: 4.6303e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m139/156 [=========================>....] - ETA: 15s - loss: 4.6185e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m140/156 [=========================>....] - ETA: 14s - loss: 4.6009e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m141/156 [==========================>...] - ETA: 13s - loss: 4.5846e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m142/156 [==========================>...] - ETA: 12s - loss: 4.5588e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m143/156 [==========================>...] - ETA: 11s - loss: 4.5426e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m144/156 [==========================>...] - ETA: 10s - loss: 4.5320e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m145/156 [==========================>...] - ETA: 9s - loss: 4.5105e-05 - accuracy: 1.0000 \u001b[0m\n",
      "\u001b[34m146/156 [===========================>..] - ETA: 8s - loss: 4.4933e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m147/156 [===========================>..] - ETA: 8s - loss: 4.5063e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m148/156 [===========================>..] - ETA: 7s - loss: 4.5142e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m149/156 [===========================>..] - ETA: 6s - loss: 4.5093e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m150/156 [===========================>..] - ETA: 5s - loss: 4.5031e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m151/156 [============================>.] - ETA: 4s - loss: 4.4853e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m152/156 [============================>.] - ETA: 3s - loss: 4.4744e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m153/156 [============================>.] - ETA: 2s - loss: 4.4561e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m154/156 [============================>.] - ETA: 1s - loss: 4.4449e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m155/156 [============================>.] - ETA: 0s - loss: 4.4508e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m156/156 [==============================] - 154s 990ms/step - loss: 4.4381e-05 - accuracy: 1.0000 - val_loss: 0.0872 - val_accuracy: 13.4871\u001b[0m\n",
      "\u001b[34mEpoch 3/10\u001b[0m\n",
      "\u001b[34m  1/156 [..............................] - ETA: 2:21 - loss: 2.3888e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m  2/156 [..............................] - ETA: 2:11 - loss: 2.5921e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m  3/156 [..............................] - ETA: 2:08 - loss: 2.2594e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m  4/156 [..............................] - ETA: 2:11 - loss: 2.1763e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m  5/156 [..............................] - ETA: 2:11 - loss: 2.3870e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m  6/156 [>.............................] - ETA: 2:08 - loss: 2.7783e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m  7/156 [>.............................] - ETA: 2:07 - loss: 2.8058e-05 - accuracy: 1.0000\n",
      "  8/156 [>.............................] - ETA: 2:06 - loss: 2.8079e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m  9/156 [>.............................] - ETA: 2:05 - loss: 2.7899e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 10/156 [>.............................] - ETA: 2:06 - loss: 2.6538e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 11/156 [=>............................] - ETA: 2:05 - loss: 2.9191e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 12/156 [=>............................] - ETA: 2:06 - loss: 3.0915e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 13/156 [=>............................] - ETA: 2:05 - loss: 2.9553e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 14/156 [=>............................] - ETA: 2:05 - loss: 2.8853e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 15/156 [=>............................] - ETA: 2:05 - loss: 2.8893e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 16/156 [==>...........................] - ETA: 2:08 - loss: 2.8526e-05 - accuracy: 1.0000\n",
      " 17/156 [==>...........................] - ETA: 2:09 - loss: 2.8939e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 18/156 [==>...........................] - ETA: 2:08 - loss: 2.8513e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 19/156 [==>...........................] - ETA: 2:07 - loss: 2.7903e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 20/156 [==>...........................] - ETA: 2:06 - loss: 2.7532e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 21/156 [===>..........................] - ETA: 2:05 - loss: 3.0111e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 22/156 [===>..........................] - ETA: 2:03 - loss: 2.9867e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 23/156 [===>..........................] - ETA: 2:03 - loss: 2.9139e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 24/156 [===>..........................] - ETA: 2:02 - loss: 2.8978e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 25/156 [===>..........................] - ETA: 2:00 - loss: 2.8650e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 26/156 [====>.........................] - ETA: 1:59 - loss: 2.8585e-05 - accuracy: 1.0000\n",
      " 27/156 [====>.........................] - ETA: 1:58 - loss: 2.7963e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 28/156 [====>.........................] - ETA: 1:57 - loss: 2.8115e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 29/156 [====>.........................] - ETA: 1:56 - loss: 2.8422e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 30/156 [====>.........................] - ETA: 1:54 - loss: 2.8182e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 31/156 [====>.........................] - ETA: 1:53 - loss: 2.7791e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 32/156 [=====>........................] - ETA: 1:52 - loss: 2.7308e-05 - accuracy: 1.0000\n",
      " 33/156 [=====>........................] - ETA: 1:51 - loss: 2.7703e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 34/156 [=====>........................] - ETA: 1:50 - loss: 2.7612e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 35/156 [=====>........................] - ETA: 1:49 - loss: 2.7615e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 36/156 [=====>........................] - ETA: 1:48 - loss: 2.7733e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 37/156 [======>.......................] - ETA: 1:47 - loss: 2.7265e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 38/156 [======>.......................] - ETA: 1:46 - loss: 2.7067e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 39/156 [======>.......................] - ETA: 1:45 - loss: 2.6677e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 40/156 [======>.......................] - ETA: 1:44 - loss: 2.6723e-05 - accuracy: 1.0000\n",
      " 41/156 [======>.......................] - ETA: 1:43 - loss: 2.6546e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 42/156 [=======>......................] - ETA: 1:42 - loss: 2.6602e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 43/156 [=======>......................] - ETA: 1:41 - loss: 2.6280e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 44/156 [=======>......................] - ETA: 1:40 - loss: 2.6202e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 45/156 [=======>......................] - ETA: 1:39 - loss: 2.6145e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 46/156 [=======>......................] - ETA: 1:38 - loss: 2.6111e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 47/156 [========>.....................] - ETA: 1:37 - loss: 2.6043e-05 - accuracy: 1.0000\n",
      " 48/156 [========>.....................] - ETA: 1:36 - loss: 2.5772e-05 - accuracy: 1.0000\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m 49/156 [========>.....................] - ETA: 1:35 - loss: 2.5840e-05 - accuracy: 1.0000\n",
      " 50/156 [========>.....................] - ETA: 1:35 - loss: 2.5699e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 51/156 [========>.....................] - ETA: 1:34 - loss: 2.5542e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 52/156 [=========>....................] - ETA: 1:33 - loss: 2.5412e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 53/156 [=========>....................] - ETA: 1:32 - loss: 2.5425e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 54/156 [=========>....................] - ETA: 1:31 - loss: 2.5814e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 55/156 [=========>....................] - ETA: 1:30 - loss: 2.5631e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 56/156 [=========>....................] - ETA: 1:29 - loss: 2.5481e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 57/156 [=========>....................] - ETA: 1:28 - loss: 2.5443e-05 - accuracy: 1.0000\n",
      " 58/156 [==========>...................] - ETA: 1:27 - loss: 2.5343e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 59/156 [==========>...................] - ETA: 1:26 - loss: 2.6041e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 60/156 [==========>...................] - ETA: 1:25 - loss: 2.5806e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 61/156 [==========>...................] - ETA: 1:24 - loss: 2.5548e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 62/156 [==========>...................] - ETA: 1:24 - loss: 2.5535e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 63/156 [===========>..................] - ETA: 1:23 - loss: 2.5597e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 64/156 [===========>..................] - ETA: 1:22 - loss: 2.5587e-05 - accuracy: 1.0000\n",
      " 65/156 [===========>..................] - ETA: 1:21 - loss: 2.5378e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 66/156 [===========>..................] - ETA: 1:20 - loss: 2.5561e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 67/156 [===========>..................] - ETA: 1:19 - loss: 2.5287e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 68/156 [============>.................] - ETA: 1:18 - loss: 2.4991e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 69/156 [============>.................] - ETA: 1:17 - loss: 2.4838e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 70/156 [============>.................] - ETA: 1:16 - loss: 2.5480e-05 - accuracy: 1.0000\n",
      " 71/156 [============>.................] - ETA: 1:15 - loss: 2.5217e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 72/156 [============>.................] - ETA: 1:14 - loss: 2.5280e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 73/156 [=============>................] - ETA: 1:13 - loss: 2.5296e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 74/156 [=============>................] - ETA: 1:12 - loss: 2.5191e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 75/156 [=============>................] - ETA: 1:11 - loss: 2.5111e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 76/156 [=============>................] - ETA: 1:10 - loss: 2.5111e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 77/156 [=============>................] - ETA: 1:10 - loss: 2.4924e-05 - accuracy: 1.0000\n",
      " 78/156 [==============>...............] - ETA: 1:09 - loss: 2.4757e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 79/156 [==============>...............] - ETA: 1:08 - loss: 2.4738e-05 - accuracy: 1.0000\n",
      " 80/156 [==============>...............] - ETA: 1:07 - loss: 2.4691e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 81/156 [==============>...............] - ETA: 1:06 - loss: 2.4649e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 82/156 [==============>...............] - ETA: 1:05 - loss: 2.4456e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 83/156 [==============>...............] - ETA: 1:05 - loss: 2.4572e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 84/156 [===============>..............] - ETA: 1:04 - loss: 2.4402e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 85/156 [===============>..............] - ETA: 1:03 - loss: 2.4423e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 86/156 [===============>..............] - ETA: 1:02 - loss: 2.4305e-05 - accuracy: 1.0000\n",
      " 87/156 [===============>..............] - ETA: 1:01 - loss: 2.4557e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 88/156 [===============>..............] - ETA: 1:01 - loss: 2.4443e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 89/156 [================>.............] - ETA: 1:00 - loss: 2.4558e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 90/156 [================>.............] - ETA: 59s - loss: 2.4593e-05 - accuracy: 1.0000 \u001b[0m\n",
      "\u001b[34m 91/156 [================>.............] - ETA: 58s - loss: 2.4602e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 92/156 [================>.............] - ETA: 57s - loss: 2.4405e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 93/156 [================>.............] - ETA: 56s - loss: 2.4260e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 94/156 [=================>............] - ETA: 55s - loss: 2.4121e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 95/156 [=================>............] - ETA: 54s - loss: 2.4068e-05 - accuracy: 1.0000\n",
      " 96/156 [=================>............] - ETA: 53s - loss: 2.3954e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 97/156 [=================>............] - ETA: 52s - loss: 2.4043e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 98/156 [=================>............] - ETA: 52s - loss: 2.4129e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 99/156 [==================>...........] - ETA: 51s - loss: 2.4121e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m100/156 [==================>...........] - ETA: 50s - loss: 2.4092e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m101/156 [==================>...........] - ETA: 49s - loss: 2.4256e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m102/156 [==================>...........] - ETA: 48s - loss: 2.4225e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m103/156 [==================>...........] - ETA: 47s - loss: 2.4126e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m104/156 [===================>..........] - ETA: 46s - loss: 2.4010e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m105/156 [===================>..........] - ETA: 45s - loss: 2.3900e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m106/156 [===================>..........] - ETA: 44s - loss: 2.3845e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m107/156 [===================>..........] - ETA: 43s - loss: 2.3773e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m108/156 [===================>..........] - ETA: 42s - loss: 2.3912e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m109/156 [===================>..........] - ETA: 42s - loss: 2.3876e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m110/156 [====================>.........] - ETA: 41s - loss: 2.3774e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m111/156 [====================>.........] - ETA: 40s - loss: 2.3944e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m112/156 [====================>.........] - ETA: 39s - loss: 2.3808e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m113/156 [====================>.........] - ETA: 38s - loss: 2.3902e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m114/156 [====================>.........] - ETA: 37s - loss: 2.4047e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m115/156 [=====================>........] - ETA: 36s - loss: 2.3914e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m116/156 [=====================>........] - ETA: 35s - loss: 2.3806e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m117/156 [=====================>........] - ETA: 34s - loss: 2.3748e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m118/156 [=====================>........] - ETA: 33s - loss: 2.3889e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m119/156 [=====================>........] - ETA: 33s - loss: 2.3820e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m120/156 [======================>.......] - ETA: 32s - loss: 2.3760e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m121/156 [======================>.......] - ETA: 31s - loss: 2.3859e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m122/156 [======================>.......] - ETA: 30s - loss: 2.3851e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m123/156 [======================>.......] - ETA: 29s - loss: 2.3722e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m124/156 [======================>.......] - ETA: 28s - loss: 2.3670e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m125/156 [=======================>......] - ETA: 27s - loss: 2.4090e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m126/156 [=======================>......] - ETA: 26s - loss: 2.4818e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m127/156 [=======================>......] - ETA: 25s - loss: 2.4854e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m128/156 [=======================>......] - ETA: 24s - loss: 2.5542e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m129/156 [=======================>......] - ETA: 24s - loss: 2.5733e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m130/156 [========================>.....] - ETA: 23s - loss: 2.5648e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m131/156 [========================>.....] - ETA: 22s - loss: 2.5687e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m132/156 [========================>.....] - ETA: 21s - loss: 2.5667e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m133/156 [========================>.....] - ETA: 20s - loss: 2.5555e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m134/156 [========================>.....] - ETA: 19s - loss: 2.5453e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m135/156 [========================>.....] - ETA: 18s - loss: 2.5366e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m136/156 [=========================>....] - ETA: 17s - loss: 2.5441e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m137/156 [=========================>....] - ETA: 16s - loss: 2.5348e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m138/156 [=========================>....] - ETA: 16s - loss: 2.5536e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m139/156 [=========================>....] - ETA: 15s - loss: 2.5529e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m140/156 [=========================>....] - ETA: 14s - loss: 2.5510e-05 - accuracy: 1.0000\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m141/156 [==========================>...] - ETA: 13s - loss: 2.5451e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m142/156 [==========================>...] - ETA: 12s - loss: 2.5376e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m143/156 [==========================>...] - ETA: 11s - loss: 2.5376e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m144/156 [==========================>...] - ETA: 10s - loss: 2.5268e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m145/156 [==========================>...] - ETA: 9s - loss: 2.5470e-05 - accuracy: 1.0000 \u001b[0m\n",
      "\u001b[34m146/156 [===========================>..] - ETA: 8s - loss: 2.5364e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m147/156 [===========================>..] - ETA: 8s - loss: 2.5254e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m148/156 [===========================>..] - ETA: 7s - loss: 2.5266e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m149/156 [===========================>..] - ETA: 6s - loss: 2.5321e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m150/156 [===========================>..] - ETA: 5s - loss: 2.5357e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m151/156 [============================>.] - ETA: 4s - loss: 2.5265e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m152/156 [============================>.] - ETA: 3s - loss: 2.5186e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m153/156 [============================>.] - ETA: 2s - loss: 2.5167e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m154/156 [============================>.] - ETA: 1s - loss: 2.5080e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m155/156 [============================>.] - ETA: 0s - loss: 2.5037e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m156/156 [==============================] - 155s 995ms/step - loss: 2.4986e-05 - accuracy: 1.0000 - val_loss: 0.0505 - val_accuracy: 19.0850\u001b[0m\n",
      "\u001b[34mEpoch 4/10\u001b[0m\n",
      "\u001b[34m  1/156 [..............................] - ETA: 2:02 - loss: 2.5433e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m  2/156 [..............................] - ETA: 2:11 - loss: 2.1057e-05 - accuracy: 1.0000\n",
      "  3/156 [..............................] - ETA: 2:09 - loss: 2.1246e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m  4/156 [..............................] - ETA: 2:08 - loss: 3.2144e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m  5/156 [..............................] - ETA: 2:07 - loss: 2.7147e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m  6/156 [>.............................] - ETA: 2:09 - loss: 2.6644e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m  7/156 [>.............................] - ETA: 2:11 - loss: 2.7001e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m  8/156 [>.............................] - ETA: 2:12 - loss: 2.6438e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m  9/156 [>.............................] - ETA: 2:11 - loss: 2.6732e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 10/156 [>.............................] - ETA: 2:10 - loss: 2.5769e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 11/156 [=>............................] - ETA: 2:09 - loss: 2.5991e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 12/156 [=>............................] - ETA: 2:07 - loss: 2.5450e-05 - accuracy: 1.0000\n",
      " 13/156 [=>............................] - ETA: 2:07 - loss: 2.4782e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 14/156 [=>............................] - ETA: 2:05 - loss: 2.4910e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 15/156 [=>............................] - ETA: 2:05 - loss: 2.4195e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 16/156 [==>...........................] - ETA: 2:04 - loss: 2.4154e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 17/156 [==>...........................] - ETA: 2:03 - loss: 2.3163e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 18/156 [==>...........................] - ETA: 2:01 - loss: 2.2163e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 19/156 [==>...........................] - ETA: 2:00 - loss: 2.1709e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 20/156 [==>...........................] - ETA: 2:00 - loss: 2.1583e-05 - accuracy: 1.0000\n",
      " 21/156 [===>..........................] - ETA: 2:00 - loss: 2.1374e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 22/156 [===>..........................] - ETA: 1:58 - loss: 2.1525e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 23/156 [===>..........................] - ETA: 1:57 - loss: 2.1965e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 24/156 [===>..........................] - ETA: 1:56 - loss: 2.5826e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 25/156 [===>..........................] - ETA: 1:55 - loss: 2.6136e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 26/156 [====>.........................] - ETA: 1:54 - loss: 2.7945e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 27/156 [====>.........................] - ETA: 1:54 - loss: 2.7470e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 28/156 [====>.........................] - ETA: 1:53 - loss: 3.3706e-05 - accuracy: 1.0000\n",
      " 29/156 [====>.........................] - ETA: 1:52 - loss: 3.2929e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 30/156 [====>.........................] - ETA: 1:51 - loss: 3.2054e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 31/156 [====>.........................] - ETA: 1:50 - loss: 3.1234e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 32/156 [=====>........................] - ETA: 1:49 - loss: 3.0971e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 33/156 [=====>........................] - ETA: 1:48 - loss: 3.0293e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 34/156 [=====>........................] - ETA: 1:47 - loss: 2.9612e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 35/156 [=====>........................] - ETA: 1:46 - loss: 2.9132e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 36/156 [=====>........................] - ETA: 1:46 - loss: 2.8614e-05 - accuracy: 1.0000\n",
      " 37/156 [======>.......................] - ETA: 1:45 - loss: 2.8048e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 38/156 [======>.......................] - ETA: 1:44 - loss: 2.7922e-05 - accuracy: 1.0000\n",
      " 39/156 [======>.......................] - ETA: 1:43 - loss: 2.9371e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 40/156 [======>.......................] - ETA: 1:42 - loss: 2.9024e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 41/156 [======>.......................] - ETA: 1:41 - loss: 2.8784e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 42/156 [=======>......................] - ETA: 1:41 - loss: 2.8296e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 43/156 [=======>......................] - ETA: 1:40 - loss: 2.7857e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 44/156 [=======>......................] - ETA: 1:40 - loss: 2.7829e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 45/156 [=======>......................] - ETA: 1:40 - loss: 2.7471e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 46/156 [=======>......................] - ETA: 1:39 - loss: 2.7035e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 47/156 [========>.....................] - ETA: 1:39 - loss: 2.6739e-05 - accuracy: 1.0000\n",
      " 48/156 [========>.....................] - ETA: 1:38 - loss: 2.6477e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 49/156 [========>.....................] - ETA: 1:37 - loss: 2.6036e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 50/156 [========>.....................] - ETA: 1:36 - loss: 2.5922e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 51/156 [========>.....................] - ETA: 1:35 - loss: 2.5791e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 52/156 [=========>....................] - ETA: 1:34 - loss: 2.5696e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 53/156 [=========>....................] - ETA: 1:33 - loss: 2.5507e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 54/156 [=========>....................] - ETA: 1:32 - loss: 2.5310e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 55/156 [=========>....................] - ETA: 1:31 - loss: 2.4995e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 56/156 [=========>....................] - ETA: 1:30 - loss: 2.4744e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 57/156 [=========>....................] - ETA: 1:29 - loss: 2.4490e-05 - accuracy: 1.0000\n",
      " 58/156 [==========>...................] - ETA: 1:28 - loss: 2.4257e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 59/156 [==========>...................] - ETA: 1:28 - loss: 2.4156e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 60/156 [==========>...................] - ETA: 1:27 - loss: 2.4151e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 61/156 [==========>...................] - ETA: 1:26 - loss: 2.4051e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 62/156 [==========>...................] - ETA: 1:25 - loss: 2.3787e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 63/156 [===========>..................] - ETA: 1:24 - loss: 2.3502e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 64/156 [===========>..................] - ETA: 1:23 - loss: 2.3369e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 65/156 [===========>..................] - ETA: 1:22 - loss: 2.3348e-05 - accuracy: 1.0000\n",
      " 66/156 [===========>..................] - ETA: 1:21 - loss: 2.3153e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 67/156 [===========>..................] - ETA: 1:20 - loss: 2.2984e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 68/156 [============>.................] - ETA: 1:19 - loss: 2.2842e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 69/156 [============>.................] - ETA: 1:18 - loss: 2.2749e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 70/156 [============>.................] - ETA: 1:17 - loss: 2.2563e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 71/156 [============>.................] - ETA: 1:16 - loss: 2.2469e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 72/156 [============>.................] - ETA: 1:15 - loss: 2.2270e-05 - accuracy: 1.0000\n",
      " 73/156 [=============>................] - ETA: 1:14 - loss: 2.2124e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 74/156 [=============>................] - ETA: 1:13 - loss: 2.2056e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 75/156 [=============>................] - ETA: 1:12 - loss: 2.1961e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 76/156 [=============>................] - ETA: 1:11 - loss: 2.1814e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 77/156 [=============>................] - ETA: 1:10 - loss: 2.1648e-05 - accuracy: 1.0000\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m 78/156 [==============>...............] - ETA: 1:09 - loss: 2.1448e-05 - accuracy: 1.0000\n",
      " 79/156 [==============>...............] - ETA: 1:09 - loss: 2.1335e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 80/156 [==============>...............] - ETA: 1:08 - loss: 2.1124e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 81/156 [==============>...............] - ETA: 1:07 - loss: 2.1043e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 82/156 [==============>...............] - ETA: 1:06 - loss: 2.0945e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 83/156 [==============>...............] - ETA: 1:05 - loss: 2.0776e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 84/156 [===============>..............] - ETA: 1:04 - loss: 2.0719e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 85/156 [===============>..............] - ETA: 1:03 - loss: 2.0531e-05 - accuracy: 1.0000\n",
      " 86/156 [===============>..............] - ETA: 1:02 - loss: 2.0497e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 87/156 [===============>..............] - ETA: 1:01 - loss: 2.0535e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 88/156 [===============>..............] - ETA: 1:00 - loss: 2.0405e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 89/156 [================>.............] - ETA: 59s - loss: 2.0267e-05 - accuracy: 1.0000 \u001b[0m\n",
      "\u001b[34m 90/156 [================>.............] - ETA: 58s - loss: 2.0199e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 91/156 [================>.............] - ETA: 58s - loss: 2.0083e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 92/156 [================>.............] - ETA: 57s - loss: 1.9961e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 93/156 [================>.............] - ETA: 56s - loss: 1.9906e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 94/156 [=================>............] - ETA: 55s - loss: 2.2392e-05 - accuracy: 1.0000\n",
      " 95/156 [=================>............] - ETA: 54s - loss: 2.2220e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 96/156 [=================>............] - ETA: 53s - loss: 2.2281e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 97/156 [=================>............] - ETA: 52s - loss: 2.2146e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 98/156 [=================>............] - ETA: 51s - loss: 2.2036e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 99/156 [==================>...........] - ETA: 50s - loss: 2.1887e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m100/156 [==================>...........] - ETA: 49s - loss: 2.1740e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m101/156 [==================>...........] - ETA: 49s - loss: 2.2062e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m102/156 [==================>...........] - ETA: 48s - loss: 2.1947e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m103/156 [==================>...........] - ETA: 47s - loss: 2.1805e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m104/156 [===================>..........] - ETA: 46s - loss: 2.1818e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m105/156 [===================>..........] - ETA: 45s - loss: 2.1726e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m106/156 [===================>..........] - ETA: 44s - loss: 2.1747e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m107/156 [===================>..........] - ETA: 43s - loss: 2.1600e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m108/156 [===================>..........] - ETA: 42s - loss: 2.1492e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m109/156 [===================>..........] - ETA: 42s - loss: 2.1421e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m110/156 [====================>.........] - ETA: 41s - loss: 2.1295e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m111/156 [====================>.........] - ETA: 40s - loss: 2.1147e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m112/156 [====================>.........] - ETA: 39s - loss: 2.1077e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m113/156 [====================>.........] - ETA: 38s - loss: 2.1048e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m114/156 [====================>.........] - ETA: 37s - loss: 2.1057e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m115/156 [=====================>........] - ETA: 36s - loss: 2.0906e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m116/156 [=====================>........] - ETA: 35s - loss: 2.0855e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m117/156 [=====================>........] - ETA: 35s - loss: 2.0734e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m118/156 [=====================>........] - ETA: 34s - loss: 2.0610e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m119/156 [=====================>........] - ETA: 33s - loss: 2.0667e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m120/156 [======================>.......] - ETA: 32s - loss: 2.0577e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m121/156 [======================>.......] - ETA: 31s - loss: 2.0555e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m122/156 [======================>.......] - ETA: 30s - loss: 2.0447e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m123/156 [======================>.......] - ETA: 29s - loss: 2.0538e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m124/156 [======================>.......] - ETA: 28s - loss: 2.0432e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m125/156 [=======================>......] - ETA: 27s - loss: 2.0404e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m126/156 [=======================>......] - ETA: 26s - loss: 2.0315e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m127/156 [=======================>......] - ETA: 26s - loss: 2.0297e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m128/156 [=======================>......] - ETA: 25s - loss: 2.0259e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m129/156 [=======================>......] - ETA: 24s - loss: 2.0366e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m130/156 [========================>.....] - ETA: 23s - loss: 2.0290e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m131/156 [========================>.....] - ETA: 22s - loss: 2.0184e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m132/156 [========================>.....] - ETA: 21s - loss: 2.0118e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m133/156 [========================>.....] - ETA: 20s - loss: 2.0024e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m134/156 [========================>.....] - ETA: 19s - loss: 1.9907e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m135/156 [========================>.....] - ETA: 18s - loss: 1.9865e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m136/156 [=========================>....] - ETA: 17s - loss: 1.9873e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m137/156 [=========================>....] - ETA: 16s - loss: 1.9759e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m138/156 [=========================>....] - ETA: 16s - loss: 1.9695e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m139/156 [=========================>....] - ETA: 15s - loss: 1.9600e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m140/156 [=========================>....] - ETA: 14s - loss: 1.9511e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m141/156 [==========================>...] - ETA: 13s - loss: 1.9437e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m142/156 [==========================>...] - ETA: 12s - loss: 1.9377e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m143/156 [==========================>...] - ETA: 11s - loss: 1.9453e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m144/156 [==========================>...] - ETA: 10s - loss: 1.9459e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m145/156 [==========================>...] - ETA: 9s - loss: 1.9418e-05 - accuracy: 1.0000 \u001b[0m\n",
      "\u001b[34m146/156 [===========================>..] - ETA: 8s - loss: 1.9402e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m147/156 [===========================>..] - ETA: 8s - loss: 1.9394e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m148/156 [===========================>..] - ETA: 7s - loss: 1.9324e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m149/156 [===========================>..] - ETA: 6s - loss: 1.9338e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m150/156 [===========================>..] - ETA: 5s - loss: 1.9266e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m151/156 [============================>.] - ETA: 4s - loss: 1.9185e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m152/156 [============================>.] - ETA: 3s - loss: 1.9108e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m153/156 [============================>.] - ETA: 2s - loss: 1.9046e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m154/156 [============================>.] - ETA: 1s - loss: 1.8975e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m155/156 [============================>.] - ETA: 0s - loss: 1.8926e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m156/156 [==============================] - 155s 993ms/step - loss: 1.9022e-05 - accuracy: 1.0000 - val_loss: 0.0542 - val_accuracy: 20.1592\u001b[0m\n",
      "\u001b[34mEpoch 5/10\u001b[0m\n",
      "\u001b[34m  1/156 [..............................] - ETA: 2:26 - loss: 1.1096e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m  2/156 [..............................] - ETA: 2:49 - loss: 1.0562e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m  3/156 [..............................] - ETA: 2:46 - loss: 9.7605e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m  4/156 [..............................] - ETA: 2:43 - loss: 1.1195e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m  5/156 [..............................] - ETA: 2:35 - loss: 9.8050e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m  6/156 [>.............................] - ETA: 2:30 - loss: 9.4079e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m  7/156 [>.............................] - ETA: 2:25 - loss: 8.5465e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m  8/156 [>.............................] - ETA: 2:21 - loss: 9.8969e-06 - accuracy: 1.0000\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m  9/156 [>.............................] - ETA: 2:20 - loss: 9.3393e-06 - accuracy: 1.0000\n",
      " 10/156 [>.............................] - ETA: 2:18 - loss: 9.0368e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 11/156 [=>............................] - ETA: 2:16 - loss: 8.8927e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 12/156 [=>............................] - ETA: 2:14 - loss: 1.3007e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 13/156 [=>............................] - ETA: 2:14 - loss: 1.3340e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 14/156 [=>............................] - ETA: 2:12 - loss: 1.3074e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 15/156 [=>............................] - ETA: 2:11 - loss: 1.3218e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 16/156 [==>...........................] - ETA: 2:09 - loss: 1.3608e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 17/156 [==>...........................] - ETA: 2:08 - loss: 1.5399e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 18/156 [==>...........................] - ETA: 2:08 - loss: 1.5069e-05 - accuracy: 1.0000\n",
      " 19/156 [==>...........................] - ETA: 2:06 - loss: 1.4512e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 20/156 [==>...........................] - ETA: 2:05 - loss: 1.4003e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 21/156 [===>..........................] - ETA: 2:04 - loss: 1.3900e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 22/156 [===>..........................] - ETA: 2:02 - loss: 1.4523e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 23/156 [===>..........................] - ETA: 2:01 - loss: 1.4335e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 24/156 [===>..........................] - ETA: 1:59 - loss: 1.4263e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 25/156 [===>..........................] - ETA: 1:58 - loss: 1.4197e-05 - accuracy: 1.0000\n",
      " 26/156 [====>.........................] - ETA: 1:57 - loss: 1.3802e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 27/156 [====>.........................] - ETA: 1:56 - loss: 1.3648e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 28/156 [====>.........................] - ETA: 1:55 - loss: 1.3598e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 29/156 [====>.........................] - ETA: 1:54 - loss: 1.3483e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 30/156 [====>.........................] - ETA: 1:53 - loss: 1.3322e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 31/156 [====>.........................] - ETA: 1:52 - loss: 1.4694e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 32/156 [=====>........................] - ETA: 1:51 - loss: 1.4681e-05 - accuracy: 1.0000\n",
      " 33/156 [=====>........................] - ETA: 1:50 - loss: 1.4397e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 34/156 [=====>........................] - ETA: 1:49 - loss: 1.4260e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 35/156 [=====>........................] - ETA: 1:48 - loss: 1.4055e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 36/156 [=====>........................] - ETA: 1:46 - loss: 1.3812e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 37/156 [======>.......................] - ETA: 1:46 - loss: 1.3661e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 38/156 [======>.......................] - ETA: 1:45 - loss: 1.3778e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 39/156 [======>.......................] - ETA: 1:44 - loss: 1.4070e-05 - accuracy: 1.0000\n",
      " 40/156 [======>.......................] - ETA: 1:43 - loss: 1.4236e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 41/156 [======>.......................] - ETA: 1:42 - loss: 1.4044e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 42/156 [=======>......................] - ETA: 1:41 - loss: 1.4067e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 43/156 [=======>......................] - ETA: 1:40 - loss: 1.3876e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 44/156 [=======>......................] - ETA: 1:39 - loss: 1.3654e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 45/156 [=======>......................] - ETA: 1:38 - loss: 1.3708e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 46/156 [=======>......................] - ETA: 1:37 - loss: 1.3832e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 47/156 [========>.....................] - ETA: 1:37 - loss: 1.3828e-05 - accuracy: 1.0000\n",
      " 48/156 [========>.....................] - ETA: 1:36 - loss: 1.3718e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 49/156 [========>.....................] - ETA: 1:35 - loss: 1.3761e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 50/156 [========>.....................] - ETA: 1:34 - loss: 1.3781e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 51/156 [========>.....................] - ETA: 1:33 - loss: 1.3710e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 52/156 [=========>....................] - ETA: 1:32 - loss: 1.3668e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 53/156 [=========>....................] - ETA: 1:31 - loss: 1.3632e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 54/156 [=========>....................] - ETA: 1:30 - loss: 1.3511e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 55/156 [=========>....................] - ETA: 1:29 - loss: 1.3325e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 56/156 [=========>....................] - ETA: 1:29 - loss: 1.3201e-05 - accuracy: 1.0000\n",
      " 57/156 [=========>....................] - ETA: 1:28 - loss: 1.3156e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 58/156 [==========>...................] - ETA: 1:27 - loss: 1.3069e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 59/156 [==========>...................] - ETA: 1:26 - loss: 1.3694e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 60/156 [==========>...................] - ETA: 1:25 - loss: 1.3709e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 61/156 [==========>...................] - ETA: 1:24 - loss: 1.3589e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 62/156 [==========>...................] - ETA: 1:23 - loss: 1.3430e-05 - accuracy: 1.0000\n",
      " 63/156 [===========>..................] - ETA: 1:22 - loss: 1.3628e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 64/156 [===========>..................] - ETA: 1:21 - loss: 1.3486e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 65/156 [===========>..................] - ETA: 1:20 - loss: 1.3375e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 66/156 [===========>..................] - ETA: 1:19 - loss: 1.3443e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 67/156 [===========>..................] - ETA: 1:19 - loss: 1.3379e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 68/156 [============>.................] - ETA: 1:18 - loss: 1.3248e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 69/156 [============>.................] - ETA: 1:17 - loss: 1.3136e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 70/156 [============>.................] - ETA: 1:16 - loss: 1.3788e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 71/156 [============>.................] - ETA: 1:16 - loss: 1.3822e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 72/156 [============>.................] - ETA: 1:15 - loss: 1.3702e-05 - accuracy: 1.0000\n",
      " 73/156 [=============>................] - ETA: 1:14 - loss: 1.3996e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 74/156 [=============>................] - ETA: 1:13 - loss: 1.3901e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 75/156 [=============>................] - ETA: 1:12 - loss: 1.3888e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 76/156 [=============>................] - ETA: 1:11 - loss: 1.3815e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 77/156 [=============>................] - ETA: 1:11 - loss: 1.3778e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 78/156 [==============>...............] - ETA: 1:10 - loss: 1.3664e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 79/156 [==============>...............] - ETA: 1:09 - loss: 1.3675e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 80/156 [==============>...............] - ETA: 1:08 - loss: 1.3724e-05 - accuracy: 1.0000\n",
      " 81/156 [==============>...............] - ETA: 1:07 - loss: 1.3748e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 82/156 [==============>...............] - ETA: 1:06 - loss: 1.3652e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 83/156 [==============>...............] - ETA: 1:05 - loss: 1.3609e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 84/156 [===============>..............] - ETA: 1:04 - loss: 1.3778e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 85/156 [===============>..............] - ETA: 1:03 - loss: 1.3650e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 86/156 [===============>..............] - ETA: 1:02 - loss: 1.3654e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 87/156 [===============>..............] - ETA: 1:02 - loss: 1.3604e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 88/156 [===============>..............] - ETA: 1:01 - loss: 1.3679e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 89/156 [================>.............] - ETA: 1:00 - loss: 1.3863e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 90/156 [================>.............] - ETA: 59s - loss: 1.3841e-05 - accuracy: 1.0000 \n",
      " 91/156 [================>.............] - ETA: 58s - loss: 1.3828e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 92/156 [================>.............] - ETA: 57s - loss: 1.3766e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 93/156 [================>.............] - ETA: 56s - loss: 1.3992e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 94/156 [=================>............] - ETA: 55s - loss: 1.3958e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 95/156 [=================>............] - ETA: 54s - loss: 1.3860e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 96/156 [=================>............] - ETA: 53s - loss: 1.3790e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 97/156 [=================>............] - ETA: 52s - loss: 1.3720e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 98/156 [=================>............] - ETA: 52s - loss: 1.3680e-05 - accuracy: 1.0000\n",
      " 99/156 [==================>...........] - ETA: 51s - loss: 1.3679e-05 - accuracy: 1.0000\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m100/156 [==================>...........] - ETA: 50s - loss: 1.3652e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m101/156 [==================>...........] - ETA: 49s - loss: 1.3625e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m102/156 [==================>...........] - ETA: 48s - loss: 1.3575e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m103/156 [==================>...........] - ETA: 47s - loss: 1.3487e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m104/156 [===================>..........] - ETA: 46s - loss: 1.3545e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m105/156 [===================>..........] - ETA: 45s - loss: 1.3651e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m106/156 [===================>..........] - ETA: 44s - loss: 1.3584e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m107/156 [===================>..........] - ETA: 43s - loss: 1.3493e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m108/156 [===================>..........] - ETA: 43s - loss: 1.3425e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m109/156 [===================>..........] - ETA: 42s - loss: 1.3333e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m110/156 [====================>.........] - ETA: 41s - loss: 1.3326e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m111/156 [====================>.........] - ETA: 40s - loss: 1.3326e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m112/156 [====================>.........] - ETA: 39s - loss: 1.3362e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m113/156 [====================>.........] - ETA: 38s - loss: 1.3325e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m114/156 [====================>.........] - ETA: 37s - loss: 1.3301e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m115/156 [=====================>........] - ETA: 36s - loss: 1.3248e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m116/156 [=====================>........] - ETA: 35s - loss: 1.3171e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m117/156 [=====================>........] - ETA: 34s - loss: 1.3171e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m118/156 [=====================>........] - ETA: 34s - loss: 1.3149e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m119/156 [=====================>........] - ETA: 33s - loss: 1.3094e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m120/156 [======================>.......] - ETA: 32s - loss: 1.3039e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m121/156 [======================>.......] - ETA: 31s - loss: 1.3031e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m122/156 [======================>.......] - ETA: 30s - loss: 1.3043e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m123/156 [======================>.......] - ETA: 29s - loss: 1.2972e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m124/156 [======================>.......] - ETA: 28s - loss: 1.2897e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m125/156 [=======================>......] - ETA: 27s - loss: 1.2857e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m126/156 [=======================>......] - ETA: 26s - loss: 1.3019e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m127/156 [=======================>......] - ETA: 25s - loss: 1.2991e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m128/156 [=======================>......] - ETA: 25s - loss: 1.2931e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m129/156 [=======================>......] - ETA: 24s - loss: 1.2850e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m130/156 [========================>.....] - ETA: 23s - loss: 1.2856e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m131/156 [========================>.....] - ETA: 22s - loss: 1.2813e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m132/156 [========================>.....] - ETA: 21s - loss: 1.2828e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m133/156 [========================>.....] - ETA: 20s - loss: 1.2755e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m134/156 [========================>.....] - ETA: 19s - loss: 1.2711e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m135/156 [========================>.....] - ETA: 18s - loss: 1.2652e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m136/156 [=========================>....] - ETA: 17s - loss: 1.2578e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m137/156 [=========================>....] - ETA: 17s - loss: 1.2520e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m138/156 [=========================>....] - ETA: 16s - loss: 1.2463e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m139/156 [=========================>....] - ETA: 15s - loss: 1.2444e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m140/156 [=========================>....] - ETA: 14s - loss: 1.2454e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m141/156 [==========================>...] - ETA: 13s - loss: 1.2467e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m142/156 [==========================>...] - ETA: 12s - loss: 1.2412e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m143/156 [==========================>...] - ETA: 11s - loss: 1.2380e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m144/156 [==========================>...] - ETA: 10s - loss: 1.2393e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m145/156 [==========================>...] - ETA: 9s - loss: 1.2361e-05 - accuracy: 1.0000 \u001b[0m\n",
      "\u001b[34m146/156 [===========================>..] - ETA: 9s - loss: 1.2313e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m147/156 [===========================>..] - ETA: 8s - loss: 1.2296e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m148/156 [===========================>..] - ETA: 7s - loss: 1.2233e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m149/156 [===========================>..] - ETA: 6s - loss: 1.2298e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m150/156 [===========================>..] - ETA: 5s - loss: 1.2328e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m151/156 [============================>.] - ETA: 4s - loss: 1.2281e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m152/156 [============================>.] - ETA: 3s - loss: 1.2264e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m153/156 [============================>.] - ETA: 2s - loss: 1.2243e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m154/156 [============================>.] - ETA: 1s - loss: 1.2307e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m155/156 [============================>.] - ETA: 0s - loss: 1.2260e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m156/156 [==============================] - 156s 1s/step - loss: 1.2303e-05 - accuracy: 1.0000 - val_loss: 0.0586 - val_accuracy: 21.4052\u001b[0m\n",
      "\u001b[34mEpoch 6/10\u001b[0m\n",
      "\u001b[34m  1/156 [..............................] - ETA: 2:11 - loss: 4.5633e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m  2/156 [..............................] - ETA: 2:12 - loss: 2.5245e-05 - accuracy: 1.0000\n",
      "  3/156 [..............................] - ETA: 2:11 - loss: 1.9757e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m  4/156 [..............................] - ETA: 2:10 - loss: 1.5991e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m  5/156 [..............................] - ETA: 2:07 - loss: 1.4212e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m  6/156 [>.............................] - ETA: 2:08 - loss: 1.2687e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m  7/156 [>.............................] - ETA: 2:09 - loss: 1.1781e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m  8/156 [>.............................] - ETA: 2:08 - loss: 1.1097e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m  9/156 [>.............................] - ETA: 2:07 - loss: 1.0393e-05 - accuracy: 1.0000\n",
      " 10/156 [>.............................] - ETA: 2:06 - loss: 1.1095e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 11/156 [=>............................] - ETA: 2:05 - loss: 1.0884e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 12/156 [=>............................] - ETA: 2:04 - loss: 1.0828e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 13/156 [=>............................] - ETA: 2:03 - loss: 1.0246e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 14/156 [=>............................] - ETA: 2:02 - loss: 1.0191e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 15/156 [=>............................] - ETA: 2:03 - loss: 9.9432e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 16/156 [==>...........................] - ETA: 2:02 - loss: 1.0054e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 17/156 [==>...........................] - ETA: 2:02 - loss: 1.0007e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 18/156 [==>...........................] - ETA: 2:01 - loss: 9.9165e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 19/156 [==>...........................] - ETA: 2:00 - loss: 9.5451e-06 - accuracy: 1.0000\n",
      " 20/156 [==>...........................] - ETA: 1:59 - loss: 9.5836e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 21/156 [===>..........................] - ETA: 1:58 - loss: 9.5250e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 22/156 [===>..........................] - ETA: 1:57 - loss: 9.2420e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 23/156 [===>..........................] - ETA: 1:56 - loss: 9.0406e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 24/156 [===>..........................] - ETA: 1:55 - loss: 8.9640e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 25/156 [===>..........................] - ETA: 1:54 - loss: 8.8748e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 26/156 [====>.........................] - ETA: 1:54 - loss: 8.8612e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 27/156 [====>.........................] - ETA: 1:54 - loss: 9.1566e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 28/156 [====>.........................] - ETA: 1:54 - loss: 8.9917e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 29/156 [====>.........................] - ETA: 1:54 - loss: 9.1229e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 30/156 [====>.........................] - ETA: 1:55 - loss: 9.0839e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 31/156 [====>.........................] - ETA: 1:54 - loss: 8.9268e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 32/156 [=====>........................] - ETA: 1:53 - loss: 8.8416e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 33/156 [=====>........................] - ETA: 1:52 - loss: 8.8246e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 34/156 [=====>........................] - ETA: 1:51 - loss: 8.9175e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 35/156 [=====>........................] - ETA: 1:50 - loss: 8.9939e-06 - accuracy: 1.0000\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m 36/156 [=====>........................] - ETA: 1:49 - loss: 8.9106e-06 - accuracy: 1.0000\n",
      " 37/156 [======>.......................] - ETA: 1:48 - loss: 9.0953e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 38/156 [======>.......................] - ETA: 1:46 - loss: 9.3353e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 39/156 [======>.......................] - ETA: 1:46 - loss: 9.2952e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 40/156 [======>.......................] - ETA: 1:45 - loss: 9.1885e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 41/156 [======>.......................] - ETA: 1:44 - loss: 1.0598e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 42/156 [=======>......................] - ETA: 1:43 - loss: 1.0627e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 43/156 [=======>......................] - ETA: 1:41 - loss: 1.0551e-05 - accuracy: 1.0000\n",
      " 44/156 [=======>......................] - ETA: 1:40 - loss: 1.0382e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 45/156 [=======>......................] - ETA: 1:39 - loss: 1.0388e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 46/156 [=======>......................] - ETA: 1:38 - loss: 1.0493e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 47/156 [========>.....................] - ETA: 1:37 - loss: 1.0539e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 48/156 [========>.....................] - ETA: 1:37 - loss: 1.0733e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 49/156 [========>.....................] - ETA: 1:36 - loss: 1.0988e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 50/156 [========>.....................] - ETA: 1:35 - loss: 1.0805e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 51/156 [========>.....................] - ETA: 1:34 - loss: 1.0723e-05 - accuracy: 1.0000\n",
      " 52/156 [=========>....................] - ETA: 1:33 - loss: 1.0612e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 53/156 [=========>....................] - ETA: 1:32 - loss: 1.0552e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 54/156 [=========>....................] - ETA: 1:31 - loss: 1.0492e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 55/156 [=========>....................] - ETA: 1:30 - loss: 1.1572e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 56/156 [=========>....................] - ETA: 1:29 - loss: 1.1523e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 57/156 [=========>....................] - ETA: 1:28 - loss: 1.1395e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 58/156 [==========>...................] - ETA: 1:27 - loss: 1.1271e-05 - accuracy: 1.0000\n",
      " 59/156 [==========>...................] - ETA: 1:26 - loss: 1.1230e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 60/156 [==========>...................] - ETA: 1:25 - loss: 1.1176e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 61/156 [==========>...................] - ETA: 1:24 - loss: 1.1044e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 62/156 [==========>...................] - ETA: 1:23 - loss: 1.0931e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 63/156 [===========>..................] - ETA: 1:22 - loss: 1.0844e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 64/156 [===========>..................] - ETA: 1:21 - loss: 1.0761e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 65/156 [===========>..................] - ETA: 1:20 - loss: 1.0687e-05 - accuracy: 1.0000\n",
      " 66/156 [===========>..................] - ETA: 1:20 - loss: 1.0694e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 67/156 [===========>..................] - ETA: 1:19 - loss: 1.0613e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 68/156 [============>.................] - ETA: 1:18 - loss: 1.0515e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 69/156 [============>.................] - ETA: 1:17 - loss: 1.0448e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 70/156 [============>.................] - ETA: 1:16 - loss: 1.0319e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 71/156 [============>.................] - ETA: 1:15 - loss: 1.0215e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 72/156 [============>.................] - ETA: 1:14 - loss: 1.0379e-05 - accuracy: 1.0000\n",
      " 73/156 [=============>................] - ETA: 1:13 - loss: 1.0330e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 74/156 [=============>................] - ETA: 1:12 - loss: 1.0269e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 75/156 [=============>................] - ETA: 1:11 - loss: 1.0196e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 76/156 [=============>................] - ETA: 1:10 - loss: 1.0115e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 77/156 [=============>................] - ETA: 1:09 - loss: 1.0023e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 78/156 [==============>...............] - ETA: 1:08 - loss: 1.0032e-05 - accuracy: 1.0000\n",
      " 79/156 [==============>...............] - ETA: 1:08 - loss: 9.9254e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 80/156 [==============>...............] - ETA: 1:07 - loss: 9.9384e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 81/156 [==============>...............] - ETA: 1:06 - loss: 9.8834e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 82/156 [==============>...............] - ETA: 1:05 - loss: 9.8117e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 83/156 [==============>...............] - ETA: 1:04 - loss: 9.8166e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 84/156 [===============>..............] - ETA: 1:03 - loss: 9.7657e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 85/156 [===============>..............] - ETA: 1:02 - loss: 9.7137e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 86/156 [===============>..............] - ETA: 1:01 - loss: 9.7110e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 87/156 [===============>..............] - ETA: 1:00 - loss: 9.7642e-06 - accuracy: 1.0000\n",
      " 88/156 [===============>..............] - ETA: 1:00 - loss: 9.6821e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 89/156 [================>.............] - ETA: 59s - loss: 9.6329e-06 - accuracy: 1.0000 \u001b[0m\n",
      "\u001b[34m 90/156 [================>.............] - ETA: 58s - loss: 9.6187e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 91/156 [================>.............] - ETA: 57s - loss: 9.5532e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 92/156 [================>.............] - ETA: 56s - loss: 9.4858e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 93/156 [================>.............] - ETA: 55s - loss: 9.4816e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 94/156 [=================>............] - ETA: 54s - loss: 9.5478e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 95/156 [=================>............] - ETA: 54s - loss: 9.4855e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 96/156 [=================>............] - ETA: 53s - loss: 9.4402e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 97/156 [=================>............] - ETA: 52s - loss: 9.5378e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 98/156 [=================>............] - ETA: 51s - loss: 9.4710e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 99/156 [==================>...........] - ETA: 50s - loss: 9.5400e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m100/156 [==================>...........] - ETA: 50s - loss: 9.5970e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m101/156 [==================>...........] - ETA: 49s - loss: 9.7440e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m102/156 [==================>...........] - ETA: 48s - loss: 9.7295e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m103/156 [==================>...........] - ETA: 47s - loss: 9.6880e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m104/156 [===================>..........] - ETA: 46s - loss: 9.7054e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m105/156 [===================>..........] - ETA: 45s - loss: 9.7331e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m106/156 [===================>..........] - ETA: 44s - loss: 9.7016e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m107/156 [===================>..........] - ETA: 43s - loss: 9.6408e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m108/156 [===================>..........] - ETA: 42s - loss: 9.5819e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m109/156 [===================>..........] - ETA: 41s - loss: 9.6593e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m110/156 [====================>.........] - ETA: 41s - loss: 9.6328e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m111/156 [====================>.........] - ETA: 40s - loss: 9.6068e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m112/156 [====================>.........] - ETA: 39s - loss: 9.6445e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m113/156 [====================>.........] - ETA: 38s - loss: 9.6090e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m114/156 [====================>.........] - ETA: 37s - loss: 9.5509e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m115/156 [=====================>........] - ETA: 36s - loss: 9.4944e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m116/156 [=====================>........] - ETA: 35s - loss: 9.4775e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m117/156 [=====================>........] - ETA: 34s - loss: 9.4318e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m118/156 [=====================>........] - ETA: 33s - loss: 9.4013e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m119/156 [=====================>........] - ETA: 32s - loss: 9.3479e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m120/156 [======================>.......] - ETA: 32s - loss: 9.3308e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m121/156 [======================>.......] - ETA: 31s - loss: 9.2884e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m122/156 [======================>.......] - ETA: 30s - loss: 9.2449e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m123/156 [======================>.......] - ETA: 29s - loss: 9.1938e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m124/156 [======================>.......] - ETA: 28s - loss: 9.2143e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m125/156 [=======================>......] - ETA: 27s - loss: 9.1656e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m126/156 [=======================>......] - ETA: 26s - loss: 9.1521e-06 - accuracy: 1.0000\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m127/156 [=======================>......] - ETA: 25s - loss: 9.1014e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m128/156 [=======================>......] - ETA: 24s - loss: 9.0601e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m129/156 [=======================>......] - ETA: 24s - loss: 9.0490e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m130/156 [========================>.....] - ETA: 23s - loss: 9.0205e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m131/156 [========================>.....] - ETA: 22s - loss: 8.9999e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m132/156 [========================>.....] - ETA: 21s - loss: 9.0292e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m133/156 [========================>.....] - ETA: 20s - loss: 8.9787e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m134/156 [========================>.....] - ETA: 19s - loss: 8.9492e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m135/156 [========================>.....] - ETA: 18s - loss: 8.9057e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m136/156 [=========================>....] - ETA: 17s - loss: 8.9333e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m137/156 [=========================>....] - ETA: 16s - loss: 8.8903e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m138/156 [=========================>....] - ETA: 16s - loss: 8.8432e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m139/156 [=========================>....] - ETA: 15s - loss: 8.8098e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m140/156 [=========================>....] - ETA: 14s - loss: 8.7901e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m141/156 [==========================>...] - ETA: 13s - loss: 8.7762e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m142/156 [==========================>...] - ETA: 12s - loss: 8.7451e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m143/156 [==========================>...] - ETA: 11s - loss: 8.7789e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m144/156 [==========================>...] - ETA: 10s - loss: 8.7491e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m145/156 [==========================>...] - ETA: 9s - loss: 8.7661e-06 - accuracy: 1.0000 \u001b[0m\n",
      "\u001b[34m146/156 [===========================>..] - ETA: 8s - loss: 8.7451e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m147/156 [===========================>..] - ETA: 7s - loss: 8.8341e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m148/156 [===========================>..] - ETA: 7s - loss: 8.8005e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m149/156 [===========================>..] - ETA: 6s - loss: 8.8637e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m150/156 [===========================>..] - ETA: 5s - loss: 8.8176e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m151/156 [============================>.] - ETA: 4s - loss: 8.7760e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m152/156 [============================>.] - ETA: 3s - loss: 8.7386e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m153/156 [============================>.] - ETA: 2s - loss: 8.7102e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m154/156 [============================>.] - ETA: 1s - loss: 8.6810e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m155/156 [============================>.] - ETA: 0s - loss: 8.6467e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m156/156 [==============================] - 155s 992ms/step - loss: 8.6404e-06 - accuracy: 1.0000 - val_loss: 0.0508 - val_accuracy: 21.2744\u001b[0m\n",
      "\u001b[34mEpoch 7/10\u001b[0m\n",
      "\u001b[34m  1/156 [..............................] - ETA: 2:20 - loss: 6.9935e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m  2/156 [..............................] - ETA: 2:14 - loss: 7.0234e-06 - accuracy: 1.0000\n",
      "  3/156 [..............................] - ETA: 2:13 - loss: 1.1176e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m  4/156 [..............................] - ETA: 2:13 - loss: 9.5472e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m  5/156 [..............................] - ETA: 2:13 - loss: 9.0039e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m  6/156 [>.............................] - ETA: 2:12 - loss: 9.5153e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m  7/156 [>.............................] - ETA: 2:10 - loss: 9.4579e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m  8/156 [>.............................] - ETA: 2:08 - loss: 8.9058e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m  9/156 [>.............................] - ETA: 2:08 - loss: 9.8761e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 10/156 [>.............................] - ETA: 2:07 - loss: 1.0002e-05 - accuracy: 1.0000\n",
      " 11/156 [=>............................] - ETA: 2:06 - loss: 9.6475e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 12/156 [=>............................] - ETA: 2:06 - loss: 9.2537e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 13/156 [=>............................] - ETA: 2:06 - loss: 8.9128e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 14/156 [=>............................] - ETA: 2:06 - loss: 8.6577e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 15/156 [=>............................] - ETA: 2:05 - loss: 8.2885e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 16/156 [==>...........................] - ETA: 2:04 - loss: 8.0891e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 17/156 [==>...........................] - ETA: 2:03 - loss: 7.9832e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 18/156 [==>...........................] - ETA: 2:02 - loss: 8.8796e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 19/156 [==>...........................] - ETA: 2:01 - loss: 1.4058e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 20/156 [==>...........................] - ETA: 2:00 - loss: 1.3491e-05 - accuracy: 1.0000\n",
      " 21/156 [===>..........................] - ETA: 1:59 - loss: 1.2966e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 22/156 [===>..........................] - ETA: 1:58 - loss: 1.2913e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 23/156 [===>..........................] - ETA: 1:57 - loss: 1.2558e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 24/156 [===>..........................] - ETA: 1:55 - loss: 1.2190e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 25/156 [===>..........................] - ETA: 1:54 - loss: 1.3878e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 26/156 [====>.........................] - ETA: 1:53 - loss: 1.3495e-05 - accuracy: 1.0000\n",
      " 27/156 [====>.........................] - ETA: 1:53 - loss: 1.3144e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 28/156 [====>.........................] - ETA: 1:52 - loss: 1.3018e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 29/156 [====>.........................] - ETA: 1:51 - loss: 1.2748e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 30/156 [====>.........................] - ETA: 1:50 - loss: 1.2583e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 31/156 [====>.........................] - ETA: 1:49 - loss: 1.2507e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 32/156 [=====>........................] - ETA: 1:48 - loss: 1.2281e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 33/156 [=====>........................] - ETA: 1:48 - loss: 1.1992e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 34/156 [=====>........................] - ETA: 1:47 - loss: 1.1759e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 35/156 [=====>........................] - ETA: 1:46 - loss: 1.1575e-05 - accuracy: 1.0000\n",
      " 36/156 [=====>........................] - ETA: 1:45 - loss: 1.1336e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 37/156 [======>.......................] - ETA: 1:44 - loss: 1.1189e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 38/156 [======>.......................] - ETA: 1:44 - loss: 1.1067e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 39/156 [======>.......................] - ETA: 1:43 - loss: 1.0835e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 40/156 [======>.......................] - ETA: 1:42 - loss: 1.1412e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 41/156 [======>.......................] - ETA: 1:41 - loss: 1.1239e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 42/156 [=======>......................] - ETA: 1:40 - loss: 1.1143e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 43/156 [=======>......................] - ETA: 1:39 - loss: 1.0991e-05 - accuracy: 1.0000\n",
      " 44/156 [=======>......................] - ETA: 1:38 - loss: 1.0921e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 45/156 [=======>......................] - ETA: 1:37 - loss: 1.0809e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 46/156 [=======>......................] - ETA: 1:36 - loss: 1.0720e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 47/156 [========>.....................] - ETA: 1:35 - loss: 1.0608e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 48/156 [========>.....................] - ETA: 1:35 - loss: 1.0501e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 49/156 [========>.....................] - ETA: 1:34 - loss: 1.0398e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 50/156 [========>.....................] - ETA: 1:33 - loss: 1.0359e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 51/156 [========>.....................] - ETA: 1:32 - loss: 1.0205e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 52/156 [=========>....................] - ETA: 1:31 - loss: 1.0058e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 53/156 [=========>....................] - ETA: 1:31 - loss: 9.9880e-06 - accuracy: 1.0000\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m 54/156 [=========>....................] - ETA: 1:30 - loss: 1.0094e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 55/156 [=========>....................] - ETA: 1:29 - loss: 1.0071e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 56/156 [=========>....................] - ETA: 1:29 - loss: 1.0007e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 57/156 [=========>....................] - ETA: 1:29 - loss: 9.8945e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 58/156 [==========>...................] - ETA: 1:28 - loss: 9.7760e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 59/156 [==========>...................] - ETA: 1:27 - loss: 9.7350e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 60/156 [==========>...................] - ETA: 1:26 - loss: 9.7749e-06 - accuracy: 1.0000\n",
      " 61/156 [==========>...................] - ETA: 1:25 - loss: 9.7171e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 62/156 [==========>...................] - ETA: 1:24 - loss: 9.6225e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 63/156 [===========>..................] - ETA: 1:23 - loss: 9.5098e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 64/156 [===========>..................] - ETA: 1:22 - loss: 9.5416e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 65/156 [===========>..................] - ETA: 1:21 - loss: 9.4704e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 66/156 [===========>..................] - ETA: 1:20 - loss: 9.3812e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 67/156 [===========>..................] - ETA: 1:19 - loss: 9.2846e-06 - accuracy: 1.0000\n",
      " 68/156 [============>.................] - ETA: 1:18 - loss: 9.2444e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 69/156 [============>.................] - ETA: 1:17 - loss: 9.1822e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 70/156 [============>.................] - ETA: 1:16 - loss: 9.1028e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 71/156 [============>.................] - ETA: 1:15 - loss: 9.0497e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 72/156 [============>.................] - ETA: 1:15 - loss: 9.0086e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 73/156 [=============>................] - ETA: 1:14 - loss: 8.9410e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 74/156 [=============>................] - ETA: 1:13 - loss: 8.9170e-06 - accuracy: 1.0000\n",
      " 75/156 [=============>................] - ETA: 1:12 - loss: 8.8394e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 76/156 [=============>................] - ETA: 1:11 - loss: 8.7550e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 77/156 [=============>................] - ETA: 1:10 - loss: 8.6838e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 78/156 [==============>...............] - ETA: 1:09 - loss: 8.7585e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 79/156 [==============>...............] - ETA: 1:08 - loss: 8.7852e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 80/156 [==============>...............] - ETA: 1:07 - loss: 8.7781e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 81/156 [==============>...............] - ETA: 1:07 - loss: 8.7712e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 82/156 [==============>...............] - ETA: 1:06 - loss: 8.7321e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 83/156 [==============>...............] - ETA: 1:05 - loss: 8.6778e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 84/156 [===============>..............] - ETA: 1:04 - loss: 8.6134e-06 - accuracy: 1.0000\n",
      " 85/156 [===============>..............] - ETA: 1:03 - loss: 8.5547e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 86/156 [===============>..............] - ETA: 1:02 - loss: 8.4866e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 87/156 [===============>..............] - ETA: 1:01 - loss: 8.5849e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 88/156 [===============>..............] - ETA: 1:00 - loss: 8.5318e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 89/156 [================>.............] - ETA: 59s - loss: 8.5412e-06 - accuracy: 1.0000 \u001b[0m\n",
      "\u001b[34m 90/156 [================>.............] - ETA: 58s - loss: 8.5537e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 91/156 [================>.............] - ETA: 57s - loss: 8.5303e-06 - accuracy: 1.0000\n",
      " 92/156 [================>.............] - ETA: 57s - loss: 8.4568e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 93/156 [================>.............] - ETA: 56s - loss: 8.4295e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 94/156 [=================>............] - ETA: 55s - loss: 8.3917e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 95/156 [=================>............] - ETA: 54s - loss: 8.3504e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 96/156 [=================>............] - ETA: 53s - loss: 8.3458e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 97/156 [=================>............] - ETA: 52s - loss: 8.3639e-06 - accuracy: 1.0000\n",
      " 98/156 [=================>............] - ETA: 51s - loss: 8.3606e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 99/156 [==================>...........] - ETA: 50s - loss: 8.2969e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m100/156 [==================>...........] - ETA: 49s - loss: 8.2592e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m101/156 [==================>...........] - ETA: 48s - loss: 8.2997e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m102/156 [==================>...........] - ETA: 47s - loss: 8.3333e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m103/156 [==================>...........] - ETA: 47s - loss: 8.3269e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m104/156 [===================>..........] - ETA: 46s - loss: 8.3353e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m105/156 [===================>..........] - ETA: 45s - loss: 8.3302e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m106/156 [===================>..........] - ETA: 44s - loss: 8.2730e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m107/156 [===================>..........] - ETA: 43s - loss: 8.3262e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m108/156 [===================>..........] - ETA: 42s - loss: 8.2886e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m109/156 [===================>..........] - ETA: 41s - loss: 8.2609e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m110/156 [====================>.........] - ETA: 40s - loss: 8.2440e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m111/156 [====================>.........] - ETA: 39s - loss: 8.1963e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m112/156 [====================>.........] - ETA: 38s - loss: 8.1808e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m113/156 [====================>.........] - ETA: 38s - loss: 8.1374e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m114/156 [====================>.........] - ETA: 37s - loss: 8.1517e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m115/156 [=====================>........] - ETA: 36s - loss: 8.4465e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m116/156 [=====================>........] - ETA: 35s - loss: 8.4187e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m117/156 [=====================>........] - ETA: 34s - loss: 8.3677e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m118/156 [=====================>........] - ETA: 33s - loss: 8.3206e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m119/156 [=====================>........] - ETA: 32s - loss: 8.2818e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m120/156 [======================>.......] - ETA: 31s - loss: 8.2677e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m121/156 [======================>.......] - ETA: 31s - loss: 8.2348e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m122/156 [======================>.......] - ETA: 30s - loss: 8.2162e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m123/156 [======================>.......] - ETA: 29s - loss: 8.2205e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m124/156 [======================>.......] - ETA: 28s - loss: 8.2249e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m125/156 [=======================>......] - ETA: 27s - loss: 8.1744e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m126/156 [=======================>......] - ETA: 26s - loss: 8.1352e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m127/156 [=======================>......] - ETA: 25s - loss: 8.2793e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m128/156 [=======================>......] - ETA: 25s - loss: 8.2962e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m129/156 [=======================>......] - ETA: 24s - loss: 8.2665e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m130/156 [========================>.....] - ETA: 23s - loss: 8.2360e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m131/156 [========================>.....] - ETA: 22s - loss: 8.1980e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m132/156 [========================>.....] - ETA: 21s - loss: 8.1528e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m133/156 [========================>.....] - ETA: 20s - loss: 8.1149e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m134/156 [========================>.....] - ETA: 19s - loss: 8.1193e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m135/156 [========================>.....] - ETA: 18s - loss: 8.2208e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m136/156 [=========================>....] - ETA: 17s - loss: 8.2851e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m137/156 [=========================>....] - ETA: 16s - loss: 8.2556e-06 - accuracy: 1.0000\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m138/156 [=========================>....] - ETA: 16s - loss: 8.2504e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m139/156 [=========================>....] - ETA: 15s - loss: 8.2226e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m140/156 [=========================>....] - ETA: 14s - loss: 8.1900e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m141/156 [==========================>...] - ETA: 13s - loss: 8.1647e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m142/156 [==========================>...] - ETA: 12s - loss: 8.1812e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m143/156 [==========================>...] - ETA: 11s - loss: 8.1825e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m144/156 [==========================>...] - ETA: 10s - loss: 8.1682e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m145/156 [==========================>...] - ETA: 9s - loss: 8.1581e-06 - accuracy: 1.0000 \u001b[0m\n",
      "\u001b[34m146/156 [===========================>..] - ETA: 8s - loss: 8.1209e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m147/156 [===========================>..] - ETA: 8s - loss: 8.1151e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m148/156 [===========================>..] - ETA: 7s - loss: 8.0798e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m149/156 [===========================>..] - ETA: 6s - loss: 8.0656e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m150/156 [===========================>..] - ETA: 5s - loss: 8.0603e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m151/156 [============================>.] - ETA: 4s - loss: 8.0343e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m152/156 [============================>.] - ETA: 3s - loss: 8.0230e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m153/156 [============================>.] - ETA: 2s - loss: 8.0036e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m154/156 [============================>.] - ETA: 1s - loss: 7.9689e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m155/156 [============================>.] - ETA: 0s - loss: 7.9568e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m156/156 [==============================] - 154s 987ms/step - loss: 7.9197e-06 - accuracy: 1.0000 - val_loss: 0.0502 - val_accuracy: 20.9456\u001b[0m\n",
      "\u001b[34mEpoch 8/10\u001b[0m\n",
      "\u001b[34m  1/156 [..............................] - ETA: 2:06 - loss: 2.7943e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m  2/156 [..............................] - ETA: 2:13 - loss: 1.4666e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m  3/156 [..............................] - ETA: 2:11 - loss: 1.1164e-05 - accuracy: 1.0000\n",
      "  4/156 [..............................] - ETA: 2:11 - loss: 9.0284e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m  5/156 [..............................] - ETA: 2:11 - loss: 8.9779e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m  6/156 [>.............................] - ETA: 2:09 - loss: 7.9908e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m  7/156 [>.............................] - ETA: 2:09 - loss: 9.5108e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m  8/156 [>.............................] - ETA: 2:09 - loss: 1.0184e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m  9/156 [>.............................] - ETA: 2:08 - loss: 9.4133e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 10/156 [>.............................] - ETA: 2:08 - loss: 9.2895e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 11/156 [=>............................] - ETA: 2:09 - loss: 9.1501e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 12/156 [=>............................] - ETA: 2:07 - loss: 8.7599e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 13/156 [=>............................] - ETA: 2:06 - loss: 1.0563e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 14/156 [=>............................] - ETA: 2:08 - loss: 1.0236e-05 - accuracy: 1.0000\n",
      " 15/156 [=>............................] - ETA: 2:06 - loss: 9.8510e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 16/156 [==>...........................] - ETA: 2:05 - loss: 9.8180e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 17/156 [==>...........................] - ETA: 2:06 - loss: 9.5392e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 18/156 [==>...........................] - ETA: 2:05 - loss: 9.7801e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 19/156 [==>...........................] - ETA: 2:07 - loss: 9.5526e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 20/156 [==>...........................] - ETA: 2:07 - loss: 9.1752e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 21/156 [===>..........................] - ETA: 2:06 - loss: 9.0668e-06 - accuracy: 1.0000\n",
      " 22/156 [===>..........................] - ETA: 2:05 - loss: 8.9982e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 23/156 [===>..........................] - ETA: 2:03 - loss: 8.8299e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 24/156 [===>..........................] - ETA: 2:02 - loss: 8.5914e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 25/156 [===>..........................] - ETA: 2:00 - loss: 8.4675e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 26/156 [====>.........................] - ETA: 1:59 - loss: 8.2397e-06 - accuracy: 1.0000\n",
      " 27/156 [====>.........................] - ETA: 1:58 - loss: 8.0603e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 28/156 [====>.........................] - ETA: 1:56 - loss: 8.1011e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 29/156 [====>.........................] - ETA: 1:55 - loss: 7.9386e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 30/156 [====>.........................] - ETA: 1:54 - loss: 7.7802e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 31/156 [====>.........................] - ETA: 1:53 - loss: 7.6081e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 32/156 [=====>........................] - ETA: 1:52 - loss: 7.5965e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 33/156 [=====>........................] - ETA: 1:51 - loss: 7.5512e-06 - accuracy: 1.0000\n",
      " 34/156 [=====>........................] - ETA: 1:50 - loss: 7.5298e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 35/156 [=====>........................] - ETA: 1:48 - loss: 7.4024e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 36/156 [=====>........................] - ETA: 1:47 - loss: 7.2779e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 37/156 [======>.......................] - ETA: 1:46 - loss: 7.2602e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 38/156 [======>.......................] - ETA: 1:45 - loss: 7.2306e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 39/156 [======>.......................] - ETA: 1:45 - loss: 7.3150e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 40/156 [======>.......................] - ETA: 1:44 - loss: 7.2351e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 41/156 [======>.......................] - ETA: 1:43 - loss: 7.1849e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 42/156 [=======>......................] - ETA: 1:42 - loss: 7.0741e-06 - accuracy: 1.0000\n",
      " 43/156 [=======>......................] - ETA: 1:41 - loss: 7.3773e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 44/156 [=======>......................] - ETA: 1:40 - loss: 7.2895e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 45/156 [=======>......................] - ETA: 1:39 - loss: 7.1569e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 46/156 [=======>......................] - ETA: 1:38 - loss: 7.0853e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 47/156 [========>.....................] - ETA: 1:37 - loss: 7.0354e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 48/156 [========>.....................] - ETA: 1:36 - loss: 6.9710e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 49/156 [========>.....................] - ETA: 1:35 - loss: 6.8616e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 50/156 [========>.....................] - ETA: 1:34 - loss: 6.9776e-06 - accuracy: 1.0000\n",
      " 51/156 [========>.....................] - ETA: 1:33 - loss: 7.0889e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 52/156 [=========>....................] - ETA: 1:32 - loss: 7.0091e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 53/156 [=========>....................] - ETA: 1:31 - loss: 7.0420e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 54/156 [=========>....................] - ETA: 1:30 - loss: 6.9679e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 55/156 [=========>....................] - ETA: 1:29 - loss: 6.9475e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 56/156 [=========>....................] - ETA: 1:29 - loss: 6.9610e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 57/156 [=========>....................] - ETA: 1:28 - loss: 6.9658e-06 - accuracy: 1.0000\n",
      " 58/156 [==========>...................] - ETA: 1:27 - loss: 7.2021e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 59/156 [==========>...................] - ETA: 1:26 - loss: 7.2018e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 60/156 [==========>...................] - ETA: 1:25 - loss: 7.1661e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 61/156 [==========>...................] - ETA: 1:24 - loss: 7.1045e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 62/156 [==========>...................] - ETA: 1:23 - loss: 7.0208e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 63/156 [===========>..................] - ETA: 1:22 - loss: 7.0415e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 64/156 [===========>..................] - ETA: 1:21 - loss: 7.0882e-06 - accuracy: 1.0000\n",
      " 65/156 [===========>..................] - ETA: 1:20 - loss: 7.0179e-06 - accuracy: 1.0000\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m 66/156 [===========>..................] - ETA: 1:19 - loss: 6.9393e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 67/156 [===========>..................] - ETA: 1:18 - loss: 6.8742e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 68/156 [============>.................] - ETA: 1:17 - loss: 6.8634e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 69/156 [============>.................] - ETA: 1:16 - loss: 6.8158e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 70/156 [============>.................] - ETA: 1:16 - loss: 6.7578e-06 - accuracy: 1.0000\n",
      " 71/156 [============>.................] - ETA: 1:15 - loss: 6.8500e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 72/156 [============>.................] - ETA: 1:14 - loss: 6.8156e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 73/156 [=============>................] - ETA: 1:13 - loss: 6.7914e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 74/156 [=============>................] - ETA: 1:12 - loss: 6.8019e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 75/156 [=============>................] - ETA: 1:11 - loss: 6.7326e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 76/156 [=============>................] - ETA: 1:10 - loss: 6.7166e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 77/156 [=============>................] - ETA: 1:09 - loss: 6.6578e-06 - accuracy: 1.0000\n",
      " 78/156 [==============>...............] - ETA: 1:08 - loss: 6.6834e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 79/156 [==============>...............] - ETA: 1:07 - loss: 6.6251e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 80/156 [==============>...............] - ETA: 1:06 - loss: 6.8475e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 81/156 [==============>...............] - ETA: 1:06 - loss: 6.8074e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 82/156 [==============>...............] - ETA: 1:05 - loss: 6.7657e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 83/156 [==============>...............] - ETA: 1:04 - loss: 6.8787e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 84/156 [===============>..............] - ETA: 1:03 - loss: 6.8492e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 85/156 [===============>..............] - ETA: 1:03 - loss: 6.8966e-06 - accuracy: 1.0000\n",
      " 86/156 [===============>..............] - ETA: 1:02 - loss: 6.8646e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 87/156 [===============>..............] - ETA: 1:01 - loss: 6.8091e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 88/156 [===============>..............] - ETA: 1:00 - loss: 6.7980e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 89/156 [================>.............] - ETA: 59s - loss: 6.7704e-06 - accuracy: 1.0000 \u001b[0m\n",
      "\u001b[34m 90/156 [================>.............] - ETA: 58s - loss: 6.7907e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 91/156 [================>.............] - ETA: 57s - loss: 6.7368e-06 - accuracy: 1.0000\n",
      " 92/156 [================>.............] - ETA: 56s - loss: 6.7060e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 93/156 [================>.............] - ETA: 56s - loss: 6.6497e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 94/156 [=================>............] - ETA: 55s - loss: 6.6284e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 95/156 [=================>............] - ETA: 54s - loss: 6.5887e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 96/156 [=================>............] - ETA: 53s - loss: 6.5743e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 97/156 [=================>............] - ETA: 52s - loss: 6.5244e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 98/156 [=================>............] - ETA: 51s - loss: 6.4963e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 99/156 [==================>...........] - ETA: 50s - loss: 6.5242e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m100/156 [==================>...........] - ETA: 49s - loss: 6.4773e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m101/156 [==================>...........] - ETA: 48s - loss: 6.5006e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m102/156 [==================>...........] - ETA: 47s - loss: 6.4835e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m103/156 [==================>...........] - ETA: 47s - loss: 6.4399e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m104/156 [===================>..........] - ETA: 46s - loss: 6.4378e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m105/156 [===================>..........] - ETA: 45s - loss: 6.4262e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m106/156 [===================>..........] - ETA: 44s - loss: 6.4453e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m107/156 [===================>..........] - ETA: 43s - loss: 6.4099e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m108/156 [===================>..........] - ETA: 42s - loss: 6.3793e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m109/156 [===================>..........] - ETA: 41s - loss: 6.3843e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m110/156 [====================>.........] - ETA: 40s - loss: 6.3760e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m111/156 [====================>.........] - ETA: 39s - loss: 6.3428e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m112/156 [====================>.........] - ETA: 38s - loss: 6.2981e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m113/156 [====================>.........] - ETA: 38s - loss: 6.2536e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m114/156 [====================>.........] - ETA: 37s - loss: 6.2351e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m115/156 [=====================>........] - ETA: 36s - loss: 6.2100e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m116/156 [=====================>........] - ETA: 35s - loss: 6.1678e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m117/156 [=====================>........] - ETA: 34s - loss: 6.1457e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m118/156 [=====================>........] - ETA: 33s - loss: 6.1268e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m119/156 [=====================>........] - ETA: 32s - loss: 6.0841e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m120/156 [======================>.......] - ETA: 31s - loss: 6.1118e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m121/156 [======================>.......] - ETA: 31s - loss: 6.1113e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m122/156 [======================>.......] - ETA: 30s - loss: 6.1052e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m123/156 [======================>.......] - ETA: 29s - loss: 6.1047e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m124/156 [======================>.......] - ETA: 28s - loss: 6.1000e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m125/156 [=======================>......] - ETA: 27s - loss: 6.0773e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m126/156 [=======================>......] - ETA: 26s - loss: 6.0603e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m127/156 [=======================>......] - ETA: 25s - loss: 6.0538e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m128/156 [=======================>......] - ETA: 24s - loss: 6.0356e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m129/156 [=======================>......] - ETA: 23s - loss: 6.0074e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m130/156 [========================>.....] - ETA: 23s - loss: 5.9742e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m131/156 [========================>.....] - ETA: 22s - loss: 5.9474e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m132/156 [========================>.....] - ETA: 21s - loss: 5.9208e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m133/156 [========================>.....] - ETA: 20s - loss: 5.9027e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m134/156 [========================>.....] - ETA: 19s - loss: 5.8757e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m135/156 [========================>.....] - ETA: 18s - loss: 5.8508e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m136/156 [=========================>....] - ETA: 17s - loss: 5.9534e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m137/156 [=========================>....] - ETA: 16s - loss: 5.9264e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m138/156 [=========================>....] - ETA: 15s - loss: 5.9563e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m139/156 [=========================>....] - ETA: 15s - loss: 5.9372e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m140/156 [=========================>....] - ETA: 14s - loss: 5.9074e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m141/156 [==========================>...] - ETA: 13s - loss: 5.9048e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m142/156 [==========================>...] - ETA: 12s - loss: 5.8837e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m143/156 [==========================>...] - ETA: 11s - loss: 5.8586e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m144/156 [==========================>...] - ETA: 10s - loss: 5.8456e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m145/156 [==========================>...] - ETA: 9s - loss: 5.8214e-06 - accuracy: 1.0000 \u001b[0m\n",
      "\u001b[34m146/156 [===========================>..] - ETA: 8s - loss: 5.8080e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m147/156 [===========================>..] - ETA: 7s - loss: 5.7799e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m148/156 [===========================>..] - ETA: 7s - loss: 5.7691e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m149/156 [===========================>..] - ETA: 6s - loss: 5.7401e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m150/156 [===========================>..] - ETA: 5s - loss: 5.7126e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m151/156 [============================>.] - ETA: 4s - loss: 5.6924e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m152/156 [============================>.] - ETA: 3s - loss: 5.6674e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m153/156 [============================>.] - ETA: 2s - loss: 5.6603e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m154/156 [============================>.] - ETA: 1s - loss: 6.1890e-06 - accuracy: 1.0000\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m155/156 [============================>.] - ETA: 0s - loss: 6.1676e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m156/156 [==============================] - 155s 993ms/step - loss: 6.1500e-06 - accuracy: 1.0000 - val_loss: 0.0516 - val_accuracy: 20.2688\u001b[0m\n",
      "\u001b[34mEpoch 9/10\u001b[0m\n",
      "\u001b[34m  1/156 [..............................] - ETA: 2:18 - loss: 6.4401e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m  2/156 [..............................] - ETA: 2:09 - loss: 5.2160e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m  3/156 [..............................] - ETA: 2:11 - loss: 5.1886e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m  4/156 [..............................] - ETA: 2:11 - loss: 4.7952e-06 - accuracy: 1.0000\n",
      "  5/156 [..............................] - ETA: 2:10 - loss: 4.1685e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m  6/156 [>.............................] - ETA: 2:09 - loss: 3.7234e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m  7/156 [>.............................] - ETA: 2:10 - loss: 3.4059e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m  8/156 [>.............................] - ETA: 2:11 - loss: 5.3979e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m  9/156 [>.............................] - ETA: 2:11 - loss: 5.0239e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 10/156 [>.............................] - ETA: 2:11 - loss: 5.3181e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 11/156 [=>............................] - ETA: 2:10 - loss: 5.6370e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 12/156 [=>............................] - ETA: 2:10 - loss: 5.3584e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 13/156 [=>............................] - ETA: 2:08 - loss: 5.7269e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 14/156 [=>............................] - ETA: 2:07 - loss: 5.5344e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 15/156 [=>............................] - ETA: 2:06 - loss: 5.2911e-06 - accuracy: 1.0000\n",
      " 16/156 [==>...........................] - ETA: 2:05 - loss: 5.2357e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 17/156 [==>...........................] - ETA: 2:04 - loss: 5.6442e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 18/156 [==>...........................] - ETA: 2:03 - loss: 5.5127e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 19/156 [==>...........................] - ETA: 2:01 - loss: 5.4564e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 20/156 [==>...........................] - ETA: 2:00 - loss: 5.2264e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 21/156 [===>..........................] - ETA: 1:59 - loss: 5.0802e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 22/156 [===>..........................] - ETA: 1:59 - loss: 5.1097e-06 - accuracy: 1.0000\n",
      " 23/156 [===>..........................] - ETA: 1:58 - loss: 4.9739e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 24/156 [===>..........................] - ETA: 1:57 - loss: 5.0643e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 25/156 [===>..........................] - ETA: 1:55 - loss: 5.0388e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 26/156 [====>.........................] - ETA: 1:54 - loss: 5.4243e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 27/156 [====>.........................] - ETA: 1:53 - loss: 5.3936e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 28/156 [====>.........................] - ETA: 1:53 - loss: 5.4588e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 29/156 [====>.........................] - ETA: 1:51 - loss: 5.4189e-06 - accuracy: 1.0000\n",
      " 30/156 [====>.........................] - ETA: 1:50 - loss: 5.4709e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 31/156 [====>.........................] - ETA: 1:49 - loss: 5.3949e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 32/156 [=====>........................] - ETA: 1:48 - loss: 5.4302e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 33/156 [=====>........................] - ETA: 1:47 - loss: 5.4288e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 34/156 [=====>........................] - ETA: 1:47 - loss: 5.4646e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 35/156 [=====>........................] - ETA: 1:46 - loss: 5.3652e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 36/156 [=====>........................] - ETA: 1:45 - loss: 5.2935e-06 - accuracy: 1.0000\n",
      " 37/156 [======>.......................] - ETA: 1:44 - loss: 5.3363e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 38/156 [======>.......................] - ETA: 1:43 - loss: 5.3198e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 39/156 [======>.......................] - ETA: 1:42 - loss: 5.2416e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 40/156 [======>.......................] - ETA: 1:41 - loss: 5.1633e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 41/156 [======>.......................] - ETA: 1:40 - loss: 5.1299e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 42/156 [=======>......................] - ETA: 1:40 - loss: 5.1509e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 43/156 [=======>......................] - ETA: 1:40 - loss: 5.1599e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 44/156 [=======>......................] - ETA: 1:39 - loss: 5.1188e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 45/156 [=======>......................] - ETA: 1:39 - loss: 5.1904e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 46/156 [=======>......................] - ETA: 1:39 - loss: 5.1473e-06 - accuracy: 1.0000\n",
      " 47/156 [========>.....................] - ETA: 1:38 - loss: 5.1149e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 48/156 [========>.....................] - ETA: 1:37 - loss: 5.1319e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 49/156 [========>.....................] - ETA: 1:36 - loss: 5.1096e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 50/156 [========>.....................] - ETA: 1:35 - loss: 5.1050e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 51/156 [========>.....................] - ETA: 1:34 - loss: 5.1075e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 52/156 [=========>....................] - ETA: 1:33 - loss: 5.1162e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 53/156 [=========>....................] - ETA: 1:32 - loss: 5.1684e-06 - accuracy: 1.0000\n",
      " 54/156 [=========>....................] - ETA: 1:31 - loss: 5.1138e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 55/156 [=========>....................] - ETA: 1:30 - loss: 5.0509e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 56/156 [=========>....................] - ETA: 1:29 - loss: 5.0149e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 57/156 [=========>....................] - ETA: 1:28 - loss: 4.9557e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 58/156 [==========>...................] - ETA: 1:27 - loss: 4.9236e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 59/156 [==========>...................] - ETA: 1:27 - loss: 4.8682e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 60/156 [==========>...................] - ETA: 1:26 - loss: 4.8198e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 61/156 [==========>...................] - ETA: 1:25 - loss: 4.7825e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 62/156 [==========>...................] - ETA: 1:24 - loss: 4.7383e-06 - accuracy: 1.0000\n",
      " 63/156 [===========>..................] - ETA: 1:23 - loss: 4.7324e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 64/156 [===========>..................] - ETA: 1:22 - loss: 4.6835e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 65/156 [===========>..................] - ETA: 1:21 - loss: 4.7162e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 66/156 [===========>..................] - ETA: 1:20 - loss: 4.7179e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 67/156 [===========>..................] - ETA: 1:19 - loss: 4.6686e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 68/156 [============>.................] - ETA: 1:18 - loss: 4.6250e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 69/156 [============>.................] - ETA: 1:17 - loss: 4.5894e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 70/156 [============>.................] - ETA: 1:16 - loss: 4.6414e-06 - accuracy: 1.0000\n",
      " 71/156 [============>.................] - ETA: 1:16 - loss: 4.6226e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 72/156 [============>.................] - ETA: 1:15 - loss: 4.5863e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 73/156 [=============>................] - ETA: 1:14 - loss: 4.6759e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 74/156 [=============>................] - ETA: 1:13 - loss: 4.6476e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 75/156 [=============>................] - ETA: 1:12 - loss: 4.5952e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 76/156 [=============>................] - ETA: 1:11 - loss: 4.5738e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 77/156 [=============>................] - ETA: 1:10 - loss: 4.6033e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 78/156 [==============>...............] - ETA: 1:10 - loss: 4.5649e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 79/156 [==============>...............] - ETA: 1:09 - loss: 4.5822e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 80/156 [==============>...............] - ETA: 1:08 - loss: 4.5752e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 81/156 [==============>...............] - ETA: 1:07 - loss: 4.5535e-06 - accuracy: 1.0000\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m 82/156 [==============>...............] - ETA: 1:06 - loss: 4.5175e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 83/156 [==============>...............] - ETA: 1:05 - loss: 4.5199e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 84/156 [===============>..............] - ETA: 1:05 - loss: 4.8139e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 85/156 [===============>..............] - ETA: 1:04 - loss: 4.7761e-06 - accuracy: 1.0000\n",
      " 86/156 [===============>..............] - ETA: 1:03 - loss: 4.7388e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 87/156 [===============>..............] - ETA: 1:02 - loss: 4.7759e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 88/156 [===============>..............] - ETA: 1:01 - loss: 4.8859e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 89/156 [================>.............] - ETA: 1:00 - loss: 4.8781e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 90/156 [================>.............] - ETA: 59s - loss: 4.8485e-06 - accuracy: 1.0000 \u001b[0m\n",
      "\u001b[34m 91/156 [================>.............] - ETA: 58s - loss: 4.8356e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 92/156 [================>.............] - ETA: 57s - loss: 4.9013e-06 - accuracy: 1.0000\n",
      " 93/156 [================>.............] - ETA: 56s - loss: 4.9522e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 94/156 [=================>............] - ETA: 55s - loss: 4.9208e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 95/156 [=================>............] - ETA: 54s - loss: 5.0071e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 96/156 [=================>............] - ETA: 53s - loss: 4.9956e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 97/156 [=================>............] - ETA: 53s - loss: 5.0343e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 98/156 [=================>............] - ETA: 52s - loss: 5.0292e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 99/156 [==================>...........] - ETA: 51s - loss: 5.0228e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m100/156 [==================>...........] - ETA: 50s - loss: 4.9982e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m101/156 [==================>...........] - ETA: 49s - loss: 4.9837e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m102/156 [==================>...........] - ETA: 48s - loss: 5.0812e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m103/156 [==================>...........] - ETA: 47s - loss: 5.0501e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m104/156 [===================>..........] - ETA: 46s - loss: 5.0291e-06 - accuracy: 1.0000\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "inputs = {\n",
    "    'train': '{}/train'.format(dataset_uri),\n",
    "    'validation': '{}/validation'.format(dataset_uri),\n",
    "    'eval': '{}/eval'.format(dataset_uri),\n",
    "}\n",
    "\n",
    "estimator.fit(inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### View the job training metrics\n",
    "\n",
    "We can now view the metrics from the training job directly in the SageMaker console.  \n",
    "\n",
    "Log into the [SageMaker console](https://console.aws.amazon.com/sagemaker/home), choose the latest training job, and scroll down to the monitor section. Alternatively, the code below uses the region and training job name to generate a URL to CloudWatch metrics.\n",
    "\n",
    "Using CloudWatch metrics, you can change the period and configure the statistics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib import parse\n",
    "\n",
    "from IPython.core.display import Markdown\n",
    "\n",
    "region = sagemaker_session.boto_region_name\n",
    "cw_url = parse.urlunparse((\n",
    "    'https',\n",
    "    '{}.console.aws.amazon.com'.format(region),\n",
    "    '/cloudwatch/home',\n",
    "    '',\n",
    "    'region={}'.format(region),\n",
    "    'metricsV2:namespace=/aws/sagemaker/TrainingJobs;dimensions=TrainingJobName;search={}'.format(estimator.latest_training_job.name),\n",
    "))\n",
    "\n",
    "display(Markdown('CloudWatch metrics: [link]({}). After you choose a metric, '\n",
    "                 'change the period to 1 Minute (Graphed Metrics -> Period).'.format(cw_url)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train on SageMaker with Pipe Mode\n",
    "\n",
    "Here we train our model using Pipe Mode. With Pipe Mode, SageMaker uses [Linux named pipes](https://www.linuxjournal.com/article/2156) to stream the training data directly from S3 instead of downloading the data first.\n",
    "\n",
    "In our script, we enable Pipe Mode using the following code:\n",
    "\n",
    "```python\n",
    "from sagemaker_tensorflow import PipeModeDataset\n",
    "\n",
    "dataset = PipeModeDataset(channel=channel_name, record_format='TFRecord')\n",
    "```\n",
    "\n",
    "When we create our estimator, the only difference from before is that we also specify `input_mode='Pipe'`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_mode_estimator = TensorFlow(entry_point='cifar10_keras_main.py',\n",
    "                                 source_dir='source_dir',\n",
    "                                 metric_definitions=metric_definitions,\n",
    "                                 hyperparameters=hyperparameters,\n",
    "                                 role=role,\n",
    "                                 framework_version='1.15.2',\n",
    "                                 py_version='py3',\n",
    "                                 train_instance_count=1,\n",
    "                                 train_instance_type='ml.p2.xlarge',\n",
    "                                 input_mode='Pipe',\n",
    "                                 base_job_name='cifar10-tf-pipe',\n",
    "                                 tags=tags)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example, we set ```wait=False``` if you want to see the output logs, change this to ```wait=True```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_mode_estimator.fit(inputs, wait=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distributed training with Horovod\n",
    "\n",
    "[Horovod](https://horovod.readthedocs.io) is a distributed training framework based on MPI. To use Horovod, we make the following changes to our training script:\n",
    "\n",
    "1. Enable Horovod:\n",
    "\n",
    "```python\n",
    "import horovod.keras as hvd\n",
    "\n",
    "hvd.init()\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "config.gpu_options.visible_device_list = str(hvd.local_rank())\n",
    "K.set_session(tf.Session(config=config))\n",
    "```\n",
    "\n",
    "2. Add these callbacks:\n",
    "\n",
    "```python\n",
    "hvd.callbacks.BroadcastGlobalVariablesCallback(0)\n",
    "hvd.callbacks.MetricAverageCallback()\n",
    "```\n",
    "\n",
    "3. Configure the optimizer:\n",
    "\n",
    "```python\n",
    "opt = Adam(lr=learning_rate * size, decay=weight_decay)\n",
    "opt = hvd.DistributedOptimizer(opt)\n",
    "```\n",
    "\n",
    "4. Choose to save checkpoints and send TensorBoard logs only from the master node:\n",
    "\n",
    "```python\n",
    "if hvd.rank() == 0:\n",
    "    save_model(model, args.model_output_dir)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To configure the training job, we specify the following for the distribution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distribution = {\n",
    "    'mpi': {\n",
    "        'enabled': True,\n",
    "        'processes_per_host': 1,  # Number of Horovod processes per host\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is then passed to our estimator, in addition to setting `train_instance_count` to 2:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dist_estimator = TensorFlow(entry_point='cifar10_keras_main.py',\n",
    "                            source_dir='source_dir',\n",
    "                            metric_definitions=metric_definitions,\n",
    "                            hyperparameters=hyperparameters,\n",
    "                            distributions=distribution,\n",
    "                            role=role,\n",
    "                            framework_version='1.15.2',\n",
    "                            py_version='py3',\n",
    "                            train_instance_count=2,\n",
    "                            train_instance_type='ml.p3.2xlarge',\n",
    "                            base_job_name='cifar10-tf-dist',\n",
    "                            tags=tags)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Like before, we call `fit()` on our estimator. If you want to see the training job logs in the notebook output, set `wait=True`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dist_estimator.fit(inputs, wait=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare the training jobs with TensorBoard\n",
    "\n",
    "Using the visualization tool [TensorBoard](https://www.tensorflow.org/tensorboard), we can compare our training jobs.\n",
    "\n",
    "In a local setting, install TensorBoard with `pip install tensorboard`. Then run the command generated by the following code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python generate_tensorboard_command.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After running that command, we can access TensorBoard locally at http://localhost:6006.\n",
    "\n",
    "Based on the TensorBoard metrics, we can see that:\n",
    "1. All jobs run for 10 epochs (0 - 9).\n",
    "1. Both File Mode and Pipe Mode run for ~1 minute - Pipe Mode doesn't affect training performance.\n",
    "1. Distributed training runs for only 45 seconds.\n",
    "1. All of the training jobs resulted in similar validation accuracy.\n",
    "\n",
    "This example uses a relatively small dataset (179 MB). For larger datasets, Pipe Mode can significantly reduce training time because it does not copy the entire dataset into local memory."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deploy the trained model\n",
    "\n",
    "After we train our model, we can deploy it to a SageMaker Endpoint, which serves prediction requests in real-time. To do so, we simply call `deploy()` on our estimator, passing in the desired number of instances and instance type for the endpoint.\n",
    "\n",
    "Because we're using TensorFlow Serving for deployment, our training script saves the model in TensorFlow's SavedModel format. For more details, see [this blog post on deploying Keras and TF models in SageMaker](https://aws.amazon.com/blogs/machine-learning/deploy-trained-keras-or-tensorflow-models-using-amazon-sagemaker)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "predictor = estimator.deploy(initial_instance_count=1, instance_type='ml.m4.xlarge')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Invoke the endpoint\n",
    "\n",
    "To verify the that the endpoint is in service, we generate some random data in the correct shape and get a prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "data = np.random.randn(1, 32, 32, 3)\n",
    "print('Predicted class: {}'.format(np.argmax(predictor.predict(data)['predictions'])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's use the test dataset for predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import cifar10\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the data loaded, we can use it for predictions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "def predict(data):\n",
    "    predictions = predictor.predict(data)['predictions']\n",
    "    return predictions\n",
    "\n",
    "\n",
    "predicted = []\n",
    "actual = []\n",
    "batches = 0\n",
    "batch_size = 128\n",
    "\n",
    "datagen = ImageDataGenerator()\n",
    "for data in datagen.flow(x_test, y_test, batch_size=batch_size):\n",
    "    for i, prediction in enumerate(predict(data[0])):\n",
    "        predicted.append(np.argmax(prediction))\n",
    "        actual.append(data[1][i][0])\n",
    "\n",
    "    batches += 1\n",
    "    if batches >= len(x_test) / batch_size:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the predictions, we calculate our model accuracy and create a confusion matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "accuracy = accuracy_score(y_pred=predicted, y_true=actual)\n",
    "display('Average accuracy: {}%'.format(round(accuracy * 100, 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sn\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "cm = confusion_matrix(y_pred=predicted, y_true=actual)\n",
    "cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "sn.set(rc={'figure.figsize': (11.7,8.27)})\n",
    "sn.set(font_scale=1.4)  # for label size\n",
    "sn.heatmap(cm, annot=True, annot_kws={\"size\": 10})  # font size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aided by the colors of the heatmap, we can use this confusion matrix to understand how well the model performed for each label."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleanup\n",
    "\n",
    "To avoid incurring extra charges to your AWS account, let's delete the endpoint we created:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor.delete_endpoint()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_tensorflow_p36",
   "language": "python",
   "name": "conda_tensorflow_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  },
  "notice": "Copyright 2017-2020 Amazon.com, Inc. or its affiliates. All Rights Reserved. Licensed under the Apache License, Version 2.0 (the \"License\"). You may not use this file except in compliance with the License. A copy of the License is located at http://aws.amazon.com/apache2.0/ or in the \"license\" file accompanying this file. This file is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License.",
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
