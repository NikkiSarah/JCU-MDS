{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train and Host a Keras Model with Pipe Mode and Horovod on Amazon SageMaker\n",
    "\n",
    "Amazon SageMaker is a fully-managed service that provides developers and data scientists with the ability to build, train, and deploy machine learning (ML) models quickly. Amazon SageMaker removes the heavy lifting from each step of the machine learning process to make it easier to develop high-quality models. The SageMaker Python SDK makes it easy to train and deploy models in Amazon SageMaker with several different machine learning and deep learning frameworks, including TensorFlow and Keras.\n",
    "\n",
    "In this notebook, we train and host a [Keras Sequential model](https://keras.io/getting-started/sequential-model-guide) on SageMaker. The model used for this notebook is a simple deep convolutional neural network (CNN) that was extracted from [the Keras examples](https://github.com/keras-team/keras/blob/master/examples/cifar10_cnn.py).\n",
    "\n",
    "For training our model, we also demonstrate distributed training with [Horovod](https://horovod.readthedocs.io) and Pipe Mode. Amazon SageMaker's Pipe Mode streams your dataset directly to your training instances instead of being downloaded first, which translates to training jobs that start sooner, finish quicker, and need less disk space."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "First, we define a few variables that are be needed later in the example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "from sagemaker import get_execution_role\n",
    "\n",
    "sagemaker_session = sagemaker.Session()\n",
    "\n",
    "role = get_execution_role()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The CIFAR-10 dataset\n",
    "\n",
    "The [CIFAR-10 dataset](https://www.cs.toronto.edu/~kriz/cifar.html) is one of the most popular machine learning datasets. It consists of 60,000 32x32 images belonging to 10 different classes (6,000 images per class). Here are the classes in the dataset, as well as 10 random images from each:\n",
    "\n",
    "![cifar10](https://maet3608.github.io/nuts-ml/_images/cifar10.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare the dataset for training\n",
    "\n",
    "To use the CIFAR-10 dataset, we first download it and convert it to TFRecords. This step takes around 5 minutes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/ec2-user/anaconda3/envs/tensorflow_p36/cpu/lib/python3.6/site-packages/tensorflow_core/__init__.py:1473: The name tf.estimator.inputs is deprecated. Please use tf.compat.v1.estimator.inputs instead.\n",
      "\n",
      "Download from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz and extract.\n",
      "WARNING:tensorflow:\n",
      "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "  * https://github.com/tensorflow/io (for I/O related ops)\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n",
      "WARNING:tensorflow:From generate_cifar10_tfrecords.py:32: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "WARNING:tensorflow:From /home/ec2-user/anaconda3/envs/tensorflow_p36/cpu/lib/python3.6/site-packages/tensorflow_core/contrib/learn/python/learn/datasets/base.py:252: _internal_retry.<locals>.wrap.<locals>.wrapped_fn (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use urllib or similar directly.\n",
      "Successfully downloaded cifar-10-python.tar.gz 170498071 bytes.\n",
      "Generating ./data/train/train.tfrecords\n",
      "Generating ./data/validation/validation.tfrecords\n",
      "Generating ./data/eval/eval.tfrecords\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "!python generate_cifar10_tfrecords.py --data-dir ./data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we upload the data to Amazon S3:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'s3://sagemaker-ap-southeast-2-987959606453/tf-cifar10-example/data'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sagemaker.s3 import S3Uploader\n",
    "\n",
    "bucket = sagemaker_session.default_bucket()\n",
    "dataset_uri = S3Uploader.upload('data', 's3://{}/tf-cifar10-example/data'.format(bucket))\n",
    "\n",
    "display(dataset_uri)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the model\n",
    "\n",
    "In this tutorial, we train a deep CNN to learn a classification task with the CIFAR-10 dataset. We compare three different training jobs: a baseline training job, training with Pipe Mode, and distributed training with Horovod.\n",
    "\n",
    "### Run a baseline training job on SageMaker\n",
    "\n",
    "The SageMaker Python SDK's `sagemaker.tensorflow.TensorFlow` estimator class makes it easy for us to interact with SageMaker. We create one for each of the different training jobs we run in this example. A couple parameters worth noting:\n",
    "\n",
    "* `entry_point`: our training script (adapted from [this Keras example](https://github.com/keras-team/keras/blob/master/examples/cifar10_cnn.py)).\n",
    "* `train_instance_count`: the number of training instances. Here, we set it to 1 for our baseline training job.\n",
    "\n",
    "As we run each of our training jobs, we change different parameters to configure our different training jobs.\n",
    "\n",
    "For more details about the TensorFlow estimator class, see the [API documentation](https://sagemaker.readthedocs.io/en/stable/sagemaker.tensorflow.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Verify the training code\n",
    "\n",
    "Before running the baseline training job, we first use [the SageMaker Python SDK's Local Mode feature](https://sagemaker.readthedocs.io/en/stable/overview.html#local-mode) to check that our code works with SageMaker's TensorFlow environment. Local Mode downloads the [prebuilt Docker image for TensorFlow](https://docs.aws.amazon.com/deep-learning-containers/latest/devguide/deep-learning-containers-images.html) and runs a Docker container locally for a training job. In other words, it simulates the SageMaker environment for a quicker development cycle, so we use it here just to test out our code.\n",
    "\n",
    "We create a TensorFlow estimator, and specify the `instance_type` to be `'local'` or `'local_gpu'`, depending on our local instance type. This tells the estimator to run our training job locally (as opposed to on SageMaker). We also have our training code run for only one epoch because our intent here is to verify the code, not train an accurate model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train_instance_type has been renamed in sagemaker>=2.\n",
      "See: https://sagemaker.readthedocs.io/en/stable/v2.html for details.\n",
      "train_instance_count has been renamed in sagemaker>=2.\n",
      "See: https://sagemaker.readthedocs.io/en/stable/v2.html for details.\n",
      "train_instance_type has been renamed in sagemaker>=2.\n",
      "See: https://sagemaker.readthedocs.io/en/stable/v2.html for details.\n"
     ]
    }
   ],
   "source": [
    "import subprocess\n",
    "\n",
    "from sagemaker.tensorflow import TensorFlow\n",
    "\n",
    "instance_type = 'local'\n",
    "\n",
    "if subprocess.call('nvidia-smi') == 0:\n",
    "    # Set instance type to GPU if one is present\n",
    "    instance_type = 'local_gpu'\n",
    "    \n",
    "local_hyperparameters = {'epochs': 1, 'batch-size' : 64}\n",
    "\n",
    "estimator = TensorFlow(entry_point='cifar10_keras_main.py',\n",
    "                       source_dir='source_dir',\n",
    "                       role=role,\n",
    "                       framework_version='1.15.2',\n",
    "                       py_version='py3',\n",
    "                       hyperparameters=local_hyperparameters,\n",
    "                       train_instance_count=1,\n",
    "                       train_instance_type=instance_type)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we have our estimator, we call `fit()` to start the training job and pass the inputs that we downloaded earlier. We pass the inputs as a dictionary to define different data channels for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating 7828rhrjz9-algo-1-9g2mh ... \n",
      "Creating 7828rhrjz9-algo-1-9g2mh ... done\n",
      "Attaching to 7828rhrjz9-algo-1-9g2mh\n",
      "\u001b[36m7828rhrjz9-algo-1-9g2mh |\u001b[0m WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/__init__.py:1473: The name tf.estimator.inputs is deprecated. Please use tf.compat.v1.estimator.inputs instead.\n",
      "\u001b[36m7828rhrjz9-algo-1-9g2mh |\u001b[0m \n",
      "\u001b[36m7828rhrjz9-algo-1-9g2mh |\u001b[0m 2021-05-14 10:19:51,755 sagemaker-containers INFO     Imported framework sagemaker_tensorflow_container.training\n",
      "\u001b[36m7828rhrjz9-algo-1-9g2mh |\u001b[0m 2021-05-14 10:19:51,771 sagemaker-containers INFO     No GPUs detected (normal if no gpus installed)\n",
      "\u001b[36m7828rhrjz9-algo-1-9g2mh |\u001b[0m 2021-05-14 10:19:52,276 sagemaker-containers INFO     No GPUs detected (normal if no gpus installed)\n",
      "\u001b[36m7828rhrjz9-algo-1-9g2mh |\u001b[0m 2021-05-14 10:19:52,333 sagemaker-containers INFO     No GPUs detected (normal if no gpus installed)\n",
      "\u001b[36m7828rhrjz9-algo-1-9g2mh |\u001b[0m 2021-05-14 10:19:52,408 sagemaker-containers INFO     No GPUs detected (normal if no gpus installed)\n",
      "\u001b[36m7828rhrjz9-algo-1-9g2mh |\u001b[0m 2021-05-14 10:19:52,453 sagemaker-containers INFO     Invoking user script\n",
      "\u001b[36m7828rhrjz9-algo-1-9g2mh |\u001b[0m \n",
      "\u001b[36m7828rhrjz9-algo-1-9g2mh |\u001b[0m Training Env:\n",
      "\u001b[36m7828rhrjz9-algo-1-9g2mh |\u001b[0m \n",
      "\u001b[36m7828rhrjz9-algo-1-9g2mh |\u001b[0m {\n",
      "\u001b[36m7828rhrjz9-algo-1-9g2mh |\u001b[0m     \"additional_framework_parameters\": {},\n",
      "\u001b[36m7828rhrjz9-algo-1-9g2mh |\u001b[0m     \"channel_input_dirs\": {\n",
      "\u001b[36m7828rhrjz9-algo-1-9g2mh |\u001b[0m         \"train\": \"/opt/ml/input/data/train\",\n",
      "\u001b[36m7828rhrjz9-algo-1-9g2mh |\u001b[0m         \"validation\": \"/opt/ml/input/data/validation\",\n",
      "\u001b[36m7828rhrjz9-algo-1-9g2mh |\u001b[0m         \"eval\": \"/opt/ml/input/data/eval\"\n",
      "\u001b[36m7828rhrjz9-algo-1-9g2mh |\u001b[0m     },\n",
      "\u001b[36m7828rhrjz9-algo-1-9g2mh |\u001b[0m     \"current_host\": \"algo-1-9g2mh\",\n",
      "\u001b[36m7828rhrjz9-algo-1-9g2mh |\u001b[0m     \"framework_module\": \"sagemaker_tensorflow_container.training:main\",\n",
      "\u001b[36m7828rhrjz9-algo-1-9g2mh |\u001b[0m     \"hosts\": [\n",
      "\u001b[36m7828rhrjz9-algo-1-9g2mh |\u001b[0m         \"algo-1-9g2mh\"\n",
      "\u001b[36m7828rhrjz9-algo-1-9g2mh |\u001b[0m     ],\n",
      "\u001b[36m7828rhrjz9-algo-1-9g2mh |\u001b[0m     \"hyperparameters\": {\n",
      "\u001b[36m7828rhrjz9-algo-1-9g2mh |\u001b[0m         \"epochs\": 1,\n",
      "\u001b[36m7828rhrjz9-algo-1-9g2mh |\u001b[0m         \"batch-size\": 64,\n",
      "\u001b[36m7828rhrjz9-algo-1-9g2mh |\u001b[0m         \"model_dir\": \"s3://sagemaker-ap-southeast-2-987959606453/tensorflow-training-2021-05-14-10-19-37-516/model\"\n",
      "\u001b[36m7828rhrjz9-algo-1-9g2mh |\u001b[0m     },\n",
      "\u001b[36m7828rhrjz9-algo-1-9g2mh |\u001b[0m     \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "\u001b[36m7828rhrjz9-algo-1-9g2mh |\u001b[0m     \"input_data_config\": {\n",
      "\u001b[36m7828rhrjz9-algo-1-9g2mh |\u001b[0m         \"train\": {\n",
      "\u001b[36m7828rhrjz9-algo-1-9g2mh |\u001b[0m             \"TrainingInputMode\": \"File\"\n",
      "\u001b[36m7828rhrjz9-algo-1-9g2mh |\u001b[0m         },\n",
      "\u001b[36m7828rhrjz9-algo-1-9g2mh |\u001b[0m         \"validation\": {\n",
      "\u001b[36m7828rhrjz9-algo-1-9g2mh |\u001b[0m             \"TrainingInputMode\": \"File\"\n",
      "\u001b[36m7828rhrjz9-algo-1-9g2mh |\u001b[0m         },\n",
      "\u001b[36m7828rhrjz9-algo-1-9g2mh |\u001b[0m         \"eval\": {\n",
      "\u001b[36m7828rhrjz9-algo-1-9g2mh |\u001b[0m             \"TrainingInputMode\": \"File\"\n",
      "\u001b[36m7828rhrjz9-algo-1-9g2mh |\u001b[0m         }\n",
      "\u001b[36m7828rhrjz9-algo-1-9g2mh |\u001b[0m     },\n",
      "\u001b[36m7828rhrjz9-algo-1-9g2mh |\u001b[0m     \"input_dir\": \"/opt/ml/input\",\n",
      "\u001b[36m7828rhrjz9-algo-1-9g2mh |\u001b[0m     \"is_master\": true,\n",
      "\u001b[36m7828rhrjz9-algo-1-9g2mh |\u001b[0m     \"job_name\": \"tensorflow-training-2021-05-14-10-19-37-516\",\n",
      "\u001b[36m7828rhrjz9-algo-1-9g2mh |\u001b[0m     \"log_level\": 20,\n",
      "\u001b[36m7828rhrjz9-algo-1-9g2mh |\u001b[0m     \"master_hostname\": \"algo-1-9g2mh\",\n",
      "\u001b[36m7828rhrjz9-algo-1-9g2mh |\u001b[0m     \"model_dir\": \"/opt/ml/model\",\n",
      "\u001b[36m7828rhrjz9-algo-1-9g2mh |\u001b[0m     \"module_dir\": \"s3://sagemaker-ap-southeast-2-987959606453/tensorflow-training-2021-05-14-10-19-37-516/source/sourcedir.tar.gz\",\n",
      "\u001b[36m7828rhrjz9-algo-1-9g2mh |\u001b[0m     \"module_name\": \"cifar10_keras_main\",\n",
      "\u001b[36m7828rhrjz9-algo-1-9g2mh |\u001b[0m     \"network_interface_name\": \"eth0\",\n",
      "\u001b[36m7828rhrjz9-algo-1-9g2mh |\u001b[0m     \"num_cpus\": 2,\n",
      "\u001b[36m7828rhrjz9-algo-1-9g2mh |\u001b[0m     \"num_gpus\": 0,\n",
      "\u001b[36m7828rhrjz9-algo-1-9g2mh |\u001b[0m     \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "\u001b[36m7828rhrjz9-algo-1-9g2mh |\u001b[0m     \"output_dir\": \"/opt/ml/output\",\n",
      "\u001b[36m7828rhrjz9-algo-1-9g2mh |\u001b[0m     \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "\u001b[36m7828rhrjz9-algo-1-9g2mh |\u001b[0m     \"resource_config\": {\n",
      "\u001b[36m7828rhrjz9-algo-1-9g2mh |\u001b[0m         \"current_host\": \"algo-1-9g2mh\",\n",
      "\u001b[36m7828rhrjz9-algo-1-9g2mh |\u001b[0m         \"hosts\": [\n",
      "\u001b[36m7828rhrjz9-algo-1-9g2mh |\u001b[0m             \"algo-1-9g2mh\"\n",
      "\u001b[36m7828rhrjz9-algo-1-9g2mh |\u001b[0m         ]\n",
      "\u001b[36m7828rhrjz9-algo-1-9g2mh |\u001b[0m     },\n",
      "\u001b[36m7828rhrjz9-algo-1-9g2mh |\u001b[0m     \"user_entry_point\": \"cifar10_keras_main.py\"\n",
      "\u001b[36m7828rhrjz9-algo-1-9g2mh |\u001b[0m }\n",
      "\u001b[36m7828rhrjz9-algo-1-9g2mh |\u001b[0m \n",
      "\u001b[36m7828rhrjz9-algo-1-9g2mh |\u001b[0m Environment variables:\n",
      "\u001b[36m7828rhrjz9-algo-1-9g2mh |\u001b[0m \n",
      "\u001b[36m7828rhrjz9-algo-1-9g2mh |\u001b[0m SM_HOSTS=[\"algo-1-9g2mh\"]\n",
      "\u001b[36m7828rhrjz9-algo-1-9g2mh |\u001b[0m SM_NETWORK_INTERFACE_NAME=eth0\n",
      "\u001b[36m7828rhrjz9-algo-1-9g2mh |\u001b[0m SM_HPS={\"batch-size\":64,\"epochs\":1,\"model_dir\":\"s3://sagemaker-ap-southeast-2-987959606453/tensorflow-training-2021-05-14-10-19-37-516/model\"}\n",
      "\u001b[36m7828rhrjz9-algo-1-9g2mh |\u001b[0m SM_USER_ENTRY_POINT=cifar10_keras_main.py\n",
      "\u001b[36m7828rhrjz9-algo-1-9g2mh |\u001b[0m SM_FRAMEWORK_PARAMS={}\n",
      "\u001b[36m7828rhrjz9-algo-1-9g2mh |\u001b[0m SM_RESOURCE_CONFIG={\"current_host\":\"algo-1-9g2mh\",\"hosts\":[\"algo-1-9g2mh\"]}\n",
      "\u001b[36m7828rhrjz9-algo-1-9g2mh |\u001b[0m SM_INPUT_DATA_CONFIG={\"eval\":{\"TrainingInputMode\":\"File\"},\"train\":{\"TrainingInputMode\":\"File\"},\"validation\":{\"TrainingInputMode\":\"File\"}}\n",
      "\u001b[36m7828rhrjz9-algo-1-9g2mh |\u001b[0m SM_OUTPUT_DATA_DIR=/opt/ml/output/data\n",
      "\u001b[36m7828rhrjz9-algo-1-9g2mh |\u001b[0m SM_CHANNELS=[\"eval\",\"train\",\"validation\"]\n",
      "\u001b[36m7828rhrjz9-algo-1-9g2mh |\u001b[0m SM_CURRENT_HOST=algo-1-9g2mh\n",
      "\u001b[36m7828rhrjz9-algo-1-9g2mh |\u001b[0m SM_MODULE_NAME=cifar10_keras_main\n",
      "\u001b[36m7828rhrjz9-algo-1-9g2mh |\u001b[0m SM_LOG_LEVEL=20\n",
      "\u001b[36m7828rhrjz9-algo-1-9g2mh |\u001b[0m SM_FRAMEWORK_MODULE=sagemaker_tensorflow_container.training:main\n",
      "\u001b[36m7828rhrjz9-algo-1-9g2mh |\u001b[0m SM_INPUT_DIR=/opt/ml/input\n",
      "\u001b[36m7828rhrjz9-algo-1-9g2mh |\u001b[0m SM_INPUT_CONFIG_DIR=/opt/ml/input/config\n",
      "\u001b[36m7828rhrjz9-algo-1-9g2mh |\u001b[0m SM_OUTPUT_DIR=/opt/ml/output\n",
      "\u001b[36m7828rhrjz9-algo-1-9g2mh |\u001b[0m SM_NUM_CPUS=2\n",
      "\u001b[36m7828rhrjz9-algo-1-9g2mh |\u001b[0m SM_NUM_GPUS=0\n",
      "\u001b[36m7828rhrjz9-algo-1-9g2mh |\u001b[0m SM_MODEL_DIR=/opt/ml/model\n",
      "\u001b[36m7828rhrjz9-algo-1-9g2mh |\u001b[0m SM_MODULE_DIR=s3://sagemaker-ap-southeast-2-987959606453/tensorflow-training-2021-05-14-10-19-37-516/source/sourcedir.tar.gz\n",
      "\u001b[36m7828rhrjz9-algo-1-9g2mh |\u001b[0m SM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"eval\":\"/opt/ml/input/data/eval\",\"train\":\"/opt/ml/input/data/train\",\"validation\":\"/opt/ml/input/data/validation\"},\"current_host\":\"algo-1-9g2mh\",\"framework_module\":\"sagemaker_tensorflow_container.training:main\",\"hosts\":[\"algo-1-9g2mh\"],\"hyperparameters\":{\"batch-size\":64,\"epochs\":1,\"model_dir\":\"s3://sagemaker-ap-southeast-2-987959606453/tensorflow-training-2021-05-14-10-19-37-516/model\"},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"eval\":{\"TrainingInputMode\":\"File\"},\"train\":{\"TrainingInputMode\":\"File\"},\"validation\":{\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"is_master\":true,\"job_name\":\"tensorflow-training-2021-05-14-10-19-37-516\",\"log_level\":20,\"master_hostname\":\"algo-1-9g2mh\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-ap-southeast-2-987959606453/tensorflow-training-2021-05-14-10-19-37-516/source/sourcedir.tar.gz\",\"module_name\":\"cifar10_keras_main\",\"network_interface_name\":\"eth0\",\"num_cpus\":2,\"num_gpus\":0,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_host\":\"algo-1-9g2mh\",\"hosts\":[\"algo-1-9g2mh\"]},\"user_entry_point\":\"cifar10_keras_main.py\"}\n",
      "\u001b[36m7828rhrjz9-algo-1-9g2mh |\u001b[0m SM_USER_ARGS=[\"--batch-size\",\"64\",\"--epochs\",\"1\",\"--model_dir\",\"s3://sagemaker-ap-southeast-2-987959606453/tensorflow-training-2021-05-14-10-19-37-516/model\"]\n",
      "\u001b[36m7828rhrjz9-algo-1-9g2mh |\u001b[0m SM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\n",
      "\u001b[36m7828rhrjz9-algo-1-9g2mh |\u001b[0m SM_CHANNEL_TRAIN=/opt/ml/input/data/train\n",
      "\u001b[36m7828rhrjz9-algo-1-9g2mh |\u001b[0m SM_CHANNEL_VALIDATION=/opt/ml/input/data/validation\n",
      "\u001b[36m7828rhrjz9-algo-1-9g2mh |\u001b[0m SM_CHANNEL_EVAL=/opt/ml/input/data/eval\n",
      "\u001b[36m7828rhrjz9-algo-1-9g2mh |\u001b[0m SM_HP_EPOCHS=1\n",
      "\u001b[36m7828rhrjz9-algo-1-9g2mh |\u001b[0m SM_HP_BATCH-SIZE=64\n",
      "\u001b[36m7828rhrjz9-algo-1-9g2mh |\u001b[0m SM_HP_MODEL_DIR=s3://sagemaker-ap-southeast-2-987959606453/tensorflow-training-2021-05-14-10-19-37-516/model\n",
      "\u001b[36m7828rhrjz9-algo-1-9g2mh |\u001b[0m PYTHONPATH=/opt/ml/code:/usr/local/bin:/usr/lib/python36.zip:/usr/lib/python3.6:/usr/lib/python3.6/lib-dynload:/usr/local/lib/python3.6/dist-packages:/usr/lib/python3/dist-packages\n",
      "\u001b[36m7828rhrjz9-algo-1-9g2mh |\u001b[0m \n",
      "\u001b[36m7828rhrjz9-algo-1-9g2mh |\u001b[0m Invoking script with the following command:\n",
      "\u001b[36m7828rhrjz9-algo-1-9g2mh |\u001b[0m \n",
      "\u001b[36m7828rhrjz9-algo-1-9g2mh |\u001b[0m /usr/bin/python3 cifar10_keras_main.py --batch-size 64 --epochs 1 --model_dir s3://sagemaker-ap-southeast-2-987959606453/tensorflow-training-2021-05-14-10-19-37-516/model\n",
      "\u001b[36m7828rhrjz9-algo-1-9g2mh |\u001b[0m \n",
      "\u001b[36m7828rhrjz9-algo-1-9g2mh |\u001b[0m \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m7828rhrjz9-algo-1-9g2mh |\u001b[0m Using TensorFlow backend.\n",
      "\u001b[36m7828rhrjz9-algo-1-9g2mh |\u001b[0m WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/__init__.py:1473: The name tf.estimator.inputs is deprecated. Please use tf.compat.v1.estimator.inputs instead.\n",
      "\u001b[36m7828rhrjz9-algo-1-9g2mh |\u001b[0m \n",
      "\u001b[36m7828rhrjz9-algo-1-9g2mh |\u001b[0m WARNING:tensorflow:From cifar10_keras_main.py:30: The name tf.logging.set_verbosity is deprecated. Please use tf.compat.v1.logging.set_verbosity instead.\n",
      "\u001b[36m7828rhrjz9-algo-1-9g2mh |\u001b[0m \n",
      "\u001b[36m7828rhrjz9-algo-1-9g2mh |\u001b[0m WARNING:tensorflow:From cifar10_keras_main.py:30: The name tf.logging.INFO is deprecated. Please use tf.compat.v1.logging.INFO instead.\n",
      "\u001b[36m7828rhrjz9-algo-1-9g2mh |\u001b[0m \n",
      "\u001b[36m7828rhrjz9-algo-1-9g2mh |\u001b[0m INFO:root:Writing TensorBoard logs to s3://sagemaker-ap-southeast-2-987959606453/tensorflow-training-2021-05-14-10-19-37-516/model\n",
      "\u001b[36m7828rhrjz9-algo-1-9g2mh |\u001b[0m INFO:root:Running with MPI=False\n",
      "\u001b[36m7828rhrjz9-algo-1-9g2mh |\u001b[0m INFO:root:getting data\n",
      "\u001b[36m7828rhrjz9-algo-1-9g2mh |\u001b[0m INFO:root:Running train in File mode\n",
      "\u001b[36m7828rhrjz9-algo-1-9g2mh |\u001b[0m WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.FixedLenFeature is deprecated. Please use tf.io.FixedLenFeature instead.\n",
      "\u001b[36m7828rhrjz9-algo-1-9g2mh |\u001b[0m \n",
      "\u001b[36m7828rhrjz9-algo-1-9g2mh |\u001b[0m WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.FixedLenFeature is deprecated. Please use tf.io.FixedLenFeature instead.\n",
      "\u001b[36m7828rhrjz9-algo-1-9g2mh |\u001b[0m \n",
      "\u001b[36m7828rhrjz9-algo-1-9g2mh |\u001b[0m WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.parse_single_example is deprecated. Please use tf.io.parse_single_example instead.\n",
      "\u001b[36m7828rhrjz9-algo-1-9g2mh |\u001b[0m \n",
      "\u001b[36m7828rhrjz9-algo-1-9g2mh |\u001b[0m WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.parse_single_example is deprecated. Please use tf.io.parse_single_example instead.\n",
      "\u001b[36m7828rhrjz9-algo-1-9g2mh |\u001b[0m \n",
      "\u001b[36m7828rhrjz9-algo-1-9g2mh |\u001b[0m WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.image.resize_image_with_crop_or_pad is deprecated. Please use tf.image.resize_with_crop_or_pad instead.\n",
      "\u001b[36m7828rhrjz9-algo-1-9g2mh |\u001b[0m \n",
      "\u001b[36m7828rhrjz9-algo-1-9g2mh |\u001b[0m WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.image.resize_image_with_crop_or_pad is deprecated. Please use tf.image.resize_with_crop_or_pad instead.\n",
      "\u001b[36m7828rhrjz9-algo-1-9g2mh |\u001b[0m \n",
      "\u001b[36m7828rhrjz9-algo-1-9g2mh |\u001b[0m WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.random_crop is deprecated. Please use tf.image.random_crop instead.\n",
      "\u001b[36m7828rhrjz9-algo-1-9g2mh |\u001b[0m \n",
      "\u001b[36m7828rhrjz9-algo-1-9g2mh |\u001b[0m WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.random_crop is deprecated. Please use tf.image.random_crop instead.\n",
      "\u001b[36m7828rhrjz9-algo-1-9g2mh |\u001b[0m \n",
      "\u001b[36m7828rhrjz9-algo-1-9g2mh |\u001b[0m INFO:root:Running eval in File mode\n",
      "\u001b[36m7828rhrjz9-algo-1-9g2mh |\u001b[0m INFO:root:Running validation in File mode\n",
      "\u001b[36m7828rhrjz9-algo-1-9g2mh |\u001b[0m INFO:root:configuring model\n",
      "\u001b[36m7828rhrjz9-algo-1-9g2mh |\u001b[0m WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "\u001b[36m7828rhrjz9-algo-1-9g2mh |\u001b[0m Instructions for updating:\n",
      "\u001b[36m7828rhrjz9-algo-1-9g2mh |\u001b[0m If using Keras pass *_constraint arguments to layers.\n",
      "\u001b[36m7828rhrjz9-algo-1-9g2mh |\u001b[0m WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "\u001b[36m7828rhrjz9-algo-1-9g2mh |\u001b[0m Instructions for updating:\n",
      "\u001b[36m7828rhrjz9-algo-1-9g2mh |\u001b[0m If using Keras pass *_constraint arguments to layers.\n",
      "\u001b[36m7828rhrjz9-algo-1-9g2mh |\u001b[0m WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4070: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\u001b[36m7828rhrjz9-algo-1-9g2mh |\u001b[0m \n",
      "\u001b[36m7828rhrjz9-algo-1-9g2mh |\u001b[0m WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4070: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\u001b[36m7828rhrjz9-algo-1-9g2mh |\u001b[0m \n",
      "\u001b[36m7828rhrjz9-algo-1-9g2mh |\u001b[0m INFO:root:Starting training\n",
      "\u001b[36m7828rhrjz9-algo-1-9g2mh |\u001b[0m WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\u001b[36m7828rhrjz9-algo-1-9g2mh |\u001b[0m \n",
      "\u001b[36m7828rhrjz9-algo-1-9g2mh |\u001b[0m WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\u001b[36m7828rhrjz9-algo-1-9g2mh |\u001b[0m \n",
      "\u001b[36m7828rhrjz9-algo-1-9g2mh |\u001b[0m Train on 64 samples, validate on 64 samples\n",
      "\u001b[36m7828rhrjz9-algo-1-9g2mh |\u001b[0m WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/callbacks/tensorboard_v1.py:200: The name tf.summary.merge_all is deprecated. Please use tf.compat.v1.summary.merge_all instead.\n",
      "\u001b[36m7828rhrjz9-algo-1-9g2mh |\u001b[0m \n",
      "\u001b[36m7828rhrjz9-algo-1-9g2mh |\u001b[0m WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/callbacks/tensorboard_v1.py:200: The name tf.summary.merge_all is deprecated. Please use tf.compat.v1.summary.merge_all instead.\n",
      "\u001b[36m7828rhrjz9-algo-1-9g2mh |\u001b[0m \n",
      "\u001b[36m7828rhrjz9-algo-1-9g2mh |\u001b[0m WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/callbacks/tensorboard_v1.py:203: The name tf.summary.FileWriter is deprecated. Please use tf.compat.v1.summary.FileWriter instead.\n",
      "\u001b[36m7828rhrjz9-algo-1-9g2mh |\u001b[0m \n",
      "\u001b[36m7828rhrjz9-algo-1-9g2mh |\u001b[0m WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/callbacks/tensorboard_v1.py:203: The name tf.summary.FileWriter is deprecated. Please use tf.compat.v1.summary.FileWriter instead.\n",
      "\u001b[36m7828rhrjz9-algo-1-9g2mh |\u001b[0m \n",
      "\u001b[36m7828rhrjz9-algo-1-9g2mh |\u001b[0m Epoch 1/1\n",
      "625/625 [==============================] - 485s 775ms/step - loss: 0.0150 - accuracy: 0.9959 - val_loss: 0.0138 - val_accuracy: 93.4043\n",
      "\u001b[36m7828rhrjz9-algo-1-9g2mh |\u001b[0m WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/callbacks/tensorboard_v1.py:343: The name tf.Summary is deprecated. Please use tf.compat.v1.Summary instead.\n",
      "\u001b[36m7828rhrjz9-algo-1-9g2mh |\u001b[0m \n",
      "\u001b[36m7828rhrjz9-algo-1-9g2mh |\u001b[0m WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/callbacks/tensorboard_v1.py:343: The name tf.Summary is deprecated. Please use tf.compat.v1.Summary instead.\n",
      "\u001b[36m7828rhrjz9-algo-1-9g2mh |\u001b[0m \n",
      "\u001b[36m7828rhrjz9-algo-1-9g2mh |\u001b[0m INFO:root:Test loss:0.10140141462668395\n",
      "\u001b[36m7828rhrjz9-algo-1-9g2mh |\u001b[0m INFO:root:Test accuracy:0.0\n",
      "\u001b[36m7828rhrjz9-algo-1-9g2mh |\u001b[0m WARNING:tensorflow:From cifar10_keras_main.py:189: The name tf.saved_model.signature_def_utils.predict_signature_def is deprecated. Please use tf.compat.v1.saved_model.signature_def_utils.predict_signature_def instead.\n",
      "\u001b[36m7828rhrjz9-algo-1-9g2mh |\u001b[0m \n",
      "\u001b[36m7828rhrjz9-algo-1-9g2mh |\u001b[0m WARNING:tensorflow:From cifar10_keras_main.py:189: The name tf.saved_model.signature_def_utils.predict_signature_def is deprecated. Please use tf.compat.v1.saved_model.signature_def_utils.predict_signature_def instead.\n",
      "\u001b[36m7828rhrjz9-algo-1-9g2mh |\u001b[0m \n",
      "\u001b[36m7828rhrjz9-algo-1-9g2mh |\u001b[0m WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/saved_model/signature_def_utils_impl.py:201: build_tensor_info (from tensorflow.python.saved_model.utils_impl) is deprecated and will be removed in a future version.\n",
      "\u001b[36m7828rhrjz9-algo-1-9g2mh |\u001b[0m Instructions for updating:\n",
      "\u001b[36m7828rhrjz9-algo-1-9g2mh |\u001b[0m This function will only be available through the v1 compatibility library as tf.compat.v1.saved_model.utils.build_tensor_info or tf.compat.v1.saved_model.build_tensor_info.\n",
      "\u001b[36m7828rhrjz9-algo-1-9g2mh |\u001b[0m WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/saved_model/signature_def_utils_impl.py:201: build_tensor_info (from tensorflow.python.saved_model.utils_impl) is deprecated and will be removed in a future version.\n",
      "\u001b[36m7828rhrjz9-algo-1-9g2mh |\u001b[0m Instructions for updating:\n",
      "\u001b[36m7828rhrjz9-algo-1-9g2mh |\u001b[0m This function will only be available through the v1 compatibility library as tf.compat.v1.saved_model.utils.build_tensor_info or tf.compat.v1.saved_model.build_tensor_info.\n",
      "\u001b[36m7828rhrjz9-algo-1-9g2mh |\u001b[0m WARNING:tensorflow:From cifar10_keras_main.py:193: The name tf.saved_model.builder.SavedModelBuilder is deprecated. Please use tf.compat.v1.saved_model.builder.SavedModelBuilder instead.\n",
      "\u001b[36m7828rhrjz9-algo-1-9g2mh |\u001b[0m \n",
      "\u001b[36m7828rhrjz9-algo-1-9g2mh |\u001b[0m WARNING:tensorflow:From cifar10_keras_main.py:193: The name tf.saved_model.builder.SavedModelBuilder is deprecated. Please use tf.compat.v1.saved_model.builder.SavedModelBuilder instead.\n",
      "\u001b[36m7828rhrjz9-algo-1-9g2mh |\u001b[0m \n",
      "\u001b[36m7828rhrjz9-algo-1-9g2mh |\u001b[0m WARNING:tensorflow:From cifar10_keras_main.py:196: The name tf.saved_model.tag_constants.SERVING is deprecated. Please use tf.saved_model.SERVING instead.\n",
      "\u001b[36m7828rhrjz9-algo-1-9g2mh |\u001b[0m \n",
      "\u001b[36m7828rhrjz9-algo-1-9g2mh |\u001b[0m WARNING:tensorflow:From cifar10_keras_main.py:196: The name tf.saved_model.tag_constants.SERVING is deprecated. Please use tf.saved_model.SERVING instead.\n",
      "\u001b[36m7828rhrjz9-algo-1-9g2mh |\u001b[0m \n",
      "\u001b[36m7828rhrjz9-algo-1-9g2mh |\u001b[0m WARNING:tensorflow:From cifar10_keras_main.py:198: The name tf.saved_model.signature_constants.DEFAULT_SERVING_SIGNATURE_DEF_KEY is deprecated. Please use tf.saved_model.DEFAULT_SERVING_SIGNATURE_DEF_KEY instead.\n",
      "\u001b[36m7828rhrjz9-algo-1-9g2mh |\u001b[0m \n",
      "\u001b[36m7828rhrjz9-algo-1-9g2mh |\u001b[0m WARNING:tensorflow:From cifar10_keras_main.py:198: The name tf.saved_model.signature_constants.DEFAULT_SERVING_SIGNATURE_DEF_KEY is deprecated. Please use tf.saved_model.DEFAULT_SERVING_SIGNATURE_DEF_KEY instead.\n",
      "\u001b[36m7828rhrjz9-algo-1-9g2mh |\u001b[0m \n",
      "\u001b[36m7828rhrjz9-algo-1-9g2mh |\u001b[0m INFO:tensorflow:No assets to save.\n",
      "\u001b[36m7828rhrjz9-algo-1-9g2mh |\u001b[0m INFO:tensorflow:No assets to save.\n",
      "\u001b[36m7828rhrjz9-algo-1-9g2mh |\u001b[0m INFO:tensorflow:No assets to write.\n",
      "\u001b[36m7828rhrjz9-algo-1-9g2mh |\u001b[0m INFO:tensorflow:No assets to write.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m7828rhrjz9-algo-1-9g2mh |\u001b[0m INFO:tensorflow:SavedModel written to: /opt/ml/model/1/saved_model.pb\n",
      "\u001b[36m7828rhrjz9-algo-1-9g2mh |\u001b[0m INFO:tensorflow:SavedModel written to: /opt/ml/model/1/saved_model.pb\n",
      "\u001b[36m7828rhrjz9-algo-1-9g2mh |\u001b[0m INFO:root:Model successfully saved at: /opt/ml/model\n",
      "\u001b[36m7828rhrjz9-algo-1-9g2mh |\u001b[0m 2021-05-14 10:29:48,019 sagemaker-containers INFO     Reporting training SUCCESS\n",
      "\u001b[36m7828rhrjz9-algo-1-9g2mh exited with code 0\n",
      "\u001b[0mAborting on container exit...\n",
      "===== Job Complete =====\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "data_path = os.path.join(os.getcwd(), 'data')\n",
    "\n",
    "local_inputs = {\n",
    "    'train': 'file://{}/train'.format(data_path),\n",
    "    'validation': 'file://{}/validation'.format(data_path),\n",
    "    'eval': 'file://{}/eval'.format(data_path),\n",
    "}\n",
    "estimator.fit(local_inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run a baseline training job on SageMaker\n",
    "\n",
    "Now we run training jobs on SageMaker, starting with our baseline training job."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configure metrics\n",
    "\n",
    "In addition to running the training job, Amazon SageMaker can retrieve training metrics directly from the logs and send them to CloudWatch metrics. Here, we define metrics we would like to observe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_definitions = [\n",
    "    {'Name': 'train:loss', 'Regex': '.*loss: ([0-9\\\\.]+) - accuracy: [0-9\\\\.]+.*'},\n",
    "    {'Name': 'train:accuracy', 'Regex': '.*loss: [0-9\\\\.]+ - accuracy: ([0-9\\\\.]+).*'},\n",
    "    {'Name': 'validation:accuracy', 'Regex': '.*step - loss: [0-9\\\\.]+ - accuracy: [0-9\\\\.]+ - val_loss: [0-9\\\\.]+ - val_accuracy: ([0-9\\\\.]+).*'},\n",
    "    {'Name': 'validation:loss', 'Regex': '.*step - loss: [0-9\\\\.]+ - accuracy: [0-9\\\\.]+ - val_loss: ([0-9\\\\.]+) - val_accuracy: [0-9\\\\.]+.*'},\n",
    "    {'Name': 'sec/steps', 'Regex': '.* - \\d+s (\\d+)[mu]s/step - loss: [0-9\\\\.]+ - accuracy: [0-9\\\\.]+ - val_loss: [0-9\\\\.]+ - val_accuracy: [0-9\\\\.]+'}\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once again, we create a TensorFlow estimator, with a couple key modfications from last time:\n",
    "\n",
    "* `train_instance_type`: the instance type for training. We set this to `ml.p2.xlarge` because we are training on SageMaker now. For a list of available instance types, see [the AWS documentation](https://aws.amazon.com/sagemaker/pricing/instance-types).\n",
    "* `metric_definitions`: the metrics (defined above) that we want sent to CloudWatch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train_instance_type has been renamed in sagemaker>=2.\n",
      "See: https://sagemaker.readthedocs.io/en/stable/v2.html for details.\n",
      "train_instance_count has been renamed in sagemaker>=2.\n",
      "See: https://sagemaker.readthedocs.io/en/stable/v2.html for details.\n",
      "train_instance_type has been renamed in sagemaker>=2.\n",
      "See: https://sagemaker.readthedocs.io/en/stable/v2.html for details.\n"
     ]
    }
   ],
   "source": [
    "from sagemaker.tensorflow import TensorFlow\n",
    "\n",
    "hyperparameters = {'epochs': 10, 'batch-size': 256}\n",
    "tags = [{'Key': 'Project', 'Value': 'cifar10'}, {'Key': 'TensorBoard', 'Value': 'file'}]\n",
    "\n",
    "estimator = TensorFlow(entry_point='cifar10_keras_main.py',\n",
    "                       source_dir='source_dir',\n",
    "                       metric_definitions=metric_definitions,\n",
    "                       hyperparameters=hyperparameters,\n",
    "                       role=role,\n",
    "                       framework_version='1.15.2',\n",
    "                       py_version='py3',\n",
    "                       train_instance_count=1,\n",
    "                       train_instance_type='ml.m4.xlarge', # changed from ml.p2.xlarge to ml.m4.xlarge due to \n",
    "                                                           # Free Tier allowances\n",
    "                       base_job_name='cifar10-tf',\n",
    "                       tags=tags)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Like before, we call `fit()` to start the SageMaker training job and pass the inputs in a dictionary to define different data channels for training. This time, we use the S3 URI from uploading our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-14 10:37:03 Starting - Starting the training job...\n",
      "2021-05-14 10:37:27 Starting - Launching requested ML instancesProfilerReport-1620988623: InProgress\n",
      "......\n",
      "2021-05-14 10:38:29 Starting - Preparing the instances for training.........\n",
      "2021-05-14 10:39:55 Downloading - Downloading input data\n",
      "2021-05-14 10:39:55 Training - Downloading the training image...\n",
      "2021-05-14 10:40:28 Training - Training image download completed. Training in progress.\u001b[34mWARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/__init__.py:1473: The name tf.estimator.inputs is deprecated. Please use tf.compat.v1.estimator.inputs instead.\n",
      "\u001b[0m\n",
      "\u001b[34m2021-05-14 10:40:21,562 sagemaker-containers INFO     Imported framework sagemaker_tensorflow_container.training\u001b[0m\n",
      "\u001b[34m2021-05-14 10:40:21,570 sagemaker-containers INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2021-05-14 10:40:22,032 sagemaker-containers INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2021-05-14 10:40:22,053 sagemaker-containers INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2021-05-14 10:40:22,074 sagemaker-containers INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2021-05-14 10:40:22,087 sagemaker-containers INFO     Invoking user script\n",
      "\u001b[0m\n",
      "\u001b[34mTraining Env:\n",
      "\u001b[0m\n",
      "\u001b[34m{\n",
      "    \"additional_framework_parameters\": {},\n",
      "    \"channel_input_dirs\": {\n",
      "        \"eval\": \"/opt/ml/input/data/eval\",\n",
      "        \"validation\": \"/opt/ml/input/data/validation\",\n",
      "        \"train\": \"/opt/ml/input/data/train\"\n",
      "    },\n",
      "    \"current_host\": \"algo-1\",\n",
      "    \"framework_module\": \"sagemaker_tensorflow_container.training:main\",\n",
      "    \"hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"hyperparameters\": {\n",
      "        \"batch-size\": 256,\n",
      "        \"model_dir\": \"s3://sagemaker-ap-southeast-2-987959606453/cifar10-tf-2021-05-14-10-37-03-005/model\",\n",
      "        \"epochs\": 10\n",
      "    },\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"input_data_config\": {\n",
      "        \"eval\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        },\n",
      "        \"validation\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        },\n",
      "        \"train\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        }\n",
      "    },\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"is_master\": true,\n",
      "    \"job_name\": \"cifar10-tf-2021-05-14-10-37-03-005\",\n",
      "    \"log_level\": 20,\n",
      "    \"master_hostname\": \"algo-1\",\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"module_dir\": \"s3://sagemaker-ap-southeast-2-987959606453/cifar10-tf-2021-05-14-10-37-03-005/source/sourcedir.tar.gz\",\n",
      "    \"module_name\": \"cifar10_keras_main\",\n",
      "    \"network_interface_name\": \"eth0\",\n",
      "    \"num_cpus\": 4,\n",
      "    \"num_gpus\": 0,\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"resource_config\": {\n",
      "        \"current_host\": \"algo-1\",\n",
      "        \"hosts\": [\n",
      "            \"algo-1\"\n",
      "        ],\n",
      "        \"network_interface_name\": \"eth0\"\n",
      "    },\n",
      "    \"user_entry_point\": \"cifar10_keras_main.py\"\u001b[0m\n",
      "\u001b[34m}\n",
      "\u001b[0m\n",
      "\u001b[34mEnvironment variables:\n",
      "\u001b[0m\n",
      "\u001b[34mSM_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[34mSM_NETWORK_INTERFACE_NAME=eth0\u001b[0m\n",
      "\u001b[34mSM_HPS={\"batch-size\":256,\"epochs\":10,\"model_dir\":\"s3://sagemaker-ap-southeast-2-987959606453/cifar10-tf-2021-05-14-10-37-03-005/model\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ENTRY_POINT=cifar10_keras_main.py\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_PARAMS={}\u001b[0m\n",
      "\u001b[34mSM_RESOURCE_CONFIG={\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"eth0\"}\u001b[0m\n",
      "\u001b[34mSM_INPUT_DATA_CONFIG={\"eval\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"train\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"validation\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}}\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DATA_DIR=/opt/ml/output/data\u001b[0m\n",
      "\u001b[34mSM_CHANNELS=[\"eval\",\"train\",\"validation\"]\u001b[0m\n",
      "\u001b[34mSM_CURRENT_HOST=algo-1\u001b[0m\n",
      "\u001b[34mSM_MODULE_NAME=cifar10_keras_main\u001b[0m\n",
      "\u001b[34mSM_LOG_LEVEL=20\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_MODULE=sagemaker_tensorflow_container.training:main\u001b[0m\n",
      "\u001b[34mSM_INPUT_DIR=/opt/ml/input\u001b[0m\n",
      "\u001b[34mSM_INPUT_CONFIG_DIR=/opt/ml/input/config\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DIR=/opt/ml/output\u001b[0m\n",
      "\u001b[34mSM_NUM_CPUS=4\u001b[0m\n",
      "\u001b[34mSM_NUM_GPUS=0\u001b[0m\n",
      "\u001b[34mSM_MODEL_DIR=/opt/ml/model\u001b[0m\n",
      "\u001b[34mSM_MODULE_DIR=s3://sagemaker-ap-southeast-2-987959606453/cifar10-tf-2021-05-14-10-37-03-005/source/sourcedir.tar.gz\u001b[0m\n",
      "\u001b[34mSM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"eval\":\"/opt/ml/input/data/eval\",\"train\":\"/opt/ml/input/data/train\",\"validation\":\"/opt/ml/input/data/validation\"},\"current_host\":\"algo-1\",\"framework_module\":\"sagemaker_tensorflow_container.training:main\",\"hosts\":[\"algo-1\"],\"hyperparameters\":{\"batch-size\":256,\"epochs\":10,\"model_dir\":\"s3://sagemaker-ap-southeast-2-987959606453/cifar10-tf-2021-05-14-10-37-03-005/model\"},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"eval\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"train\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"validation\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"is_master\":true,\"job_name\":\"cifar10-tf-2021-05-14-10-37-03-005\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-ap-southeast-2-987959606453/cifar10-tf-2021-05-14-10-37-03-005/source/sourcedir.tar.gz\",\"module_name\":\"cifar10_keras_main\",\"network_interface_name\":\"eth0\",\"num_cpus\":4,\"num_gpus\":0,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"cifar10_keras_main.py\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ARGS=[\"--batch-size\",\"256\",\"--epochs\",\"10\",\"--model_dir\",\"s3://sagemaker-ap-southeast-2-987959606453/cifar10-tf-2021-05-14-10-37-03-005/model\"]\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_EVAL=/opt/ml/input/data/eval\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_VALIDATION=/opt/ml/input/data/validation\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_TRAIN=/opt/ml/input/data/train\u001b[0m\n",
      "\u001b[34mSM_HP_BATCH-SIZE=256\u001b[0m\n",
      "\u001b[34mSM_HP_MODEL_DIR=s3://sagemaker-ap-southeast-2-987959606453/cifar10-tf-2021-05-14-10-37-03-005/model\u001b[0m\n",
      "\u001b[34mSM_HP_EPOCHS=10\u001b[0m\n",
      "\u001b[34mPYTHONPATH=/opt/ml/code:/usr/local/bin:/usr/lib/python36.zip:/usr/lib/python3.6:/usr/lib/python3.6/lib-dynload:/usr/local/lib/python3.6/dist-packages:/usr/lib/python3/dist-packages\n",
      "\u001b[0m\n",
      "\u001b[34mInvoking script with the following command:\n",
      "\u001b[0m\n",
      "\u001b[34m/usr/bin/python3 cifar10_keras_main.py --batch-size 256 --epochs 10 --model_dir s3://sagemaker-ap-southeast-2-987959606453/cifar10-tf-2021-05-14-10-37-03-005/model\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[34mUsing TensorFlow backend.\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/__init__.py:1473: The name tf.estimator.inputs is deprecated. Please use tf.compat.v1.estimator.inputs instead.\n",
      "\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:From cifar10_keras_main.py:30: The name tf.logging.set_verbosity is deprecated. Please use tf.compat.v1.logging.set_verbosity instead.\n",
      "\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:From cifar10_keras_main.py:30: The name tf.logging.INFO is deprecated. Please use tf.compat.v1.logging.INFO instead.\n",
      "\u001b[0m\n",
      "\u001b[34mINFO:root:Writing TensorBoard logs to s3://sagemaker-ap-southeast-2-987959606453/cifar10-tf-2021-05-14-10-37-03-005/model\u001b[0m\n",
      "\u001b[34mINFO:root:Running with MPI=False\u001b[0m\n",
      "\u001b[34mINFO:root:getting data\u001b[0m\n",
      "\u001b[34mINFO:root:Running train in File mode\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.FixedLenFeature is deprecated. Please use tf.io.FixedLenFeature instead.\n",
      "\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.FixedLenFeature is deprecated. Please use tf.io.FixedLenFeature instead.\n",
      "\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.parse_single_example is deprecated. Please use tf.io.parse_single_example instead.\n",
      "\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.parse_single_example is deprecated. Please use tf.io.parse_single_example instead.\n",
      "\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.image.resize_image_with_crop_or_pad is deprecated. Please use tf.image.resize_with_crop_or_pad instead.\n",
      "\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.image.resize_image_with_crop_or_pad is deprecated. Please use tf.image.resize_with_crop_or_pad instead.\n",
      "\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.random_crop is deprecated. Please use tf.image.random_crop instead.\n",
      "\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.random_crop is deprecated. Please use tf.image.random_crop instead.\n",
      "\u001b[0m\n",
      "\u001b[34mINFO:root:Running eval in File mode\u001b[0m\n",
      "\u001b[34mINFO:root:Running validation in File mode\u001b[0m\n",
      "\u001b[34mINFO:root:configuring model\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34mInstructions for updating:\u001b[0m\n",
      "\u001b[34mIf using Keras pass *_constraint arguments to layers.\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34mInstructions for updating:\u001b[0m\n",
      "\u001b[34mIf using Keras pass *_constraint arguments to layers.\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4070: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4070: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\u001b[0m\n",
      "\u001b[34mINFO:root:Starting training\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\u001b[0m\n",
      "\u001b[34mTrain on 256 samples, validate on 256 samples\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/callbacks/tensorboard_v1.py:200: The name tf.summary.merge_all is deprecated. Please use tf.compat.v1.summary.merge_all instead.\n",
      "\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/callbacks/tensorboard_v1.py:200: The name tf.summary.merge_all is deprecated. Please use tf.compat.v1.summary.merge_all instead.\n",
      "\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/callbacks/tensorboard_v1.py:203: The name tf.summary.FileWriter is deprecated. Please use tf.compat.v1.summary.FileWriter instead.\n",
      "\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/callbacks/tensorboard_v1.py:203: The name tf.summary.FileWriter is deprecated. Please use tf.compat.v1.summary.FileWriter instead.\n",
      "\u001b[0m\n",
      "\u001b[34mEpoch 1/10\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m  1/156 [..............................] - ETA: 25:45 - loss: 4.5213 - accuracy: 0.0859\u001b[0m\n",
      "\u001b[34m  2/156 [..............................] - ETA: 13:49 - loss: 2.9989 - accuracy: 0.2734\u001b[0m\n",
      "\u001b[34m  3/156 [..............................] - ETA: 9:50 - loss: 2.2958 - accuracy: 0.4258 \u001b[0m\n",
      "\u001b[34m  4/156 [..............................] - ETA: 7:52 - loss: 1.8657 - accuracy: 0.5068\u001b[0m\n",
      "\u001b[34m  5/156 [..............................] - ETA: 6:43 - loss: 1.5480 - accuracy: 0.5836\n",
      "  6/156 [>.............................] - ETA: 5:55 - loss: 1.3169 - accuracy: 0.6432\u001b[0m\n",
      "\u001b[34m  7/156 [>.............................] - ETA: 5:22 - loss: 1.1484 - accuracy: 0.6864\u001b[0m\n",
      "\u001b[34m  8/156 [>.............................] - ETA: 4:59 - loss: 1.0127 - accuracy: 0.7236\u001b[0m\n",
      "\u001b[34m  9/156 [>.............................] - ETA: 4:38 - loss: 0.9032 - accuracy: 0.7543\u001b[0m\n",
      "\u001b[34m 10/156 [>.............................] - ETA: 4:22 - loss: 0.8153 - accuracy: 0.7781\u001b[0m\n",
      "\u001b[34m 11/156 [=>............................] - ETA: 4:08 - loss: 0.7423 - accuracy: 0.7983\u001b[0m\n",
      "\u001b[34m 12/156 [=>............................] - ETA: 3:57 - loss: 0.6813 - accuracy: 0.8151\u001b[0m\n",
      "\u001b[34m 13/156 [=>............................] - ETA: 3:46 - loss: 0.6295 - accuracy: 0.8293\u001b[0m\n",
      "\u001b[34m 14/156 [=>............................] - ETA: 3:37 - loss: 0.5851 - accuracy: 0.8415\n",
      " 15/156 [=>............................] - ETA: 3:29 - loss: 0.5465 - accuracy: 0.8521\u001b[0m\n",
      "\u001b[34m 16/156 [==>...........................] - ETA: 3:22 - loss: 0.5129 - accuracy: 0.8613\u001b[0m\n",
      "\u001b[34m 17/156 [==>...........................] - ETA: 3:16 - loss: 0.4830 - accuracy: 0.8695\u001b[0m\n",
      "\u001b[34m 18/156 [==>...........................] - ETA: 3:10 - loss: 0.4566 - accuracy: 0.8767\u001b[0m\n",
      "\u001b[34m 19/156 [==>...........................] - ETA: 3:05 - loss: 0.4328 - accuracy: 0.8832\u001b[0m\n",
      "\u001b[34m 20/156 [==>...........................] - ETA: 3:01 - loss: 0.4115 - accuracy: 0.8891\u001b[0m\n",
      "\u001b[34m 21/156 [===>..........................] - ETA: 2:56 - loss: 0.3920 - accuracy: 0.8943\u001b[0m\n",
      "\u001b[34m 22/156 [===>..........................] - ETA: 2:53 - loss: 0.3743 - accuracy: 0.8991\n",
      " 23/156 [===>..........................] - ETA: 2:49 - loss: 0.3583 - accuracy: 0.9035\u001b[0m\n",
      "\u001b[34m 24/156 [===>..........................] - ETA: 2:45 - loss: 0.3435 - accuracy: 0.9076\u001b[0m\n",
      "\u001b[34m 25/156 [===>..........................] - ETA: 2:42 - loss: 0.3300 - accuracy: 0.9112\u001b[0m\n",
      "\u001b[34m 26/156 [====>.........................] - ETA: 2:40 - loss: 0.3174 - accuracy: 0.9147\u001b[0m\n",
      "\u001b[34m 27/156 [====>.........................] - ETA: 2:37 - loss: 0.3057 - accuracy: 0.9178\u001b[0m\n",
      "\u001b[34m 28/156 [====>.........................] - ETA: 2:34 - loss: 0.2949 - accuracy: 0.9208\u001b[0m\n",
      "\u001b[34m 29/156 [====>.........................] - ETA: 2:32 - loss: 0.2848 - accuracy: 0.9235\u001b[0m\n",
      "\u001b[34m 30/156 [====>.........................] - ETA: 2:29 - loss: 0.2753 - accuracy: 0.9260\u001b[0m\n",
      "\u001b[34m 31/156 [====>.........................] - ETA: 2:27 - loss: 0.2665 - accuracy: 0.9284\u001b[0m\n",
      "\u001b[34m 32/156 [=====>........................] - ETA: 2:24 - loss: 0.2582 - accuracy: 0.9307\u001b[0m\n",
      "\u001b[34m 33/156 [=====>........................] - ETA: 2:23 - loss: 0.2504 - accuracy: 0.9328\u001b[0m\n",
      "\u001b[34m 34/156 [=====>........................] - ETA: 2:22 - loss: 0.2431 - accuracy: 0.9347\u001b[0m\n",
      "\u001b[34m 35/156 [=====>........................] - ETA: 2:21 - loss: 0.2362 - accuracy: 0.9366\u001b[0m\n",
      "\u001b[34m 36/156 [=====>........................] - ETA: 2:19 - loss: 0.2296 - accuracy: 0.9384\u001b[0m\n",
      "\u001b[34m 37/156 [======>.......................] - ETA: 2:17 - loss: 0.2234 - accuracy: 0.9400\u001b[0m\n",
      "\u001b[34m 38/156 [======>.......................] - ETA: 2:14 - loss: 0.2176 - accuracy: 0.9416\n",
      " 39/156 [======>.......................] - ETA: 2:12 - loss: 0.2120 - accuracy: 0.9431\u001b[0m\n",
      "\u001b[34m 40/156 [======>.......................] - ETA: 2:11 - loss: 0.2067 - accuracy: 0.9445\u001b[0m\n",
      "\u001b[34m 41/156 [======>.......................] - ETA: 2:09 - loss: 0.2017 - accuracy: 0.9459\u001b[0m\n",
      "\u001b[34m 42/156 [=======>......................] - ETA: 2:07 - loss: 0.1969 - accuracy: 0.9472\u001b[0m\n",
      "\u001b[34m 43/156 [=======>......................] - ETA: 2:05 - loss: 0.1923 - accuracy: 0.9484\u001b[0m\n",
      "\u001b[34m 44/156 [=======>......................] - ETA: 2:04 - loss: 0.1880 - accuracy: 0.9496\u001b[0m\n",
      "\u001b[34m 45/156 [=======>......................] - ETA: 2:02 - loss: 0.1838 - accuracy: 0.9507\n",
      " 46/156 [=======>......................] - ETA: 2:00 - loss: 0.1798 - accuracy: 0.9518\u001b[0m\n",
      "\u001b[34m 47/156 [========>.....................] - ETA: 1:58 - loss: 0.1760 - accuracy: 0.9528\u001b[0m\n",
      "\u001b[34m 48/156 [========>.....................] - ETA: 1:57 - loss: 0.1723 - accuracy: 0.9538\u001b[0m\n",
      "\u001b[34m 49/156 [========>.....................] - ETA: 1:55 - loss: 0.1688 - accuracy: 0.9547\u001b[0m\n",
      "\u001b[34m 50/156 [========>.....................] - ETA: 1:54 - loss: 0.1654 - accuracy: 0.9556\u001b[0m\n",
      "\u001b[34m 51/156 [========>.....................] - ETA: 1:52 - loss: 0.1622 - accuracy: 0.9565\u001b[0m\n",
      "\u001b[34m 52/156 [=========>....................] - ETA: 1:51 - loss: 0.1591 - accuracy: 0.9573\u001b[0m\n",
      "\u001b[34m 53/156 [=========>....................] - ETA: 1:49 - loss: 0.1561 - accuracy: 0.9581\n",
      " 54/156 [=========>....................] - ETA: 1:48 - loss: 0.1532 - accuracy: 0.9589\u001b[0m\n",
      "\u001b[34m 55/156 [=========>....................] - ETA: 1:46 - loss: 0.1504 - accuracy: 0.9597\u001b[0m\n",
      "\u001b[34m 56/156 [=========>....................] - ETA: 1:45 - loss: 0.1477 - accuracy: 0.9604\u001b[0m\n",
      "\u001b[34m 57/156 [=========>....................] - ETA: 1:44 - loss: 0.1451 - accuracy: 0.9611\u001b[0m\n",
      "\u001b[34m 58/156 [==========>...................] - ETA: 1:42 - loss: 0.1426 - accuracy: 0.9617\u001b[0m\n",
      "\u001b[34m 59/156 [==========>...................] - ETA: 1:41 - loss: 0.1402 - accuracy: 0.9624\n",
      " 60/156 [==========>...................] - ETA: 1:39 - loss: 0.1379 - accuracy: 0.9630\u001b[0m\n",
      "\u001b[34m 61/156 [==========>...................] - ETA: 1:38 - loss: 0.1356 - accuracy: 0.9636\u001b[0m\n",
      "\u001b[34m 62/156 [==========>...................] - ETA: 1:37 - loss: 0.1334 - accuracy: 0.9642\u001b[0m\n",
      "\u001b[34m 63/156 [===========>..................] - ETA: 1:36 - loss: 0.1313 - accuracy: 0.9648\u001b[0m\n",
      "\u001b[34m 64/156 [===========>..................] - ETA: 1:34 - loss: 0.1293 - accuracy: 0.9653\u001b[0m\n",
      "\u001b[34m 65/156 [===========>..................] - ETA: 1:33 - loss: 0.1273 - accuracy: 0.9659\u001b[0m\n",
      "\u001b[34m 66/156 [===========>..................] - ETA: 1:32 - loss: 0.1254 - accuracy: 0.9664\u001b[0m\n",
      "\u001b[34m 67/156 [===========>..................] - ETA: 1:31 - loss: 0.1235 - accuracy: 0.9669\u001b[0m\n",
      "\u001b[34m 68/156 [============>.................] - ETA: 1:30 - loss: 0.1217 - accuracy: 0.9674\u001b[0m\n",
      "\u001b[34m 69/156 [============>.................] - ETA: 1:29 - loss: 0.1199 - accuracy: 0.9678\n",
      " 70/156 [============>.................] - ETA: 1:27 - loss: 0.1182 - accuracy: 0.9683\u001b[0m\n",
      "\u001b[34m 71/156 [============>.................] - ETA: 1:26 - loss: 0.1165 - accuracy: 0.9688\u001b[0m\n",
      "\u001b[34m 72/156 [============>.................] - ETA: 1:25 - loss: 0.1149 - accuracy: 0.9692\u001b[0m\n",
      "\u001b[34m 73/156 [=============>................] - ETA: 1:24 - loss: 0.1134 - accuracy: 0.9696\u001b[0m\n",
      "\u001b[34m 74/156 [=============>................] - ETA: 1:22 - loss: 0.1118 - accuracy: 0.9700\u001b[0m\n",
      "\u001b[34m 75/156 [=============>................] - ETA: 1:21 - loss: 0.1103 - accuracy: 0.9704\n",
      " 76/156 [=============>................] - ETA: 1:20 - loss: 0.1089 - accuracy: 0.9708\u001b[0m\n",
      "\u001b[34m 77/156 [=============>................] - ETA: 1:19 - loss: 0.1075 - accuracy: 0.9712\u001b[0m\n",
      "\u001b[34m 78/156 [==============>...............] - ETA: 1:18 - loss: 0.1061 - accuracy: 0.9716\u001b[0m\n",
      "\u001b[34m 79/156 [==============>...............] - ETA: 1:17 - loss: 0.1048 - accuracy: 0.9719\u001b[0m\n",
      "\u001b[34m 80/156 [==============>...............] - ETA: 1:16 - loss: 0.1034 - accuracy: 0.9723\u001b[0m\n",
      "\u001b[34m 81/156 [==============>...............] - ETA: 1:14 - loss: 0.1022 - accuracy: 0.9726\u001b[0m\n",
      "\u001b[34m 82/156 [==============>...............] - ETA: 1:13 - loss: 0.1009 - accuracy: 0.9729\n",
      " 83/156 [==============>...............] - ETA: 1:12 - loss: 0.0997 - accuracy: 0.9733\u001b[0m\n",
      "\u001b[34m 84/156 [===============>..............] - ETA: 1:11 - loss: 0.0985 - accuracy: 0.9736\u001b[0m\n",
      "\u001b[34m 85/156 [===============>..............] - ETA: 1:10 - loss: 0.0974 - accuracy: 0.9739\u001b[0m\n",
      "\u001b[34m 86/156 [===============>..............] - ETA: 1:09 - loss: 0.0962 - accuracy: 0.9742\u001b[0m\n",
      "\u001b[34m 87/156 [===============>..............] - ETA: 1:08 - loss: 0.0951 - accuracy: 0.9745\u001b[0m\n",
      "\u001b[34m 88/156 [===============>..............] - ETA: 1:07 - loss: 0.0941 - accuracy: 0.9748\n",
      " 89/156 [================>.............] - ETA: 1:05 - loss: 0.0930 - accuracy: 0.9751\u001b[0m\n",
      "\u001b[34m 90/156 [================>.............] - ETA: 1:04 - loss: 0.0920 - accuracy: 0.9753\u001b[0m\n",
      "\u001b[34m 91/156 [================>.............] - ETA: 1:03 - loss: 0.0910 - accuracy: 0.9756\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m 92/156 [================>.............] - ETA: 1:02 - loss: 0.0900 - accuracy: 0.9759\u001b[0m\n",
      "\u001b[34m 93/156 [================>.............] - ETA: 1:01 - loss: 0.0890 - accuracy: 0.9761\u001b[0m\n",
      "\u001b[34m 94/156 [=================>............] - ETA: 1:00 - loss: 0.0881 - accuracy: 0.9764\u001b[0m\n",
      "\u001b[34m 95/156 [=================>............] - ETA: 59s - loss: 0.0871 - accuracy: 0.9766 \u001b[0m\n",
      "\u001b[34m 96/156 [=================>............] - ETA: 58s - loss: 0.0862 - accuracy: 0.9769\u001b[0m\n",
      "\u001b[34m 97/156 [=================>............] - ETA: 57s - loss: 0.0853 - accuracy: 0.9771\u001b[0m\n",
      "\u001b[34m 98/156 [=================>............] - ETA: 57s - loss: 0.0845 - accuracy: 0.9774\u001b[0m\n",
      "\u001b[34m 99/156 [==================>...........] - ETA: 56s - loss: 0.0836 - accuracy: 0.9776\u001b[0m\n",
      "\u001b[34m100/156 [==================>...........] - ETA: 55s - loss: 0.0828 - accuracy: 0.9778\u001b[0m\n",
      "\u001b[34m101/156 [==================>...........] - ETA: 54s - loss: 0.0820 - accuracy: 0.9780\u001b[0m\n",
      "\u001b[34m102/156 [==================>...........] - ETA: 53s - loss: 0.0812 - accuracy: 0.9782\u001b[0m\n",
      "\u001b[34m103/156 [==================>...........] - ETA: 51s - loss: 0.0804 - accuracy: 0.9785\u001b[0m\n",
      "\u001b[34m104/156 [===================>..........] - ETA: 50s - loss: 0.0796 - accuracy: 0.9787\u001b[0m\n",
      "\u001b[34m105/156 [===================>..........] - ETA: 49s - loss: 0.0788 - accuracy: 0.9789\u001b[0m\n",
      "\u001b[34m106/156 [===================>..........] - ETA: 48s - loss: 0.0781 - accuracy: 0.9791\u001b[0m\n",
      "\u001b[34m107/156 [===================>..........] - ETA: 47s - loss: 0.0774 - accuracy: 0.9793\u001b[0m\n",
      "\u001b[34m108/156 [===================>..........] - ETA: 46s - loss: 0.0767 - accuracy: 0.9795\u001b[0m\n",
      "\u001b[34m109/156 [===================>..........] - ETA: 45s - loss: 0.0760 - accuracy: 0.9796\u001b[0m\n",
      "\u001b[34m110/156 [====================>.........] - ETA: 44s - loss: 0.0753 - accuracy: 0.9798\u001b[0m\n",
      "\u001b[34m111/156 [====================>.........] - ETA: 43s - loss: 0.0746 - accuracy: 0.9800\u001b[0m\n",
      "\u001b[34m112/156 [====================>.........] - ETA: 42s - loss: 0.0739 - accuracy: 0.9802\u001b[0m\n",
      "\u001b[34m113/156 [====================>.........] - ETA: 41s - loss: 0.0733 - accuracy: 0.9804\u001b[0m\n",
      "\u001b[34m114/156 [====================>.........] - ETA: 40s - loss: 0.0726 - accuracy: 0.9805\u001b[0m\n",
      "\u001b[34m115/156 [=====================>........] - ETA: 39s - loss: 0.0720 - accuracy: 0.9807\u001b[0m\n",
      "\u001b[34m116/156 [=====================>........] - ETA: 38s - loss: 0.0714 - accuracy: 0.9809\u001b[0m\n",
      "\u001b[34m117/156 [=====================>........] - ETA: 37s - loss: 0.0708 - accuracy: 0.9810\u001b[0m\n",
      "\u001b[34m118/156 [=====================>........] - ETA: 36s - loss: 0.0702 - accuracy: 0.9812\u001b[0m\n",
      "\u001b[34m119/156 [=====================>........] - ETA: 35s - loss: 0.0696 - accuracy: 0.9814\u001b[0m\n",
      "\u001b[34m120/156 [======================>.......] - ETA: 34s - loss: 0.0690 - accuracy: 0.9815\u001b[0m\n",
      "\u001b[34m121/156 [======================>.......] - ETA: 33s - loss: 0.0684 - accuracy: 0.9817\u001b[0m\n",
      "\u001b[34m122/156 [======================>.......] - ETA: 32s - loss: 0.0679 - accuracy: 0.9818\u001b[0m\n",
      "\u001b[34m123/156 [======================>.......] - ETA: 31s - loss: 0.0673 - accuracy: 0.9820\u001b[0m\n",
      "\u001b[34m124/156 [======================>.......] - ETA: 30s - loss: 0.0668 - accuracy: 0.9821\u001b[0m\n",
      "\u001b[34m125/156 [=======================>......] - ETA: 29s - loss: 0.0662 - accuracy: 0.9822\u001b[0m\n",
      "\u001b[34m126/156 [=======================>......] - ETA: 28s - loss: 0.0657 - accuracy: 0.9824\u001b[0m\n",
      "\u001b[34m127/156 [=======================>......] - ETA: 27s - loss: 0.0652 - accuracy: 0.9825\u001b[0m\n",
      "\u001b[34m128/156 [=======================>......] - ETA: 26s - loss: 0.0647 - accuracy: 0.9827\u001b[0m\n",
      "\u001b[34m129/156 [=======================>......] - ETA: 25s - loss: 0.0642 - accuracy: 0.9828\u001b[0m\n",
      "\u001b[34m130/156 [========================>.....] - ETA: 24s - loss: 0.0637 - accuracy: 0.9829\u001b[0m\n",
      "\u001b[34m131/156 [========================>.....] - ETA: 23s - loss: 0.0632 - accuracy: 0.9831\u001b[0m\n",
      "\u001b[34m132/156 [========================>.....] - ETA: 22s - loss: 0.0627 - accuracy: 0.9832\u001b[0m\n",
      "\u001b[34m133/156 [========================>.....] - ETA: 22s - loss: 0.0623 - accuracy: 0.9833\u001b[0m\n",
      "\u001b[34m134/156 [========================>.....] - ETA: 21s - loss: 0.0618 - accuracy: 0.9834\u001b[0m\n",
      "\u001b[34m135/156 [========================>.....] - ETA: 20s - loss: 0.0613 - accuracy: 0.9836\u001b[0m\n",
      "\u001b[34m136/156 [=========================>....] - ETA: 19s - loss: 0.0609 - accuracy: 0.9837\u001b[0m\n",
      "\u001b[34m137/156 [=========================>....] - ETA: 18s - loss: 0.0604 - accuracy: 0.9838\u001b[0m\n",
      "\u001b[34m138/156 [=========================>....] - ETA: 17s - loss: 0.0600 - accuracy: 0.9839\u001b[0m\n",
      "\u001b[34m139/156 [=========================>....] - ETA: 16s - loss: 0.0596 - accuracy: 0.9840\u001b[0m\n",
      "\u001b[34m140/156 [=========================>....] - ETA: 15s - loss: 0.0592 - accuracy: 0.9842\u001b[0m\n",
      "\u001b[34m141/156 [==========================>...] - ETA: 14s - loss: 0.0587 - accuracy: 0.9843\u001b[0m\n",
      "\u001b[34m142/156 [==========================>...] - ETA: 13s - loss: 0.0583 - accuracy: 0.9844\u001b[0m\n",
      "\u001b[34m143/156 [==========================>...] - ETA: 12s - loss: 0.0579 - accuracy: 0.9845\u001b[0m\n",
      "\u001b[34m144/156 [==========================>...] - ETA: 11s - loss: 0.0575 - accuracy: 0.9846\u001b[0m\n",
      "\u001b[34m145/156 [==========================>...] - ETA: 10s - loss: 0.0571 - accuracy: 0.9847\u001b[0m\n",
      "\u001b[34m146/156 [===========================>..] - ETA: 9s - loss: 0.0567 - accuracy: 0.9848 \u001b[0m\n",
      "\u001b[34m147/156 [===========================>..] - ETA: 8s - loss: 0.0563 - accuracy: 0.9849\u001b[0m\n",
      "\u001b[34m148/156 [===========================>..] - ETA: 7s - loss: 0.0560 - accuracy: 0.9850\u001b[0m\n",
      "\u001b[34m149/156 [===========================>..] - ETA: 6s - loss: 0.0556 - accuracy: 0.9851\u001b[0m\n",
      "\u001b[34m150/156 [===========================>..] - ETA: 5s - loss: 0.0552 - accuracy: 0.9852\u001b[0m\n",
      "\u001b[34m151/156 [============================>.] - ETA: 4s - loss: 0.0548 - accuracy: 0.9853\u001b[0m\n",
      "\u001b[34m152/156 [============================>.] - ETA: 3s - loss: 0.0545 - accuracy: 0.9854\u001b[0m\n",
      "\u001b[34m153/156 [============================>.] - ETA: 2s - loss: 0.0541 - accuracy: 0.9855\u001b[0m\n",
      "\u001b[34m154/156 [============================>.] - ETA: 1s - loss: 0.0538 - accuracy: 0.9856\u001b[0m\n",
      "\u001b[34m155/156 [============================>.] - ETA: 0s - loss: 0.0534 - accuracy: 0.9857\u001b[0m\n",
      "\u001b[34m156/156 [==============================] - 165s 1s/step - loss: 0.0531 - accuracy: 0.9858 - val_loss: 0.2961 - val_accuracy: 0.0000e+00\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/callbacks/tensorboard_v1.py:343: The name tf.Summary is deprecated. Please use tf.compat.v1.Summary instead.\n",
      "\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/callbacks/tensorboard_v1.py:343: The name tf.Summary is deprecated. Please use tf.compat.v1.Summary instead.\n",
      "\u001b[0m\n",
      "\u001b[34mEpoch 2/10\u001b[0m\n",
      "\u001b[34m  1/156 [..............................] - ETA: 2:25 - loss: 4.9345e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m  2/156 [..............................] - ETA: 2:20 - loss: 4.9841e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m  3/156 [..............................] - ETA: 2:15 - loss: 4.8553e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m  4/156 [..............................] - ETA: 2:12 - loss: 4.4458e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m  5/156 [..............................] - ETA: 2:16 - loss: 4.0583e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m  6/156 [>.............................] - ETA: 2:15 - loss: 4.9679e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m  7/156 [>.............................] - ETA: 2:15 - loss: 5.1140e-05 - accuracy: 1.0000\n",
      "  8/156 [>.............................] - ETA: 2:13 - loss: 5.1411e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m  9/156 [>.............................] - ETA: 2:13 - loss: 5.1401e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 10/156 [>.............................] - ETA: 2:11 - loss: 4.8669e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 11/156 [=>............................] - ETA: 2:09 - loss: 4.8908e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 12/156 [=>............................] - ETA: 2:08 - loss: 4.6843e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 13/156 [=>............................] - ETA: 2:08 - loss: 4.7450e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 14/156 [=>............................] - ETA: 2:06 - loss: 5.5371e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 15/156 [=>............................] - ETA: 2:05 - loss: 5.3301e-05 - accuracy: 1.0000\n",
      " 16/156 [==>...........................] - ETA: 2:04 - loss: 5.5950e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 17/156 [==>...........................] - ETA: 2:03 - loss: 5.4584e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 18/156 [==>...........................] - ETA: 2:02 - loss: 5.3562e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 19/156 [==>...........................] - ETA: 2:01 - loss: 5.2609e-05 - accuracy: 1.0000\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m 20/156 [==>...........................] - ETA: 2:00 - loss: 5.2773e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 21/156 [===>..........................] - ETA: 1:58 - loss: 5.1198e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 22/156 [===>..........................] - ETA: 1:58 - loss: 5.2401e-05 - accuracy: 1.0000\n",
      " 23/156 [===>..........................] - ETA: 1:56 - loss: 5.1504e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 24/156 [===>..........................] - ETA: 1:56 - loss: 5.0386e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 25/156 [===>..........................] - ETA: 1:55 - loss: 4.9855e-05 - accuracy: 1.0000\n",
      " 26/156 [====>.........................] - ETA: 1:56 - loss: 4.9602e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 27/156 [====>.........................] - ETA: 1:54 - loss: 4.9014e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 28/156 [====>.........................] - ETA: 1:53 - loss: 4.9985e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 29/156 [====>.........................] - ETA: 1:52 - loss: 5.0469e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 30/156 [====>.........................] - ETA: 1:52 - loss: 5.0786e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 31/156 [====>.........................] - ETA: 1:51 - loss: 5.1047e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 32/156 [=====>........................] - ETA: 1:50 - loss: 5.1145e-05 - accuracy: 1.0000\n",
      " 33/156 [=====>........................] - ETA: 1:49 - loss: 5.2062e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 34/156 [=====>........................] - ETA: 1:48 - loss: 5.2293e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 35/156 [=====>........................] - ETA: 1:47 - loss: 5.1863e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 36/156 [=====>........................] - ETA: 1:46 - loss: 5.1322e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 37/156 [======>.......................] - ETA: 1:45 - loss: 5.0645e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 38/156 [======>.......................] - ETA: 1:44 - loss: 4.9975e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 39/156 [======>.......................] - ETA: 1:43 - loss: 5.2108e-05 - accuracy: 1.0000\n",
      " 40/156 [======>.......................] - ETA: 1:42 - loss: 5.1534e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 41/156 [======>.......................] - ETA: 1:41 - loss: 5.1502e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 42/156 [=======>......................] - ETA: 1:40 - loss: 5.1872e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 43/156 [=======>......................] - ETA: 1:39 - loss: 5.2540e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 44/156 [=======>......................] - ETA: 1:38 - loss: 5.2049e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 45/156 [=======>......................] - ETA: 1:37 - loss: 5.2586e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 46/156 [=======>......................] - ETA: 1:36 - loss: 5.2516e-05 - accuracy: 1.0000\n",
      " 47/156 [========>.....................] - ETA: 1:35 - loss: 5.1684e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 48/156 [========>.....................] - ETA: 1:34 - loss: 5.1484e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 49/156 [========>.....................] - ETA: 1:33 - loss: 5.2948e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 50/156 [========>.....................] - ETA: 1:32 - loss: 5.2496e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 51/156 [========>.....................] - ETA: 1:32 - loss: 5.2078e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 52/156 [=========>....................] - ETA: 1:31 - loss: 5.1398e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 53/156 [=========>....................] - ETA: 1:30 - loss: 5.1284e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 54/156 [=========>....................] - ETA: 1:30 - loss: 5.1081e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 55/156 [=========>....................] - ETA: 1:29 - loss: 5.0703e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 56/156 [=========>....................] - ETA: 1:29 - loss: 5.0935e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 57/156 [=========>....................] - ETA: 1:28 - loss: 5.0511e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 58/156 [==========>...................] - ETA: 1:27 - loss: 5.0096e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 59/156 [==========>...................] - ETA: 1:26 - loss: 5.4548e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 60/156 [==========>...................] - ETA: 1:26 - loss: 5.4491e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 61/156 [==========>...................] - ETA: 1:25 - loss: 5.3964e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 62/156 [==========>...................] - ETA: 1:24 - loss: 5.5153e-05 - accuracy: 1.0000\n",
      " 63/156 [===========>..................] - ETA: 1:23 - loss: 5.4815e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 64/156 [===========>..................] - ETA: 1:22 - loss: 5.5084e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 65/156 [===========>..................] - ETA: 1:21 - loss: 5.4475e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 66/156 [===========>..................] - ETA: 1:20 - loss: 5.4363e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 67/156 [===========>..................] - ETA: 1:19 - loss: 5.4168e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 68/156 [============>.................] - ETA: 1:18 - loss: 5.3739e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 69/156 [============>.................] - ETA: 1:17 - loss: 5.3293e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 70/156 [============>.................] - ETA: 1:17 - loss: 5.3213e-05 - accuracy: 1.0000\n",
      " 71/156 [============>.................] - ETA: 1:16 - loss: 5.2853e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 72/156 [============>.................] - ETA: 1:15 - loss: 5.2642e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 73/156 [=============>................] - ETA: 1:14 - loss: 5.2574e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 74/156 [=============>................] - ETA: 1:13 - loss: 5.3980e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 75/156 [=============>................] - ETA: 1:12 - loss: 5.4296e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 76/156 [=============>................] - ETA: 1:11 - loss: 5.4068e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 77/156 [=============>................] - ETA: 1:10 - loss: 5.3600e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 78/156 [==============>...............] - ETA: 1:09 - loss: 5.3134e-05 - accuracy: 1.0000\n",
      " 79/156 [==============>...............] - ETA: 1:08 - loss: 5.2969e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 80/156 [==============>...............] - ETA: 1:07 - loss: 5.3067e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 81/156 [==============>...............] - ETA: 1:06 - loss: 5.2917e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 82/156 [==============>...............] - ETA: 1:05 - loss: 5.2810e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 83/156 [==============>...............] - ETA: 1:04 - loss: 5.2448e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 84/156 [===============>..............] - ETA: 1:04 - loss: 5.2220e-05 - accuracy: 1.0000\n",
      " 85/156 [===============>..............] - ETA: 1:03 - loss: 5.2208e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 86/156 [===============>..............] - ETA: 1:02 - loss: 5.1760e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 87/156 [===============>..............] - ETA: 1:01 - loss: 5.1546e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 88/156 [===============>..............] - ETA: 1:00 - loss: 5.1122e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 89/156 [================>.............] - ETA: 59s - loss: 5.1019e-05 - accuracy: 1.0000 \u001b[0m\n",
      "\u001b[34m 90/156 [================>.............] - ETA: 58s - loss: 5.0897e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 91/156 [================>.............] - ETA: 57s - loss: 5.0785e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 92/156 [================>.............] - ETA: 56s - loss: 5.0647e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 93/156 [================>.............] - ETA: 55s - loss: 5.0601e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 94/156 [=================>............] - ETA: 55s - loss: 5.0378e-05 - accuracy: 1.0000\n",
      " 95/156 [=================>............] - ETA: 54s - loss: 5.0053e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 96/156 [=================>............] - ETA: 53s - loss: 4.9719e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 97/156 [=================>............] - ETA: 52s - loss: 4.9927e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 98/156 [=================>............] - ETA: 51s - loss: 4.9601e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 99/156 [==================>...........] - ETA: 50s - loss: 4.9423e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m100/156 [==================>...........] - ETA: 49s - loss: 4.9182e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m101/156 [==================>...........] - ETA: 48s - loss: 4.9426e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m102/156 [==================>...........] - ETA: 47s - loss: 4.9219e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m103/156 [==================>...........] - ETA: 47s - loss: 4.8940e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m104/156 [===================>..........] - ETA: 46s - loss: 4.9252e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m105/156 [===================>..........] - ETA: 45s - loss: 4.9134e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m106/156 [===================>..........] - ETA: 44s - loss: 4.8933e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m107/156 [===================>..........] - ETA: 43s - loss: 4.8703e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m108/156 [===================>..........] - ETA: 42s - loss: 4.8622e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m109/156 [===================>..........] - ETA: 41s - loss: 4.8339e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m110/156 [====================>.........] - ETA: 40s - loss: 4.8070e-05 - accuracy: 1.0000\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m111/156 [====================>.........] - ETA: 39s - loss: 5.0048e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m112/156 [====================>.........] - ETA: 38s - loss: 4.9888e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m113/156 [====================>.........] - ETA: 38s - loss: 5.0307e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m114/156 [====================>.........] - ETA: 37s - loss: 5.0010e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m115/156 [=====================>........] - ETA: 36s - loss: 4.9743e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m116/156 [=====================>........] - ETA: 35s - loss: 4.9613e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m117/156 [=====================>........] - ETA: 34s - loss: 4.9351e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m118/156 [=====================>........] - ETA: 33s - loss: 4.9258e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m119/156 [=====================>........] - ETA: 32s - loss: 4.9035e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m120/156 [======================>.......] - ETA: 31s - loss: 4.8849e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m121/156 [======================>.......] - ETA: 31s - loss: 4.8632e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m122/156 [======================>.......] - ETA: 30s - loss: 4.8544e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m123/156 [======================>.......] - ETA: 29s - loss: 4.8323e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m124/156 [======================>.......] - ETA: 28s - loss: 4.8106e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m125/156 [=======================>......] - ETA: 27s - loss: 4.8004e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m126/156 [=======================>......] - ETA: 26s - loss: 4.7977e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m127/156 [=======================>......] - ETA: 25s - loss: 4.8026e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m128/156 [=======================>......] - ETA: 25s - loss: 4.7930e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m129/156 [=======================>......] - ETA: 24s - loss: 4.7837e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m130/156 [========================>.....] - ETA: 23s - loss: 4.7614e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m131/156 [========================>.....] - ETA: 22s - loss: 4.7409e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m132/156 [========================>.....] - ETA: 21s - loss: 4.7197e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m133/156 [========================>.....] - ETA: 20s - loss: 4.7296e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m134/156 [========================>.....] - ETA: 19s - loss: 4.7081e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m135/156 [========================>.....] - ETA: 18s - loss: 4.6881e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m136/156 [=========================>....] - ETA: 17s - loss: 4.6650e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m137/156 [=========================>....] - ETA: 16s - loss: 4.6480e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m138/156 [=========================>....] - ETA: 16s - loss: 4.6303e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m139/156 [=========================>....] - ETA: 15s - loss: 4.6185e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m140/156 [=========================>....] - ETA: 14s - loss: 4.6009e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m141/156 [==========================>...] - ETA: 13s - loss: 4.5846e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m142/156 [==========================>...] - ETA: 12s - loss: 4.5588e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m143/156 [==========================>...] - ETA: 11s - loss: 4.5426e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m144/156 [==========================>...] - ETA: 10s - loss: 4.5320e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m145/156 [==========================>...] - ETA: 9s - loss: 4.5105e-05 - accuracy: 1.0000 \u001b[0m\n",
      "\u001b[34m146/156 [===========================>..] - ETA: 8s - loss: 4.4933e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m147/156 [===========================>..] - ETA: 8s - loss: 4.5063e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m148/156 [===========================>..] - ETA: 7s - loss: 4.5142e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m149/156 [===========================>..] - ETA: 6s - loss: 4.5093e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m150/156 [===========================>..] - ETA: 5s - loss: 4.5031e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m151/156 [============================>.] - ETA: 4s - loss: 4.4853e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m152/156 [============================>.] - ETA: 3s - loss: 4.4744e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m153/156 [============================>.] - ETA: 2s - loss: 4.4561e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m154/156 [============================>.] - ETA: 1s - loss: 4.4449e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m155/156 [============================>.] - ETA: 0s - loss: 4.4508e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m156/156 [==============================] - 154s 990ms/step - loss: 4.4381e-05 - accuracy: 1.0000 - val_loss: 0.0872 - val_accuracy: 13.4871\u001b[0m\n",
      "\u001b[34mEpoch 3/10\u001b[0m\n",
      "\u001b[34m  1/156 [..............................] - ETA: 2:21 - loss: 2.3888e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m  2/156 [..............................] - ETA: 2:11 - loss: 2.5921e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m  3/156 [..............................] - ETA: 2:08 - loss: 2.2594e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m  4/156 [..............................] - ETA: 2:11 - loss: 2.1763e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m  5/156 [..............................] - ETA: 2:11 - loss: 2.3870e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m  6/156 [>.............................] - ETA: 2:08 - loss: 2.7783e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m  7/156 [>.............................] - ETA: 2:07 - loss: 2.8058e-05 - accuracy: 1.0000\n",
      "  8/156 [>.............................] - ETA: 2:06 - loss: 2.8079e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m  9/156 [>.............................] - ETA: 2:05 - loss: 2.7899e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 10/156 [>.............................] - ETA: 2:06 - loss: 2.6538e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 11/156 [=>............................] - ETA: 2:05 - loss: 2.9191e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 12/156 [=>............................] - ETA: 2:06 - loss: 3.0915e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 13/156 [=>............................] - ETA: 2:05 - loss: 2.9553e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 14/156 [=>............................] - ETA: 2:05 - loss: 2.8853e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 15/156 [=>............................] - ETA: 2:05 - loss: 2.8893e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 16/156 [==>...........................] - ETA: 2:08 - loss: 2.8526e-05 - accuracy: 1.0000\n",
      " 17/156 [==>...........................] - ETA: 2:09 - loss: 2.8939e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 18/156 [==>...........................] - ETA: 2:08 - loss: 2.8513e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 19/156 [==>...........................] - ETA: 2:07 - loss: 2.7903e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 20/156 [==>...........................] - ETA: 2:06 - loss: 2.7532e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 21/156 [===>..........................] - ETA: 2:05 - loss: 3.0111e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 22/156 [===>..........................] - ETA: 2:03 - loss: 2.9867e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 23/156 [===>..........................] - ETA: 2:03 - loss: 2.9139e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 24/156 [===>..........................] - ETA: 2:02 - loss: 2.8978e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 25/156 [===>..........................] - ETA: 2:00 - loss: 2.8650e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 26/156 [====>.........................] - ETA: 1:59 - loss: 2.8585e-05 - accuracy: 1.0000\n",
      " 27/156 [====>.........................] - ETA: 1:58 - loss: 2.7963e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 28/156 [====>.........................] - ETA: 1:57 - loss: 2.8115e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 29/156 [====>.........................] - ETA: 1:56 - loss: 2.8422e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 30/156 [====>.........................] - ETA: 1:54 - loss: 2.8182e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 31/156 [====>.........................] - ETA: 1:53 - loss: 2.7791e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 32/156 [=====>........................] - ETA: 1:52 - loss: 2.7308e-05 - accuracy: 1.0000\n",
      " 33/156 [=====>........................] - ETA: 1:51 - loss: 2.7703e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 34/156 [=====>........................] - ETA: 1:50 - loss: 2.7612e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 35/156 [=====>........................] - ETA: 1:49 - loss: 2.7615e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 36/156 [=====>........................] - ETA: 1:48 - loss: 2.7733e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 37/156 [======>.......................] - ETA: 1:47 - loss: 2.7265e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 38/156 [======>.......................] - ETA: 1:46 - loss: 2.7067e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 39/156 [======>.......................] - ETA: 1:45 - loss: 2.6677e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 40/156 [======>.......................] - ETA: 1:44 - loss: 2.6723e-05 - accuracy: 1.0000\n",
      " 41/156 [======>.......................] - ETA: 1:43 - loss: 2.6546e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 42/156 [=======>......................] - ETA: 1:42 - loss: 2.6602e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 43/156 [=======>......................] - ETA: 1:41 - loss: 2.6280e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 44/156 [=======>......................] - ETA: 1:40 - loss: 2.6202e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 45/156 [=======>......................] - ETA: 1:39 - loss: 2.6145e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 46/156 [=======>......................] - ETA: 1:38 - loss: 2.6111e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 47/156 [========>.....................] - ETA: 1:37 - loss: 2.6043e-05 - accuracy: 1.0000\n",
      " 48/156 [========>.....................] - ETA: 1:36 - loss: 2.5772e-05 - accuracy: 1.0000\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m 49/156 [========>.....................] - ETA: 1:35 - loss: 2.5840e-05 - accuracy: 1.0000\n",
      " 50/156 [========>.....................] - ETA: 1:35 - loss: 2.5699e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 51/156 [========>.....................] - ETA: 1:34 - loss: 2.5542e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 52/156 [=========>....................] - ETA: 1:33 - loss: 2.5412e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 53/156 [=========>....................] - ETA: 1:32 - loss: 2.5425e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 54/156 [=========>....................] - ETA: 1:31 - loss: 2.5814e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 55/156 [=========>....................] - ETA: 1:30 - loss: 2.5631e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 56/156 [=========>....................] - ETA: 1:29 - loss: 2.5481e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 57/156 [=========>....................] - ETA: 1:28 - loss: 2.5443e-05 - accuracy: 1.0000\n",
      " 58/156 [==========>...................] - ETA: 1:27 - loss: 2.5343e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 59/156 [==========>...................] - ETA: 1:26 - loss: 2.6041e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 60/156 [==========>...................] - ETA: 1:25 - loss: 2.5806e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 61/156 [==========>...................] - ETA: 1:24 - loss: 2.5548e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 62/156 [==========>...................] - ETA: 1:24 - loss: 2.5535e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 63/156 [===========>..................] - ETA: 1:23 - loss: 2.5597e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 64/156 [===========>..................] - ETA: 1:22 - loss: 2.5587e-05 - accuracy: 1.0000\n",
      " 65/156 [===========>..................] - ETA: 1:21 - loss: 2.5378e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 66/156 [===========>..................] - ETA: 1:20 - loss: 2.5561e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 67/156 [===========>..................] - ETA: 1:19 - loss: 2.5287e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 68/156 [============>.................] - ETA: 1:18 - loss: 2.4991e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 69/156 [============>.................] - ETA: 1:17 - loss: 2.4838e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 70/156 [============>.................] - ETA: 1:16 - loss: 2.5480e-05 - accuracy: 1.0000\n",
      " 71/156 [============>.................] - ETA: 1:15 - loss: 2.5217e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 72/156 [============>.................] - ETA: 1:14 - loss: 2.5280e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 73/156 [=============>................] - ETA: 1:13 - loss: 2.5296e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 74/156 [=============>................] - ETA: 1:12 - loss: 2.5191e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 75/156 [=============>................] - ETA: 1:11 - loss: 2.5111e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 76/156 [=============>................] - ETA: 1:10 - loss: 2.5111e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 77/156 [=============>................] - ETA: 1:10 - loss: 2.4924e-05 - accuracy: 1.0000\n",
      " 78/156 [==============>...............] - ETA: 1:09 - loss: 2.4757e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 79/156 [==============>...............] - ETA: 1:08 - loss: 2.4738e-05 - accuracy: 1.0000\n",
      " 80/156 [==============>...............] - ETA: 1:07 - loss: 2.4691e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 81/156 [==============>...............] - ETA: 1:06 - loss: 2.4649e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 82/156 [==============>...............] - ETA: 1:05 - loss: 2.4456e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 83/156 [==============>...............] - ETA: 1:05 - loss: 2.4572e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 84/156 [===============>..............] - ETA: 1:04 - loss: 2.4402e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 85/156 [===============>..............] - ETA: 1:03 - loss: 2.4423e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 86/156 [===============>..............] - ETA: 1:02 - loss: 2.4305e-05 - accuracy: 1.0000\n",
      " 87/156 [===============>..............] - ETA: 1:01 - loss: 2.4557e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 88/156 [===============>..............] - ETA: 1:01 - loss: 2.4443e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 89/156 [================>.............] - ETA: 1:00 - loss: 2.4558e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 90/156 [================>.............] - ETA: 59s - loss: 2.4593e-05 - accuracy: 1.0000 \u001b[0m\n",
      "\u001b[34m 91/156 [================>.............] - ETA: 58s - loss: 2.4602e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 92/156 [================>.............] - ETA: 57s - loss: 2.4405e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 93/156 [================>.............] - ETA: 56s - loss: 2.4260e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 94/156 [=================>............] - ETA: 55s - loss: 2.4121e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 95/156 [=================>............] - ETA: 54s - loss: 2.4068e-05 - accuracy: 1.0000\n",
      " 96/156 [=================>............] - ETA: 53s - loss: 2.3954e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 97/156 [=================>............] - ETA: 52s - loss: 2.4043e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 98/156 [=================>............] - ETA: 52s - loss: 2.4129e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 99/156 [==================>...........] - ETA: 51s - loss: 2.4121e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m100/156 [==================>...........] - ETA: 50s - loss: 2.4092e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m101/156 [==================>...........] - ETA: 49s - loss: 2.4256e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m102/156 [==================>...........] - ETA: 48s - loss: 2.4225e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m103/156 [==================>...........] - ETA: 47s - loss: 2.4126e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m104/156 [===================>..........] - ETA: 46s - loss: 2.4010e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m105/156 [===================>..........] - ETA: 45s - loss: 2.3900e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m106/156 [===================>..........] - ETA: 44s - loss: 2.3845e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m107/156 [===================>..........] - ETA: 43s - loss: 2.3773e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m108/156 [===================>..........] - ETA: 42s - loss: 2.3912e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m109/156 [===================>..........] - ETA: 42s - loss: 2.3876e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m110/156 [====================>.........] - ETA: 41s - loss: 2.3774e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m111/156 [====================>.........] - ETA: 40s - loss: 2.3944e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m112/156 [====================>.........] - ETA: 39s - loss: 2.3808e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m113/156 [====================>.........] - ETA: 38s - loss: 2.3902e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m114/156 [====================>.........] - ETA: 37s - loss: 2.4047e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m115/156 [=====================>........] - ETA: 36s - loss: 2.3914e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m116/156 [=====================>........] - ETA: 35s - loss: 2.3806e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m117/156 [=====================>........] - ETA: 34s - loss: 2.3748e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m118/156 [=====================>........] - ETA: 33s - loss: 2.3889e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m119/156 [=====================>........] - ETA: 33s - loss: 2.3820e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m120/156 [======================>.......] - ETA: 32s - loss: 2.3760e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m121/156 [======================>.......] - ETA: 31s - loss: 2.3859e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m122/156 [======================>.......] - ETA: 30s - loss: 2.3851e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m123/156 [======================>.......] - ETA: 29s - loss: 2.3722e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m124/156 [======================>.......] - ETA: 28s - loss: 2.3670e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m125/156 [=======================>......] - ETA: 27s - loss: 2.4090e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m126/156 [=======================>......] - ETA: 26s - loss: 2.4818e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m127/156 [=======================>......] - ETA: 25s - loss: 2.4854e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m128/156 [=======================>......] - ETA: 24s - loss: 2.5542e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m129/156 [=======================>......] - ETA: 24s - loss: 2.5733e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m130/156 [========================>.....] - ETA: 23s - loss: 2.5648e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m131/156 [========================>.....] - ETA: 22s - loss: 2.5687e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m132/156 [========================>.....] - ETA: 21s - loss: 2.5667e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m133/156 [========================>.....] - ETA: 20s - loss: 2.5555e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m134/156 [========================>.....] - ETA: 19s - loss: 2.5453e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m135/156 [========================>.....] - ETA: 18s - loss: 2.5366e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m136/156 [=========================>....] - ETA: 17s - loss: 2.5441e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m137/156 [=========================>....] - ETA: 16s - loss: 2.5348e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m138/156 [=========================>....] - ETA: 16s - loss: 2.5536e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m139/156 [=========================>....] - ETA: 15s - loss: 2.5529e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m140/156 [=========================>....] - ETA: 14s - loss: 2.5510e-05 - accuracy: 1.0000\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m141/156 [==========================>...] - ETA: 13s - loss: 2.5451e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m142/156 [==========================>...] - ETA: 12s - loss: 2.5376e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m143/156 [==========================>...] - ETA: 11s - loss: 2.5376e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m144/156 [==========================>...] - ETA: 10s - loss: 2.5268e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m145/156 [==========================>...] - ETA: 9s - loss: 2.5470e-05 - accuracy: 1.0000 \u001b[0m\n",
      "\u001b[34m146/156 [===========================>..] - ETA: 8s - loss: 2.5364e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m147/156 [===========================>..] - ETA: 8s - loss: 2.5254e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m148/156 [===========================>..] - ETA: 7s - loss: 2.5266e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m149/156 [===========================>..] - ETA: 6s - loss: 2.5321e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m150/156 [===========================>..] - ETA: 5s - loss: 2.5357e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m151/156 [============================>.] - ETA: 4s - loss: 2.5265e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m152/156 [============================>.] - ETA: 3s - loss: 2.5186e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m153/156 [============================>.] - ETA: 2s - loss: 2.5167e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m154/156 [============================>.] - ETA: 1s - loss: 2.5080e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m155/156 [============================>.] - ETA: 0s - loss: 2.5037e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m156/156 [==============================] - 155s 995ms/step - loss: 2.4986e-05 - accuracy: 1.0000 - val_loss: 0.0505 - val_accuracy: 19.0850\u001b[0m\n",
      "\u001b[34mEpoch 4/10\u001b[0m\n",
      "\u001b[34m  1/156 [..............................] - ETA: 2:02 - loss: 2.5433e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m  2/156 [..............................] - ETA: 2:11 - loss: 2.1057e-05 - accuracy: 1.0000\n",
      "  3/156 [..............................] - ETA: 2:09 - loss: 2.1246e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m  4/156 [..............................] - ETA: 2:08 - loss: 3.2144e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m  5/156 [..............................] - ETA: 2:07 - loss: 2.7147e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m  6/156 [>.............................] - ETA: 2:09 - loss: 2.6644e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m  7/156 [>.............................] - ETA: 2:11 - loss: 2.7001e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m  8/156 [>.............................] - ETA: 2:12 - loss: 2.6438e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m  9/156 [>.............................] - ETA: 2:11 - loss: 2.6732e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 10/156 [>.............................] - ETA: 2:10 - loss: 2.5769e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 11/156 [=>............................] - ETA: 2:09 - loss: 2.5991e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 12/156 [=>............................] - ETA: 2:07 - loss: 2.5450e-05 - accuracy: 1.0000\n",
      " 13/156 [=>............................] - ETA: 2:07 - loss: 2.4782e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 14/156 [=>............................] - ETA: 2:05 - loss: 2.4910e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 15/156 [=>............................] - ETA: 2:05 - loss: 2.4195e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 16/156 [==>...........................] - ETA: 2:04 - loss: 2.4154e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 17/156 [==>...........................] - ETA: 2:03 - loss: 2.3163e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 18/156 [==>...........................] - ETA: 2:01 - loss: 2.2163e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 19/156 [==>...........................] - ETA: 2:00 - loss: 2.1709e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 20/156 [==>...........................] - ETA: 2:00 - loss: 2.1583e-05 - accuracy: 1.0000\n",
      " 21/156 [===>..........................] - ETA: 2:00 - loss: 2.1374e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 22/156 [===>..........................] - ETA: 1:58 - loss: 2.1525e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 23/156 [===>..........................] - ETA: 1:57 - loss: 2.1965e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 24/156 [===>..........................] - ETA: 1:56 - loss: 2.5826e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 25/156 [===>..........................] - ETA: 1:55 - loss: 2.6136e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 26/156 [====>.........................] - ETA: 1:54 - loss: 2.7945e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 27/156 [====>.........................] - ETA: 1:54 - loss: 2.7470e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 28/156 [====>.........................] - ETA: 1:53 - loss: 3.3706e-05 - accuracy: 1.0000\n",
      " 29/156 [====>.........................] - ETA: 1:52 - loss: 3.2929e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 30/156 [====>.........................] - ETA: 1:51 - loss: 3.2054e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 31/156 [====>.........................] - ETA: 1:50 - loss: 3.1234e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 32/156 [=====>........................] - ETA: 1:49 - loss: 3.0971e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 33/156 [=====>........................] - ETA: 1:48 - loss: 3.0293e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 34/156 [=====>........................] - ETA: 1:47 - loss: 2.9612e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 35/156 [=====>........................] - ETA: 1:46 - loss: 2.9132e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 36/156 [=====>........................] - ETA: 1:46 - loss: 2.8614e-05 - accuracy: 1.0000\n",
      " 37/156 [======>.......................] - ETA: 1:45 - loss: 2.8048e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 38/156 [======>.......................] - ETA: 1:44 - loss: 2.7922e-05 - accuracy: 1.0000\n",
      " 39/156 [======>.......................] - ETA: 1:43 - loss: 2.9371e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 40/156 [======>.......................] - ETA: 1:42 - loss: 2.9024e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 41/156 [======>.......................] - ETA: 1:41 - loss: 2.8784e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 42/156 [=======>......................] - ETA: 1:41 - loss: 2.8296e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 43/156 [=======>......................] - ETA: 1:40 - loss: 2.7857e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 44/156 [=======>......................] - ETA: 1:40 - loss: 2.7829e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 45/156 [=======>......................] - ETA: 1:40 - loss: 2.7471e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 46/156 [=======>......................] - ETA: 1:39 - loss: 2.7035e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 47/156 [========>.....................] - ETA: 1:39 - loss: 2.6739e-05 - accuracy: 1.0000\n",
      " 48/156 [========>.....................] - ETA: 1:38 - loss: 2.6477e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 49/156 [========>.....................] - ETA: 1:37 - loss: 2.6036e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 50/156 [========>.....................] - ETA: 1:36 - loss: 2.5922e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 51/156 [========>.....................] - ETA: 1:35 - loss: 2.5791e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 52/156 [=========>....................] - ETA: 1:34 - loss: 2.5696e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 53/156 [=========>....................] - ETA: 1:33 - loss: 2.5507e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 54/156 [=========>....................] - ETA: 1:32 - loss: 2.5310e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 55/156 [=========>....................] - ETA: 1:31 - loss: 2.4995e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 56/156 [=========>....................] - ETA: 1:30 - loss: 2.4744e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 57/156 [=========>....................] - ETA: 1:29 - loss: 2.4490e-05 - accuracy: 1.0000\n",
      " 58/156 [==========>...................] - ETA: 1:28 - loss: 2.4257e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 59/156 [==========>...................] - ETA: 1:28 - loss: 2.4156e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 60/156 [==========>...................] - ETA: 1:27 - loss: 2.4151e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 61/156 [==========>...................] - ETA: 1:26 - loss: 2.4051e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 62/156 [==========>...................] - ETA: 1:25 - loss: 2.3787e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 63/156 [===========>..................] - ETA: 1:24 - loss: 2.3502e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 64/156 [===========>..................] - ETA: 1:23 - loss: 2.3369e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 65/156 [===========>..................] - ETA: 1:22 - loss: 2.3348e-05 - accuracy: 1.0000\n",
      " 66/156 [===========>..................] - ETA: 1:21 - loss: 2.3153e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 67/156 [===========>..................] - ETA: 1:20 - loss: 2.2984e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 68/156 [============>.................] - ETA: 1:19 - loss: 2.2842e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 69/156 [============>.................] - ETA: 1:18 - loss: 2.2749e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 70/156 [============>.................] - ETA: 1:17 - loss: 2.2563e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 71/156 [============>.................] - ETA: 1:16 - loss: 2.2469e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 72/156 [============>.................] - ETA: 1:15 - loss: 2.2270e-05 - accuracy: 1.0000\n",
      " 73/156 [=============>................] - ETA: 1:14 - loss: 2.2124e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 74/156 [=============>................] - ETA: 1:13 - loss: 2.2056e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 75/156 [=============>................] - ETA: 1:12 - loss: 2.1961e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 76/156 [=============>................] - ETA: 1:11 - loss: 2.1814e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 77/156 [=============>................] - ETA: 1:10 - loss: 2.1648e-05 - accuracy: 1.0000\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m 78/156 [==============>...............] - ETA: 1:09 - loss: 2.1448e-05 - accuracy: 1.0000\n",
      " 79/156 [==============>...............] - ETA: 1:09 - loss: 2.1335e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 80/156 [==============>...............] - ETA: 1:08 - loss: 2.1124e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 81/156 [==============>...............] - ETA: 1:07 - loss: 2.1043e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 82/156 [==============>...............] - ETA: 1:06 - loss: 2.0945e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 83/156 [==============>...............] - ETA: 1:05 - loss: 2.0776e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 84/156 [===============>..............] - ETA: 1:04 - loss: 2.0719e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 85/156 [===============>..............] - ETA: 1:03 - loss: 2.0531e-05 - accuracy: 1.0000\n",
      " 86/156 [===============>..............] - ETA: 1:02 - loss: 2.0497e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 87/156 [===============>..............] - ETA: 1:01 - loss: 2.0535e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 88/156 [===============>..............] - ETA: 1:00 - loss: 2.0405e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 89/156 [================>.............] - ETA: 59s - loss: 2.0267e-05 - accuracy: 1.0000 \u001b[0m\n",
      "\u001b[34m 90/156 [================>.............] - ETA: 58s - loss: 2.0199e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 91/156 [================>.............] - ETA: 58s - loss: 2.0083e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 92/156 [================>.............] - ETA: 57s - loss: 1.9961e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 93/156 [================>.............] - ETA: 56s - loss: 1.9906e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 94/156 [=================>............] - ETA: 55s - loss: 2.2392e-05 - accuracy: 1.0000\n",
      " 95/156 [=================>............] - ETA: 54s - loss: 2.2220e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 96/156 [=================>............] - ETA: 53s - loss: 2.2281e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 97/156 [=================>............] - ETA: 52s - loss: 2.2146e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 98/156 [=================>............] - ETA: 51s - loss: 2.2036e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 99/156 [==================>...........] - ETA: 50s - loss: 2.1887e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m100/156 [==================>...........] - ETA: 49s - loss: 2.1740e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m101/156 [==================>...........] - ETA: 49s - loss: 2.2062e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m102/156 [==================>...........] - ETA: 48s - loss: 2.1947e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m103/156 [==================>...........] - ETA: 47s - loss: 2.1805e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m104/156 [===================>..........] - ETA: 46s - loss: 2.1818e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m105/156 [===================>..........] - ETA: 45s - loss: 2.1726e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m106/156 [===================>..........] - ETA: 44s - loss: 2.1747e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m107/156 [===================>..........] - ETA: 43s - loss: 2.1600e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m108/156 [===================>..........] - ETA: 42s - loss: 2.1492e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m109/156 [===================>..........] - ETA: 42s - loss: 2.1421e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m110/156 [====================>.........] - ETA: 41s - loss: 2.1295e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m111/156 [====================>.........] - ETA: 40s - loss: 2.1147e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m112/156 [====================>.........] - ETA: 39s - loss: 2.1077e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m113/156 [====================>.........] - ETA: 38s - loss: 2.1048e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m114/156 [====================>.........] - ETA: 37s - loss: 2.1057e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m115/156 [=====================>........] - ETA: 36s - loss: 2.0906e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m116/156 [=====================>........] - ETA: 35s - loss: 2.0855e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m117/156 [=====================>........] - ETA: 35s - loss: 2.0734e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m118/156 [=====================>........] - ETA: 34s - loss: 2.0610e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m119/156 [=====================>........] - ETA: 33s - loss: 2.0667e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m120/156 [======================>.......] - ETA: 32s - loss: 2.0577e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m121/156 [======================>.......] - ETA: 31s - loss: 2.0555e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m122/156 [======================>.......] - ETA: 30s - loss: 2.0447e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m123/156 [======================>.......] - ETA: 29s - loss: 2.0538e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m124/156 [======================>.......] - ETA: 28s - loss: 2.0432e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m125/156 [=======================>......] - ETA: 27s - loss: 2.0404e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m126/156 [=======================>......] - ETA: 26s - loss: 2.0315e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m127/156 [=======================>......] - ETA: 26s - loss: 2.0297e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m128/156 [=======================>......] - ETA: 25s - loss: 2.0259e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m129/156 [=======================>......] - ETA: 24s - loss: 2.0366e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m130/156 [========================>.....] - ETA: 23s - loss: 2.0290e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m131/156 [========================>.....] - ETA: 22s - loss: 2.0184e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m132/156 [========================>.....] - ETA: 21s - loss: 2.0118e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m133/156 [========================>.....] - ETA: 20s - loss: 2.0024e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m134/156 [========================>.....] - ETA: 19s - loss: 1.9907e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m135/156 [========================>.....] - ETA: 18s - loss: 1.9865e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m136/156 [=========================>....] - ETA: 17s - loss: 1.9873e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m137/156 [=========================>....] - ETA: 16s - loss: 1.9759e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m138/156 [=========================>....] - ETA: 16s - loss: 1.9695e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m139/156 [=========================>....] - ETA: 15s - loss: 1.9600e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m140/156 [=========================>....] - ETA: 14s - loss: 1.9511e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m141/156 [==========================>...] - ETA: 13s - loss: 1.9437e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m142/156 [==========================>...] - ETA: 12s - loss: 1.9377e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m143/156 [==========================>...] - ETA: 11s - loss: 1.9453e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m144/156 [==========================>...] - ETA: 10s - loss: 1.9459e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m145/156 [==========================>...] - ETA: 9s - loss: 1.9418e-05 - accuracy: 1.0000 \u001b[0m\n",
      "\u001b[34m146/156 [===========================>..] - ETA: 8s - loss: 1.9402e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m147/156 [===========================>..] - ETA: 8s - loss: 1.9394e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m148/156 [===========================>..] - ETA: 7s - loss: 1.9324e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m149/156 [===========================>..] - ETA: 6s - loss: 1.9338e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m150/156 [===========================>..] - ETA: 5s - loss: 1.9266e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m151/156 [============================>.] - ETA: 4s - loss: 1.9185e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m152/156 [============================>.] - ETA: 3s - loss: 1.9108e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m153/156 [============================>.] - ETA: 2s - loss: 1.9046e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m154/156 [============================>.] - ETA: 1s - loss: 1.8975e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m155/156 [============================>.] - ETA: 0s - loss: 1.8926e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m156/156 [==============================] - 155s 993ms/step - loss: 1.9022e-05 - accuracy: 1.0000 - val_loss: 0.0542 - val_accuracy: 20.1592\u001b[0m\n",
      "\u001b[34mEpoch 5/10\u001b[0m\n",
      "\u001b[34m  1/156 [..............................] - ETA: 2:26 - loss: 1.1096e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m  2/156 [..............................] - ETA: 2:49 - loss: 1.0562e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m  3/156 [..............................] - ETA: 2:46 - loss: 9.7605e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m  4/156 [..............................] - ETA: 2:43 - loss: 1.1195e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m  5/156 [..............................] - ETA: 2:35 - loss: 9.8050e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m  6/156 [>.............................] - ETA: 2:30 - loss: 9.4079e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m  7/156 [>.............................] - ETA: 2:25 - loss: 8.5465e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m  8/156 [>.............................] - ETA: 2:21 - loss: 9.8969e-06 - accuracy: 1.0000\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m  9/156 [>.............................] - ETA: 2:20 - loss: 9.3393e-06 - accuracy: 1.0000\n",
      " 10/156 [>.............................] - ETA: 2:18 - loss: 9.0368e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 11/156 [=>............................] - ETA: 2:16 - loss: 8.8927e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 12/156 [=>............................] - ETA: 2:14 - loss: 1.3007e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 13/156 [=>............................] - ETA: 2:14 - loss: 1.3340e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 14/156 [=>............................] - ETA: 2:12 - loss: 1.3074e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 15/156 [=>............................] - ETA: 2:11 - loss: 1.3218e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 16/156 [==>...........................] - ETA: 2:09 - loss: 1.3608e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 17/156 [==>...........................] - ETA: 2:08 - loss: 1.5399e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 18/156 [==>...........................] - ETA: 2:08 - loss: 1.5069e-05 - accuracy: 1.0000\n",
      " 19/156 [==>...........................] - ETA: 2:06 - loss: 1.4512e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 20/156 [==>...........................] - ETA: 2:05 - loss: 1.4003e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 21/156 [===>..........................] - ETA: 2:04 - loss: 1.3900e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 22/156 [===>..........................] - ETA: 2:02 - loss: 1.4523e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 23/156 [===>..........................] - ETA: 2:01 - loss: 1.4335e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 24/156 [===>..........................] - ETA: 1:59 - loss: 1.4263e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 25/156 [===>..........................] - ETA: 1:58 - loss: 1.4197e-05 - accuracy: 1.0000\n",
      " 26/156 [====>.........................] - ETA: 1:57 - loss: 1.3802e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 27/156 [====>.........................] - ETA: 1:56 - loss: 1.3648e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 28/156 [====>.........................] - ETA: 1:55 - loss: 1.3598e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 29/156 [====>.........................] - ETA: 1:54 - loss: 1.3483e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 30/156 [====>.........................] - ETA: 1:53 - loss: 1.3322e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 31/156 [====>.........................] - ETA: 1:52 - loss: 1.4694e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 32/156 [=====>........................] - ETA: 1:51 - loss: 1.4681e-05 - accuracy: 1.0000\n",
      " 33/156 [=====>........................] - ETA: 1:50 - loss: 1.4397e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 34/156 [=====>........................] - ETA: 1:49 - loss: 1.4260e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 35/156 [=====>........................] - ETA: 1:48 - loss: 1.4055e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 36/156 [=====>........................] - ETA: 1:46 - loss: 1.3812e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 37/156 [======>.......................] - ETA: 1:46 - loss: 1.3661e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 38/156 [======>.......................] - ETA: 1:45 - loss: 1.3778e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 39/156 [======>.......................] - ETA: 1:44 - loss: 1.4070e-05 - accuracy: 1.0000\n",
      " 40/156 [======>.......................] - ETA: 1:43 - loss: 1.4236e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 41/156 [======>.......................] - ETA: 1:42 - loss: 1.4044e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 42/156 [=======>......................] - ETA: 1:41 - loss: 1.4067e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 43/156 [=======>......................] - ETA: 1:40 - loss: 1.3876e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 44/156 [=======>......................] - ETA: 1:39 - loss: 1.3654e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 45/156 [=======>......................] - ETA: 1:38 - loss: 1.3708e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 46/156 [=======>......................] - ETA: 1:37 - loss: 1.3832e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 47/156 [========>.....................] - ETA: 1:37 - loss: 1.3828e-05 - accuracy: 1.0000\n",
      " 48/156 [========>.....................] - ETA: 1:36 - loss: 1.3718e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 49/156 [========>.....................] - ETA: 1:35 - loss: 1.3761e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 50/156 [========>.....................] - ETA: 1:34 - loss: 1.3781e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 51/156 [========>.....................] - ETA: 1:33 - loss: 1.3710e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 52/156 [=========>....................] - ETA: 1:32 - loss: 1.3668e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 53/156 [=========>....................] - ETA: 1:31 - loss: 1.3632e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 54/156 [=========>....................] - ETA: 1:30 - loss: 1.3511e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 55/156 [=========>....................] - ETA: 1:29 - loss: 1.3325e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 56/156 [=========>....................] - ETA: 1:29 - loss: 1.3201e-05 - accuracy: 1.0000\n",
      " 57/156 [=========>....................] - ETA: 1:28 - loss: 1.3156e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 58/156 [==========>...................] - ETA: 1:27 - loss: 1.3069e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 59/156 [==========>...................] - ETA: 1:26 - loss: 1.3694e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 60/156 [==========>...................] - ETA: 1:25 - loss: 1.3709e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 61/156 [==========>...................] - ETA: 1:24 - loss: 1.3589e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 62/156 [==========>...................] - ETA: 1:23 - loss: 1.3430e-05 - accuracy: 1.0000\n",
      " 63/156 [===========>..................] - ETA: 1:22 - loss: 1.3628e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 64/156 [===========>..................] - ETA: 1:21 - loss: 1.3486e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 65/156 [===========>..................] - ETA: 1:20 - loss: 1.3375e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 66/156 [===========>..................] - ETA: 1:19 - loss: 1.3443e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 67/156 [===========>..................] - ETA: 1:19 - loss: 1.3379e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 68/156 [============>.................] - ETA: 1:18 - loss: 1.3248e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 69/156 [============>.................] - ETA: 1:17 - loss: 1.3136e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 70/156 [============>.................] - ETA: 1:16 - loss: 1.3788e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 71/156 [============>.................] - ETA: 1:16 - loss: 1.3822e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 72/156 [============>.................] - ETA: 1:15 - loss: 1.3702e-05 - accuracy: 1.0000\n",
      " 73/156 [=============>................] - ETA: 1:14 - loss: 1.3996e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 74/156 [=============>................] - ETA: 1:13 - loss: 1.3901e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 75/156 [=============>................] - ETA: 1:12 - loss: 1.3888e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 76/156 [=============>................] - ETA: 1:11 - loss: 1.3815e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 77/156 [=============>................] - ETA: 1:11 - loss: 1.3778e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 78/156 [==============>...............] - ETA: 1:10 - loss: 1.3664e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 79/156 [==============>...............] - ETA: 1:09 - loss: 1.3675e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 80/156 [==============>...............] - ETA: 1:08 - loss: 1.3724e-05 - accuracy: 1.0000\n",
      " 81/156 [==============>...............] - ETA: 1:07 - loss: 1.3748e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 82/156 [==============>...............] - ETA: 1:06 - loss: 1.3652e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 83/156 [==============>...............] - ETA: 1:05 - loss: 1.3609e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 84/156 [===============>..............] - ETA: 1:04 - loss: 1.3778e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 85/156 [===============>..............] - ETA: 1:03 - loss: 1.3650e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 86/156 [===============>..............] - ETA: 1:02 - loss: 1.3654e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 87/156 [===============>..............] - ETA: 1:02 - loss: 1.3604e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 88/156 [===============>..............] - ETA: 1:01 - loss: 1.3679e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 89/156 [================>.............] - ETA: 1:00 - loss: 1.3863e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 90/156 [================>.............] - ETA: 59s - loss: 1.3841e-05 - accuracy: 1.0000 \n",
      " 91/156 [================>.............] - ETA: 58s - loss: 1.3828e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 92/156 [================>.............] - ETA: 57s - loss: 1.3766e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 93/156 [================>.............] - ETA: 56s - loss: 1.3992e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 94/156 [=================>............] - ETA: 55s - loss: 1.3958e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 95/156 [=================>............] - ETA: 54s - loss: 1.3860e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 96/156 [=================>............] - ETA: 53s - loss: 1.3790e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 97/156 [=================>............] - ETA: 52s - loss: 1.3720e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 98/156 [=================>............] - ETA: 52s - loss: 1.3680e-05 - accuracy: 1.0000\n",
      " 99/156 [==================>...........] - ETA: 51s - loss: 1.3679e-05 - accuracy: 1.0000\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m100/156 [==================>...........] - ETA: 50s - loss: 1.3652e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m101/156 [==================>...........] - ETA: 49s - loss: 1.3625e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m102/156 [==================>...........] - ETA: 48s - loss: 1.3575e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m103/156 [==================>...........] - ETA: 47s - loss: 1.3487e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m104/156 [===================>..........] - ETA: 46s - loss: 1.3545e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m105/156 [===================>..........] - ETA: 45s - loss: 1.3651e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m106/156 [===================>..........] - ETA: 44s - loss: 1.3584e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m107/156 [===================>..........] - ETA: 43s - loss: 1.3493e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m108/156 [===================>..........] - ETA: 43s - loss: 1.3425e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m109/156 [===================>..........] - ETA: 42s - loss: 1.3333e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m110/156 [====================>.........] - ETA: 41s - loss: 1.3326e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m111/156 [====================>.........] - ETA: 40s - loss: 1.3326e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m112/156 [====================>.........] - ETA: 39s - loss: 1.3362e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m113/156 [====================>.........] - ETA: 38s - loss: 1.3325e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m114/156 [====================>.........] - ETA: 37s - loss: 1.3301e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m115/156 [=====================>........] - ETA: 36s - loss: 1.3248e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m116/156 [=====================>........] - ETA: 35s - loss: 1.3171e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m117/156 [=====================>........] - ETA: 34s - loss: 1.3171e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m118/156 [=====================>........] - ETA: 34s - loss: 1.3149e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m119/156 [=====================>........] - ETA: 33s - loss: 1.3094e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m120/156 [======================>.......] - ETA: 32s - loss: 1.3039e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m121/156 [======================>.......] - ETA: 31s - loss: 1.3031e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m122/156 [======================>.......] - ETA: 30s - loss: 1.3043e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m123/156 [======================>.......] - ETA: 29s - loss: 1.2972e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m124/156 [======================>.......] - ETA: 28s - loss: 1.2897e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m125/156 [=======================>......] - ETA: 27s - loss: 1.2857e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m126/156 [=======================>......] - ETA: 26s - loss: 1.3019e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m127/156 [=======================>......] - ETA: 25s - loss: 1.2991e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m128/156 [=======================>......] - ETA: 25s - loss: 1.2931e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m129/156 [=======================>......] - ETA: 24s - loss: 1.2850e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m130/156 [========================>.....] - ETA: 23s - loss: 1.2856e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m131/156 [========================>.....] - ETA: 22s - loss: 1.2813e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m132/156 [========================>.....] - ETA: 21s - loss: 1.2828e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m133/156 [========================>.....] - ETA: 20s - loss: 1.2755e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m134/156 [========================>.....] - ETA: 19s - loss: 1.2711e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m135/156 [========================>.....] - ETA: 18s - loss: 1.2652e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m136/156 [=========================>....] - ETA: 17s - loss: 1.2578e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m137/156 [=========================>....] - ETA: 17s - loss: 1.2520e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m138/156 [=========================>....] - ETA: 16s - loss: 1.2463e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m139/156 [=========================>....] - ETA: 15s - loss: 1.2444e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m140/156 [=========================>....] - ETA: 14s - loss: 1.2454e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m141/156 [==========================>...] - ETA: 13s - loss: 1.2467e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m142/156 [==========================>...] - ETA: 12s - loss: 1.2412e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m143/156 [==========================>...] - ETA: 11s - loss: 1.2380e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m144/156 [==========================>...] - ETA: 10s - loss: 1.2393e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m145/156 [==========================>...] - ETA: 9s - loss: 1.2361e-05 - accuracy: 1.0000 \u001b[0m\n",
      "\u001b[34m146/156 [===========================>..] - ETA: 9s - loss: 1.2313e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m147/156 [===========================>..] - ETA: 8s - loss: 1.2296e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m148/156 [===========================>..] - ETA: 7s - loss: 1.2233e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m149/156 [===========================>..] - ETA: 6s - loss: 1.2298e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m150/156 [===========================>..] - ETA: 5s - loss: 1.2328e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m151/156 [============================>.] - ETA: 4s - loss: 1.2281e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m152/156 [============================>.] - ETA: 3s - loss: 1.2264e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m153/156 [============================>.] - ETA: 2s - loss: 1.2243e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m154/156 [============================>.] - ETA: 1s - loss: 1.2307e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m155/156 [============================>.] - ETA: 0s - loss: 1.2260e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m156/156 [==============================] - 156s 1s/step - loss: 1.2303e-05 - accuracy: 1.0000 - val_loss: 0.0586 - val_accuracy: 21.4052\u001b[0m\n",
      "\u001b[34mEpoch 6/10\u001b[0m\n",
      "\u001b[34m  1/156 [..............................] - ETA: 2:11 - loss: 4.5633e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m  2/156 [..............................] - ETA: 2:12 - loss: 2.5245e-05 - accuracy: 1.0000\n",
      "  3/156 [..............................] - ETA: 2:11 - loss: 1.9757e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m  4/156 [..............................] - ETA: 2:10 - loss: 1.5991e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m  5/156 [..............................] - ETA: 2:07 - loss: 1.4212e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m  6/156 [>.............................] - ETA: 2:08 - loss: 1.2687e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m  7/156 [>.............................] - ETA: 2:09 - loss: 1.1781e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m  8/156 [>.............................] - ETA: 2:08 - loss: 1.1097e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m  9/156 [>.............................] - ETA: 2:07 - loss: 1.0393e-05 - accuracy: 1.0000\n",
      " 10/156 [>.............................] - ETA: 2:06 - loss: 1.1095e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 11/156 [=>............................] - ETA: 2:05 - loss: 1.0884e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 12/156 [=>............................] - ETA: 2:04 - loss: 1.0828e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 13/156 [=>............................] - ETA: 2:03 - loss: 1.0246e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 14/156 [=>............................] - ETA: 2:02 - loss: 1.0191e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 15/156 [=>............................] - ETA: 2:03 - loss: 9.9432e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 16/156 [==>...........................] - ETA: 2:02 - loss: 1.0054e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 17/156 [==>...........................] - ETA: 2:02 - loss: 1.0007e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 18/156 [==>...........................] - ETA: 2:01 - loss: 9.9165e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 19/156 [==>...........................] - ETA: 2:00 - loss: 9.5451e-06 - accuracy: 1.0000\n",
      " 20/156 [==>...........................] - ETA: 1:59 - loss: 9.5836e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 21/156 [===>..........................] - ETA: 1:58 - loss: 9.5250e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 22/156 [===>..........................] - ETA: 1:57 - loss: 9.2420e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 23/156 [===>..........................] - ETA: 1:56 - loss: 9.0406e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 24/156 [===>..........................] - ETA: 1:55 - loss: 8.9640e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 25/156 [===>..........................] - ETA: 1:54 - loss: 8.8748e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 26/156 [====>.........................] - ETA: 1:54 - loss: 8.8612e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 27/156 [====>.........................] - ETA: 1:54 - loss: 9.1566e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 28/156 [====>.........................] - ETA: 1:54 - loss: 8.9917e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 29/156 [====>.........................] - ETA: 1:54 - loss: 9.1229e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 30/156 [====>.........................] - ETA: 1:55 - loss: 9.0839e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 31/156 [====>.........................] - ETA: 1:54 - loss: 8.9268e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 32/156 [=====>........................] - ETA: 1:53 - loss: 8.8416e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 33/156 [=====>........................] - ETA: 1:52 - loss: 8.8246e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 34/156 [=====>........................] - ETA: 1:51 - loss: 8.9175e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 35/156 [=====>........................] - ETA: 1:50 - loss: 8.9939e-06 - accuracy: 1.0000\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m 36/156 [=====>........................] - ETA: 1:49 - loss: 8.9106e-06 - accuracy: 1.0000\n",
      " 37/156 [======>.......................] - ETA: 1:48 - loss: 9.0953e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 38/156 [======>.......................] - ETA: 1:46 - loss: 9.3353e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 39/156 [======>.......................] - ETA: 1:46 - loss: 9.2952e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 40/156 [======>.......................] - ETA: 1:45 - loss: 9.1885e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 41/156 [======>.......................] - ETA: 1:44 - loss: 1.0598e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 42/156 [=======>......................] - ETA: 1:43 - loss: 1.0627e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 43/156 [=======>......................] - ETA: 1:41 - loss: 1.0551e-05 - accuracy: 1.0000\n",
      " 44/156 [=======>......................] - ETA: 1:40 - loss: 1.0382e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 45/156 [=======>......................] - ETA: 1:39 - loss: 1.0388e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 46/156 [=======>......................] - ETA: 1:38 - loss: 1.0493e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 47/156 [========>.....................] - ETA: 1:37 - loss: 1.0539e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 48/156 [========>.....................] - ETA: 1:37 - loss: 1.0733e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 49/156 [========>.....................] - ETA: 1:36 - loss: 1.0988e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 50/156 [========>.....................] - ETA: 1:35 - loss: 1.0805e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 51/156 [========>.....................] - ETA: 1:34 - loss: 1.0723e-05 - accuracy: 1.0000\n",
      " 52/156 [=========>....................] - ETA: 1:33 - loss: 1.0612e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 53/156 [=========>....................] - ETA: 1:32 - loss: 1.0552e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 54/156 [=========>....................] - ETA: 1:31 - loss: 1.0492e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 55/156 [=========>....................] - ETA: 1:30 - loss: 1.1572e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 56/156 [=========>....................] - ETA: 1:29 - loss: 1.1523e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 57/156 [=========>....................] - ETA: 1:28 - loss: 1.1395e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 58/156 [==========>...................] - ETA: 1:27 - loss: 1.1271e-05 - accuracy: 1.0000\n",
      " 59/156 [==========>...................] - ETA: 1:26 - loss: 1.1230e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 60/156 [==========>...................] - ETA: 1:25 - loss: 1.1176e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 61/156 [==========>...................] - ETA: 1:24 - loss: 1.1044e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 62/156 [==========>...................] - ETA: 1:23 - loss: 1.0931e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 63/156 [===========>..................] - ETA: 1:22 - loss: 1.0844e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 64/156 [===========>..................] - ETA: 1:21 - loss: 1.0761e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 65/156 [===========>..................] - ETA: 1:20 - loss: 1.0687e-05 - accuracy: 1.0000\n",
      " 66/156 [===========>..................] - ETA: 1:20 - loss: 1.0694e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 67/156 [===========>..................] - ETA: 1:19 - loss: 1.0613e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 68/156 [============>.................] - ETA: 1:18 - loss: 1.0515e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 69/156 [============>.................] - ETA: 1:17 - loss: 1.0448e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 70/156 [============>.................] - ETA: 1:16 - loss: 1.0319e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 71/156 [============>.................] - ETA: 1:15 - loss: 1.0215e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 72/156 [============>.................] - ETA: 1:14 - loss: 1.0379e-05 - accuracy: 1.0000\n",
      " 73/156 [=============>................] - ETA: 1:13 - loss: 1.0330e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 74/156 [=============>................] - ETA: 1:12 - loss: 1.0269e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 75/156 [=============>................] - ETA: 1:11 - loss: 1.0196e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 76/156 [=============>................] - ETA: 1:10 - loss: 1.0115e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 77/156 [=============>................] - ETA: 1:09 - loss: 1.0023e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 78/156 [==============>...............] - ETA: 1:08 - loss: 1.0032e-05 - accuracy: 1.0000\n",
      " 79/156 [==============>...............] - ETA: 1:08 - loss: 9.9254e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 80/156 [==============>...............] - ETA: 1:07 - loss: 9.9384e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 81/156 [==============>...............] - ETA: 1:06 - loss: 9.8834e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 82/156 [==============>...............] - ETA: 1:05 - loss: 9.8117e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 83/156 [==============>...............] - ETA: 1:04 - loss: 9.8166e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 84/156 [===============>..............] - ETA: 1:03 - loss: 9.7657e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 85/156 [===============>..............] - ETA: 1:02 - loss: 9.7137e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 86/156 [===============>..............] - ETA: 1:01 - loss: 9.7110e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 87/156 [===============>..............] - ETA: 1:00 - loss: 9.7642e-06 - accuracy: 1.0000\n",
      " 88/156 [===============>..............] - ETA: 1:00 - loss: 9.6821e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 89/156 [================>.............] - ETA: 59s - loss: 9.6329e-06 - accuracy: 1.0000 \u001b[0m\n",
      "\u001b[34m 90/156 [================>.............] - ETA: 58s - loss: 9.6187e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 91/156 [================>.............] - ETA: 57s - loss: 9.5532e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 92/156 [================>.............] - ETA: 56s - loss: 9.4858e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 93/156 [================>.............] - ETA: 55s - loss: 9.4816e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 94/156 [=================>............] - ETA: 54s - loss: 9.5478e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 95/156 [=================>............] - ETA: 54s - loss: 9.4855e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 96/156 [=================>............] - ETA: 53s - loss: 9.4402e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 97/156 [=================>............] - ETA: 52s - loss: 9.5378e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 98/156 [=================>............] - ETA: 51s - loss: 9.4710e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 99/156 [==================>...........] - ETA: 50s - loss: 9.5400e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m100/156 [==================>...........] - ETA: 50s - loss: 9.5970e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m101/156 [==================>...........] - ETA: 49s - loss: 9.7440e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m102/156 [==================>...........] - ETA: 48s - loss: 9.7295e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m103/156 [==================>...........] - ETA: 47s - loss: 9.6880e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m104/156 [===================>..........] - ETA: 46s - loss: 9.7054e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m105/156 [===================>..........] - ETA: 45s - loss: 9.7331e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m106/156 [===================>..........] - ETA: 44s - loss: 9.7016e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m107/156 [===================>..........] - ETA: 43s - loss: 9.6408e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m108/156 [===================>..........] - ETA: 42s - loss: 9.5819e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m109/156 [===================>..........] - ETA: 41s - loss: 9.6593e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m110/156 [====================>.........] - ETA: 41s - loss: 9.6328e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m111/156 [====================>.........] - ETA: 40s - loss: 9.6068e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m112/156 [====================>.........] - ETA: 39s - loss: 9.6445e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m113/156 [====================>.........] - ETA: 38s - loss: 9.6090e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m114/156 [====================>.........] - ETA: 37s - loss: 9.5509e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m115/156 [=====================>........] - ETA: 36s - loss: 9.4944e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m116/156 [=====================>........] - ETA: 35s - loss: 9.4775e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m117/156 [=====================>........] - ETA: 34s - loss: 9.4318e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m118/156 [=====================>........] - ETA: 33s - loss: 9.4013e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m119/156 [=====================>........] - ETA: 32s - loss: 9.3479e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m120/156 [======================>.......] - ETA: 32s - loss: 9.3308e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m121/156 [======================>.......] - ETA: 31s - loss: 9.2884e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m122/156 [======================>.......] - ETA: 30s - loss: 9.2449e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m123/156 [======================>.......] - ETA: 29s - loss: 9.1938e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m124/156 [======================>.......] - ETA: 28s - loss: 9.2143e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m125/156 [=======================>......] - ETA: 27s - loss: 9.1656e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m126/156 [=======================>......] - ETA: 26s - loss: 9.1521e-06 - accuracy: 1.0000\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m127/156 [=======================>......] - ETA: 25s - loss: 9.1014e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m128/156 [=======================>......] - ETA: 24s - loss: 9.0601e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m129/156 [=======================>......] - ETA: 24s - loss: 9.0490e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m130/156 [========================>.....] - ETA: 23s - loss: 9.0205e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m131/156 [========================>.....] - ETA: 22s - loss: 8.9999e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m132/156 [========================>.....] - ETA: 21s - loss: 9.0292e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m133/156 [========================>.....] - ETA: 20s - loss: 8.9787e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m134/156 [========================>.....] - ETA: 19s - loss: 8.9492e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m135/156 [========================>.....] - ETA: 18s - loss: 8.9057e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m136/156 [=========================>....] - ETA: 17s - loss: 8.9333e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m137/156 [=========================>....] - ETA: 16s - loss: 8.8903e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m138/156 [=========================>....] - ETA: 16s - loss: 8.8432e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m139/156 [=========================>....] - ETA: 15s - loss: 8.8098e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m140/156 [=========================>....] - ETA: 14s - loss: 8.7901e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m141/156 [==========================>...] - ETA: 13s - loss: 8.7762e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m142/156 [==========================>...] - ETA: 12s - loss: 8.7451e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m143/156 [==========================>...] - ETA: 11s - loss: 8.7789e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m144/156 [==========================>...] - ETA: 10s - loss: 8.7491e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m145/156 [==========================>...] - ETA: 9s - loss: 8.7661e-06 - accuracy: 1.0000 \u001b[0m\n",
      "\u001b[34m146/156 [===========================>..] - ETA: 8s - loss: 8.7451e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m147/156 [===========================>..] - ETA: 7s - loss: 8.8341e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m148/156 [===========================>..] - ETA: 7s - loss: 8.8005e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m149/156 [===========================>..] - ETA: 6s - loss: 8.8637e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m150/156 [===========================>..] - ETA: 5s - loss: 8.8176e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m151/156 [============================>.] - ETA: 4s - loss: 8.7760e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m152/156 [============================>.] - ETA: 3s - loss: 8.7386e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m153/156 [============================>.] - ETA: 2s - loss: 8.7102e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m154/156 [============================>.] - ETA: 1s - loss: 8.6810e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m155/156 [============================>.] - ETA: 0s - loss: 8.6467e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m156/156 [==============================] - 155s 992ms/step - loss: 8.6404e-06 - accuracy: 1.0000 - val_loss: 0.0508 - val_accuracy: 21.2744\u001b[0m\n",
      "\u001b[34mEpoch 7/10\u001b[0m\n",
      "\u001b[34m  1/156 [..............................] - ETA: 2:20 - loss: 6.9935e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m  2/156 [..............................] - ETA: 2:14 - loss: 7.0234e-06 - accuracy: 1.0000\n",
      "  3/156 [..............................] - ETA: 2:13 - loss: 1.1176e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m  4/156 [..............................] - ETA: 2:13 - loss: 9.5472e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m  5/156 [..............................] - ETA: 2:13 - loss: 9.0039e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m  6/156 [>.............................] - ETA: 2:12 - loss: 9.5153e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m  7/156 [>.............................] - ETA: 2:10 - loss: 9.4579e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m  8/156 [>.............................] - ETA: 2:08 - loss: 8.9058e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m  9/156 [>.............................] - ETA: 2:08 - loss: 9.8761e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 10/156 [>.............................] - ETA: 2:07 - loss: 1.0002e-05 - accuracy: 1.0000\n",
      " 11/156 [=>............................] - ETA: 2:06 - loss: 9.6475e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 12/156 [=>............................] - ETA: 2:06 - loss: 9.2537e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 13/156 [=>............................] - ETA: 2:06 - loss: 8.9128e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 14/156 [=>............................] - ETA: 2:06 - loss: 8.6577e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 15/156 [=>............................] - ETA: 2:05 - loss: 8.2885e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 16/156 [==>...........................] - ETA: 2:04 - loss: 8.0891e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 17/156 [==>...........................] - ETA: 2:03 - loss: 7.9832e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 18/156 [==>...........................] - ETA: 2:02 - loss: 8.8796e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 19/156 [==>...........................] - ETA: 2:01 - loss: 1.4058e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 20/156 [==>...........................] - ETA: 2:00 - loss: 1.3491e-05 - accuracy: 1.0000\n",
      " 21/156 [===>..........................] - ETA: 1:59 - loss: 1.2966e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 22/156 [===>..........................] - ETA: 1:58 - loss: 1.2913e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 23/156 [===>..........................] - ETA: 1:57 - loss: 1.2558e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 24/156 [===>..........................] - ETA: 1:55 - loss: 1.2190e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 25/156 [===>..........................] - ETA: 1:54 - loss: 1.3878e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 26/156 [====>.........................] - ETA: 1:53 - loss: 1.3495e-05 - accuracy: 1.0000\n",
      " 27/156 [====>.........................] - ETA: 1:53 - loss: 1.3144e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 28/156 [====>.........................] - ETA: 1:52 - loss: 1.3018e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 29/156 [====>.........................] - ETA: 1:51 - loss: 1.2748e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 30/156 [====>.........................] - ETA: 1:50 - loss: 1.2583e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 31/156 [====>.........................] - ETA: 1:49 - loss: 1.2507e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 32/156 [=====>........................] - ETA: 1:48 - loss: 1.2281e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 33/156 [=====>........................] - ETA: 1:48 - loss: 1.1992e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 34/156 [=====>........................] - ETA: 1:47 - loss: 1.1759e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 35/156 [=====>........................] - ETA: 1:46 - loss: 1.1575e-05 - accuracy: 1.0000\n",
      " 36/156 [=====>........................] - ETA: 1:45 - loss: 1.1336e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 37/156 [======>.......................] - ETA: 1:44 - loss: 1.1189e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 38/156 [======>.......................] - ETA: 1:44 - loss: 1.1067e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 39/156 [======>.......................] - ETA: 1:43 - loss: 1.0835e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 40/156 [======>.......................] - ETA: 1:42 - loss: 1.1412e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 41/156 [======>.......................] - ETA: 1:41 - loss: 1.1239e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 42/156 [=======>......................] - ETA: 1:40 - loss: 1.1143e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 43/156 [=======>......................] - ETA: 1:39 - loss: 1.0991e-05 - accuracy: 1.0000\n",
      " 44/156 [=======>......................] - ETA: 1:38 - loss: 1.0921e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 45/156 [=======>......................] - ETA: 1:37 - loss: 1.0809e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 46/156 [=======>......................] - ETA: 1:36 - loss: 1.0720e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 47/156 [========>.....................] - ETA: 1:35 - loss: 1.0608e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 48/156 [========>.....................] - ETA: 1:35 - loss: 1.0501e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 49/156 [========>.....................] - ETA: 1:34 - loss: 1.0398e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 50/156 [========>.....................] - ETA: 1:33 - loss: 1.0359e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 51/156 [========>.....................] - ETA: 1:32 - loss: 1.0205e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 52/156 [=========>....................] - ETA: 1:31 - loss: 1.0058e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 53/156 [=========>....................] - ETA: 1:31 - loss: 9.9880e-06 - accuracy: 1.0000\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m 54/156 [=========>....................] - ETA: 1:30 - loss: 1.0094e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 55/156 [=========>....................] - ETA: 1:29 - loss: 1.0071e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 56/156 [=========>....................] - ETA: 1:29 - loss: 1.0007e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 57/156 [=========>....................] - ETA: 1:29 - loss: 9.8945e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 58/156 [==========>...................] - ETA: 1:28 - loss: 9.7760e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 59/156 [==========>...................] - ETA: 1:27 - loss: 9.7350e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 60/156 [==========>...................] - ETA: 1:26 - loss: 9.7749e-06 - accuracy: 1.0000\n",
      " 61/156 [==========>...................] - ETA: 1:25 - loss: 9.7171e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 62/156 [==========>...................] - ETA: 1:24 - loss: 9.6225e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 63/156 [===========>..................] - ETA: 1:23 - loss: 9.5098e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 64/156 [===========>..................] - ETA: 1:22 - loss: 9.5416e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 65/156 [===========>..................] - ETA: 1:21 - loss: 9.4704e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 66/156 [===========>..................] - ETA: 1:20 - loss: 9.3812e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 67/156 [===========>..................] - ETA: 1:19 - loss: 9.2846e-06 - accuracy: 1.0000\n",
      " 68/156 [============>.................] - ETA: 1:18 - loss: 9.2444e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 69/156 [============>.................] - ETA: 1:17 - loss: 9.1822e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 70/156 [============>.................] - ETA: 1:16 - loss: 9.1028e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 71/156 [============>.................] - ETA: 1:15 - loss: 9.0497e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 72/156 [============>.................] - ETA: 1:15 - loss: 9.0086e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 73/156 [=============>................] - ETA: 1:14 - loss: 8.9410e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 74/156 [=============>................] - ETA: 1:13 - loss: 8.9170e-06 - accuracy: 1.0000\n",
      " 75/156 [=============>................] - ETA: 1:12 - loss: 8.8394e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 76/156 [=============>................] - ETA: 1:11 - loss: 8.7550e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 77/156 [=============>................] - ETA: 1:10 - loss: 8.6838e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 78/156 [==============>...............] - ETA: 1:09 - loss: 8.7585e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 79/156 [==============>...............] - ETA: 1:08 - loss: 8.7852e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 80/156 [==============>...............] - ETA: 1:07 - loss: 8.7781e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 81/156 [==============>...............] - ETA: 1:07 - loss: 8.7712e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 82/156 [==============>...............] - ETA: 1:06 - loss: 8.7321e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 83/156 [==============>...............] - ETA: 1:05 - loss: 8.6778e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 84/156 [===============>..............] - ETA: 1:04 - loss: 8.6134e-06 - accuracy: 1.0000\n",
      " 85/156 [===============>..............] - ETA: 1:03 - loss: 8.5547e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 86/156 [===============>..............] - ETA: 1:02 - loss: 8.4866e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 87/156 [===============>..............] - ETA: 1:01 - loss: 8.5849e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 88/156 [===============>..............] - ETA: 1:00 - loss: 8.5318e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 89/156 [================>.............] - ETA: 59s - loss: 8.5412e-06 - accuracy: 1.0000 \u001b[0m\n",
      "\u001b[34m 90/156 [================>.............] - ETA: 58s - loss: 8.5537e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 91/156 [================>.............] - ETA: 57s - loss: 8.5303e-06 - accuracy: 1.0000\n",
      " 92/156 [================>.............] - ETA: 57s - loss: 8.4568e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 93/156 [================>.............] - ETA: 56s - loss: 8.4295e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 94/156 [=================>............] - ETA: 55s - loss: 8.3917e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 95/156 [=================>............] - ETA: 54s - loss: 8.3504e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 96/156 [=================>............] - ETA: 53s - loss: 8.3458e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 97/156 [=================>............] - ETA: 52s - loss: 8.3639e-06 - accuracy: 1.0000\n",
      " 98/156 [=================>............] - ETA: 51s - loss: 8.3606e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 99/156 [==================>...........] - ETA: 50s - loss: 8.2969e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m100/156 [==================>...........] - ETA: 49s - loss: 8.2592e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m101/156 [==================>...........] - ETA: 48s - loss: 8.2997e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m102/156 [==================>...........] - ETA: 47s - loss: 8.3333e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m103/156 [==================>...........] - ETA: 47s - loss: 8.3269e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m104/156 [===================>..........] - ETA: 46s - loss: 8.3353e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m105/156 [===================>..........] - ETA: 45s - loss: 8.3302e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m106/156 [===================>..........] - ETA: 44s - loss: 8.2730e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m107/156 [===================>..........] - ETA: 43s - loss: 8.3262e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m108/156 [===================>..........] - ETA: 42s - loss: 8.2886e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m109/156 [===================>..........] - ETA: 41s - loss: 8.2609e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m110/156 [====================>.........] - ETA: 40s - loss: 8.2440e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m111/156 [====================>.........] - ETA: 39s - loss: 8.1963e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m112/156 [====================>.........] - ETA: 38s - loss: 8.1808e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m113/156 [====================>.........] - ETA: 38s - loss: 8.1374e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m114/156 [====================>.........] - ETA: 37s - loss: 8.1517e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m115/156 [=====================>........] - ETA: 36s - loss: 8.4465e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m116/156 [=====================>........] - ETA: 35s - loss: 8.4187e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m117/156 [=====================>........] - ETA: 34s - loss: 8.3677e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m118/156 [=====================>........] - ETA: 33s - loss: 8.3206e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m119/156 [=====================>........] - ETA: 32s - loss: 8.2818e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m120/156 [======================>.......] - ETA: 31s - loss: 8.2677e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m121/156 [======================>.......] - ETA: 31s - loss: 8.2348e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m122/156 [======================>.......] - ETA: 30s - loss: 8.2162e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m123/156 [======================>.......] - ETA: 29s - loss: 8.2205e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m124/156 [======================>.......] - ETA: 28s - loss: 8.2249e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m125/156 [=======================>......] - ETA: 27s - loss: 8.1744e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m126/156 [=======================>......] - ETA: 26s - loss: 8.1352e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m127/156 [=======================>......] - ETA: 25s - loss: 8.2793e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m128/156 [=======================>......] - ETA: 25s - loss: 8.2962e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m129/156 [=======================>......] - ETA: 24s - loss: 8.2665e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m130/156 [========================>.....] - ETA: 23s - loss: 8.2360e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m131/156 [========================>.....] - ETA: 22s - loss: 8.1980e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m132/156 [========================>.....] - ETA: 21s - loss: 8.1528e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m133/156 [========================>.....] - ETA: 20s - loss: 8.1149e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m134/156 [========================>.....] - ETA: 19s - loss: 8.1193e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m135/156 [========================>.....] - ETA: 18s - loss: 8.2208e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m136/156 [=========================>....] - ETA: 17s - loss: 8.2851e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m137/156 [=========================>....] - ETA: 16s - loss: 8.2556e-06 - accuracy: 1.0000\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m138/156 [=========================>....] - ETA: 16s - loss: 8.2504e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m139/156 [=========================>....] - ETA: 15s - loss: 8.2226e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m140/156 [=========================>....] - ETA: 14s - loss: 8.1900e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m141/156 [==========================>...] - ETA: 13s - loss: 8.1647e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m142/156 [==========================>...] - ETA: 12s - loss: 8.1812e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m143/156 [==========================>...] - ETA: 11s - loss: 8.1825e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m144/156 [==========================>...] - ETA: 10s - loss: 8.1682e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m145/156 [==========================>...] - ETA: 9s - loss: 8.1581e-06 - accuracy: 1.0000 \u001b[0m\n",
      "\u001b[34m146/156 [===========================>..] - ETA: 8s - loss: 8.1209e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m147/156 [===========================>..] - ETA: 8s - loss: 8.1151e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m148/156 [===========================>..] - ETA: 7s - loss: 8.0798e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m149/156 [===========================>..] - ETA: 6s - loss: 8.0656e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m150/156 [===========================>..] - ETA: 5s - loss: 8.0603e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m151/156 [============================>.] - ETA: 4s - loss: 8.0343e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m152/156 [============================>.] - ETA: 3s - loss: 8.0230e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m153/156 [============================>.] - ETA: 2s - loss: 8.0036e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m154/156 [============================>.] - ETA: 1s - loss: 7.9689e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m155/156 [============================>.] - ETA: 0s - loss: 7.9568e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m156/156 [==============================] - 154s 987ms/step - loss: 7.9197e-06 - accuracy: 1.0000 - val_loss: 0.0502 - val_accuracy: 20.9456\u001b[0m\n",
      "\u001b[34mEpoch 8/10\u001b[0m\n",
      "\u001b[34m  1/156 [..............................] - ETA: 2:06 - loss: 2.7943e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m  2/156 [..............................] - ETA: 2:13 - loss: 1.4666e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m  3/156 [..............................] - ETA: 2:11 - loss: 1.1164e-05 - accuracy: 1.0000\n",
      "  4/156 [..............................] - ETA: 2:11 - loss: 9.0284e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m  5/156 [..............................] - ETA: 2:11 - loss: 8.9779e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m  6/156 [>.............................] - ETA: 2:09 - loss: 7.9908e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m  7/156 [>.............................] - ETA: 2:09 - loss: 9.5108e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m  8/156 [>.............................] - ETA: 2:09 - loss: 1.0184e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m  9/156 [>.............................] - ETA: 2:08 - loss: 9.4133e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 10/156 [>.............................] - ETA: 2:08 - loss: 9.2895e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 11/156 [=>............................] - ETA: 2:09 - loss: 9.1501e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 12/156 [=>............................] - ETA: 2:07 - loss: 8.7599e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 13/156 [=>............................] - ETA: 2:06 - loss: 1.0563e-05 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 14/156 [=>............................] - ETA: 2:08 - loss: 1.0236e-05 - accuracy: 1.0000\n",
      " 15/156 [=>............................] - ETA: 2:06 - loss: 9.8510e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 16/156 [==>...........................] - ETA: 2:05 - loss: 9.8180e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 17/156 [==>...........................] - ETA: 2:06 - loss: 9.5392e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 18/156 [==>...........................] - ETA: 2:05 - loss: 9.7801e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 19/156 [==>...........................] - ETA: 2:07 - loss: 9.5526e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 20/156 [==>...........................] - ETA: 2:07 - loss: 9.1752e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 21/156 [===>..........................] - ETA: 2:06 - loss: 9.0668e-06 - accuracy: 1.0000\n",
      " 22/156 [===>..........................] - ETA: 2:05 - loss: 8.9982e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 23/156 [===>..........................] - ETA: 2:03 - loss: 8.8299e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 24/156 [===>..........................] - ETA: 2:02 - loss: 8.5914e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 25/156 [===>..........................] - ETA: 2:00 - loss: 8.4675e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 26/156 [====>.........................] - ETA: 1:59 - loss: 8.2397e-06 - accuracy: 1.0000\n",
      " 27/156 [====>.........................] - ETA: 1:58 - loss: 8.0603e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 28/156 [====>.........................] - ETA: 1:56 - loss: 8.1011e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 29/156 [====>.........................] - ETA: 1:55 - loss: 7.9386e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 30/156 [====>.........................] - ETA: 1:54 - loss: 7.7802e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 31/156 [====>.........................] - ETA: 1:53 - loss: 7.6081e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 32/156 [=====>........................] - ETA: 1:52 - loss: 7.5965e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 33/156 [=====>........................] - ETA: 1:51 - loss: 7.5512e-06 - accuracy: 1.0000\n",
      " 34/156 [=====>........................] - ETA: 1:50 - loss: 7.5298e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 35/156 [=====>........................] - ETA: 1:48 - loss: 7.4024e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 36/156 [=====>........................] - ETA: 1:47 - loss: 7.2779e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 37/156 [======>.......................] - ETA: 1:46 - loss: 7.2602e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 38/156 [======>.......................] - ETA: 1:45 - loss: 7.2306e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 39/156 [======>.......................] - ETA: 1:45 - loss: 7.3150e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 40/156 [======>.......................] - ETA: 1:44 - loss: 7.2351e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 41/156 [======>.......................] - ETA: 1:43 - loss: 7.1849e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 42/156 [=======>......................] - ETA: 1:42 - loss: 7.0741e-06 - accuracy: 1.0000\n",
      " 43/156 [=======>......................] - ETA: 1:41 - loss: 7.3773e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 44/156 [=======>......................] - ETA: 1:40 - loss: 7.2895e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 45/156 [=======>......................] - ETA: 1:39 - loss: 7.1569e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 46/156 [=======>......................] - ETA: 1:38 - loss: 7.0853e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 47/156 [========>.....................] - ETA: 1:37 - loss: 7.0354e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 48/156 [========>.....................] - ETA: 1:36 - loss: 6.9710e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 49/156 [========>.....................] - ETA: 1:35 - loss: 6.8616e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 50/156 [========>.....................] - ETA: 1:34 - loss: 6.9776e-06 - accuracy: 1.0000\n",
      " 51/156 [========>.....................] - ETA: 1:33 - loss: 7.0889e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 52/156 [=========>....................] - ETA: 1:32 - loss: 7.0091e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 53/156 [=========>....................] - ETA: 1:31 - loss: 7.0420e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 54/156 [=========>....................] - ETA: 1:30 - loss: 6.9679e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 55/156 [=========>....................] - ETA: 1:29 - loss: 6.9475e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 56/156 [=========>....................] - ETA: 1:29 - loss: 6.9610e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 57/156 [=========>....................] - ETA: 1:28 - loss: 6.9658e-06 - accuracy: 1.0000\n",
      " 58/156 [==========>...................] - ETA: 1:27 - loss: 7.2021e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 59/156 [==========>...................] - ETA: 1:26 - loss: 7.2018e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 60/156 [==========>...................] - ETA: 1:25 - loss: 7.1661e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 61/156 [==========>...................] - ETA: 1:24 - loss: 7.1045e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 62/156 [==========>...................] - ETA: 1:23 - loss: 7.0208e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 63/156 [===========>..................] - ETA: 1:22 - loss: 7.0415e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 64/156 [===========>..................] - ETA: 1:21 - loss: 7.0882e-06 - accuracy: 1.0000\n",
      " 65/156 [===========>..................] - ETA: 1:20 - loss: 7.0179e-06 - accuracy: 1.0000\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m 66/156 [===========>..................] - ETA: 1:19 - loss: 6.9393e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 67/156 [===========>..................] - ETA: 1:18 - loss: 6.8742e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 68/156 [============>.................] - ETA: 1:17 - loss: 6.8634e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 69/156 [============>.................] - ETA: 1:16 - loss: 6.8158e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 70/156 [============>.................] - ETA: 1:16 - loss: 6.7578e-06 - accuracy: 1.0000\n",
      " 71/156 [============>.................] - ETA: 1:15 - loss: 6.8500e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 72/156 [============>.................] - ETA: 1:14 - loss: 6.8156e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 73/156 [=============>................] - ETA: 1:13 - loss: 6.7914e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 74/156 [=============>................] - ETA: 1:12 - loss: 6.8019e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 75/156 [=============>................] - ETA: 1:11 - loss: 6.7326e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 76/156 [=============>................] - ETA: 1:10 - loss: 6.7166e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 77/156 [=============>................] - ETA: 1:09 - loss: 6.6578e-06 - accuracy: 1.0000\n",
      " 78/156 [==============>...............] - ETA: 1:08 - loss: 6.6834e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 79/156 [==============>...............] - ETA: 1:07 - loss: 6.6251e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 80/156 [==============>...............] - ETA: 1:06 - loss: 6.8475e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 81/156 [==============>...............] - ETA: 1:06 - loss: 6.8074e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 82/156 [==============>...............] - ETA: 1:05 - loss: 6.7657e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 83/156 [==============>...............] - ETA: 1:04 - loss: 6.8787e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 84/156 [===============>..............] - ETA: 1:03 - loss: 6.8492e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 85/156 [===============>..............] - ETA: 1:03 - loss: 6.8966e-06 - accuracy: 1.0000\n",
      " 86/156 [===============>..............] - ETA: 1:02 - loss: 6.8646e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 87/156 [===============>..............] - ETA: 1:01 - loss: 6.8091e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 88/156 [===============>..............] - ETA: 1:00 - loss: 6.7980e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 89/156 [================>.............] - ETA: 59s - loss: 6.7704e-06 - accuracy: 1.0000 \u001b[0m\n",
      "\u001b[34m 90/156 [================>.............] - ETA: 58s - loss: 6.7907e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 91/156 [================>.............] - ETA: 57s - loss: 6.7368e-06 - accuracy: 1.0000\n",
      " 92/156 [================>.............] - ETA: 56s - loss: 6.7060e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 93/156 [================>.............] - ETA: 56s - loss: 6.6497e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 94/156 [=================>............] - ETA: 55s - loss: 6.6284e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 95/156 [=================>............] - ETA: 54s - loss: 6.5887e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 96/156 [=================>............] - ETA: 53s - loss: 6.5743e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 97/156 [=================>............] - ETA: 52s - loss: 6.5244e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 98/156 [=================>............] - ETA: 51s - loss: 6.4963e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 99/156 [==================>...........] - ETA: 50s - loss: 6.5242e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m100/156 [==================>...........] - ETA: 49s - loss: 6.4773e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m101/156 [==================>...........] - ETA: 48s - loss: 6.5006e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m102/156 [==================>...........] - ETA: 47s - loss: 6.4835e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m103/156 [==================>...........] - ETA: 47s - loss: 6.4399e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m104/156 [===================>..........] - ETA: 46s - loss: 6.4378e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m105/156 [===================>..........] - ETA: 45s - loss: 6.4262e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m106/156 [===================>..........] - ETA: 44s - loss: 6.4453e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m107/156 [===================>..........] - ETA: 43s - loss: 6.4099e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m108/156 [===================>..........] - ETA: 42s - loss: 6.3793e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m109/156 [===================>..........] - ETA: 41s - loss: 6.3843e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m110/156 [====================>.........] - ETA: 40s - loss: 6.3760e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m111/156 [====================>.........] - ETA: 39s - loss: 6.3428e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m112/156 [====================>.........] - ETA: 38s - loss: 6.2981e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m113/156 [====================>.........] - ETA: 38s - loss: 6.2536e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m114/156 [====================>.........] - ETA: 37s - loss: 6.2351e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m115/156 [=====================>........] - ETA: 36s - loss: 6.2100e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m116/156 [=====================>........] - ETA: 35s - loss: 6.1678e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m117/156 [=====================>........] - ETA: 34s - loss: 6.1457e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m118/156 [=====================>........] - ETA: 33s - loss: 6.1268e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m119/156 [=====================>........] - ETA: 32s - loss: 6.0841e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m120/156 [======================>.......] - ETA: 31s - loss: 6.1118e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m121/156 [======================>.......] - ETA: 31s - loss: 6.1113e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m122/156 [======================>.......] - ETA: 30s - loss: 6.1052e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m123/156 [======================>.......] - ETA: 29s - loss: 6.1047e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m124/156 [======================>.......] - ETA: 28s - loss: 6.1000e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m125/156 [=======================>......] - ETA: 27s - loss: 6.0773e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m126/156 [=======================>......] - ETA: 26s - loss: 6.0603e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m127/156 [=======================>......] - ETA: 25s - loss: 6.0538e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m128/156 [=======================>......] - ETA: 24s - loss: 6.0356e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m129/156 [=======================>......] - ETA: 23s - loss: 6.0074e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m130/156 [========================>.....] - ETA: 23s - loss: 5.9742e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m131/156 [========================>.....] - ETA: 22s - loss: 5.9474e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m132/156 [========================>.....] - ETA: 21s - loss: 5.9208e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m133/156 [========================>.....] - ETA: 20s - loss: 5.9027e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m134/156 [========================>.....] - ETA: 19s - loss: 5.8757e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m135/156 [========================>.....] - ETA: 18s - loss: 5.8508e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m136/156 [=========================>....] - ETA: 17s - loss: 5.9534e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m137/156 [=========================>....] - ETA: 16s - loss: 5.9264e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m138/156 [=========================>....] - ETA: 15s - loss: 5.9563e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m139/156 [=========================>....] - ETA: 15s - loss: 5.9372e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m140/156 [=========================>....] - ETA: 14s - loss: 5.9074e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m141/156 [==========================>...] - ETA: 13s - loss: 5.9048e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m142/156 [==========================>...] - ETA: 12s - loss: 5.8837e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m143/156 [==========================>...] - ETA: 11s - loss: 5.8586e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m144/156 [==========================>...] - ETA: 10s - loss: 5.8456e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m145/156 [==========================>...] - ETA: 9s - loss: 5.8214e-06 - accuracy: 1.0000 \u001b[0m\n",
      "\u001b[34m146/156 [===========================>..] - ETA: 8s - loss: 5.8080e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m147/156 [===========================>..] - ETA: 7s - loss: 5.7799e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m148/156 [===========================>..] - ETA: 7s - loss: 5.7691e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m149/156 [===========================>..] - ETA: 6s - loss: 5.7401e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m150/156 [===========================>..] - ETA: 5s - loss: 5.7126e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m151/156 [============================>.] - ETA: 4s - loss: 5.6924e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m152/156 [============================>.] - ETA: 3s - loss: 5.6674e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m153/156 [============================>.] - ETA: 2s - loss: 5.6603e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m154/156 [============================>.] - ETA: 1s - loss: 6.1890e-06 - accuracy: 1.0000\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m155/156 [============================>.] - ETA: 0s - loss: 6.1676e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m156/156 [==============================] - 155s 993ms/step - loss: 6.1500e-06 - accuracy: 1.0000 - val_loss: 0.0516 - val_accuracy: 20.2688\u001b[0m\n",
      "\u001b[34mEpoch 9/10\u001b[0m\n",
      "\u001b[34m  1/156 [..............................] - ETA: 2:18 - loss: 6.4401e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m  2/156 [..............................] - ETA: 2:09 - loss: 5.2160e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m  3/156 [..............................] - ETA: 2:11 - loss: 5.1886e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m  4/156 [..............................] - ETA: 2:11 - loss: 4.7952e-06 - accuracy: 1.0000\n",
      "  5/156 [..............................] - ETA: 2:10 - loss: 4.1685e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m  6/156 [>.............................] - ETA: 2:09 - loss: 3.7234e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m  7/156 [>.............................] - ETA: 2:10 - loss: 3.4059e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m  8/156 [>.............................] - ETA: 2:11 - loss: 5.3979e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m  9/156 [>.............................] - ETA: 2:11 - loss: 5.0239e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 10/156 [>.............................] - ETA: 2:11 - loss: 5.3181e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 11/156 [=>............................] - ETA: 2:10 - loss: 5.6370e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 12/156 [=>............................] - ETA: 2:10 - loss: 5.3584e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 13/156 [=>............................] - ETA: 2:08 - loss: 5.7269e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 14/156 [=>............................] - ETA: 2:07 - loss: 5.5344e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 15/156 [=>............................] - ETA: 2:06 - loss: 5.2911e-06 - accuracy: 1.0000\n",
      " 16/156 [==>...........................] - ETA: 2:05 - loss: 5.2357e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 17/156 [==>...........................] - ETA: 2:04 - loss: 5.6442e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 18/156 [==>...........................] - ETA: 2:03 - loss: 5.5127e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 19/156 [==>...........................] - ETA: 2:01 - loss: 5.4564e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 20/156 [==>...........................] - ETA: 2:00 - loss: 5.2264e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 21/156 [===>..........................] - ETA: 1:59 - loss: 5.0802e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 22/156 [===>..........................] - ETA: 1:59 - loss: 5.1097e-06 - accuracy: 1.0000\n",
      " 23/156 [===>..........................] - ETA: 1:58 - loss: 4.9739e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 24/156 [===>..........................] - ETA: 1:57 - loss: 5.0643e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 25/156 [===>..........................] - ETA: 1:55 - loss: 5.0388e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 26/156 [====>.........................] - ETA: 1:54 - loss: 5.4243e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 27/156 [====>.........................] - ETA: 1:53 - loss: 5.3936e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 28/156 [====>.........................] - ETA: 1:53 - loss: 5.4588e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 29/156 [====>.........................] - ETA: 1:51 - loss: 5.4189e-06 - accuracy: 1.0000\n",
      " 30/156 [====>.........................] - ETA: 1:50 - loss: 5.4709e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 31/156 [====>.........................] - ETA: 1:49 - loss: 5.3949e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 32/156 [=====>........................] - ETA: 1:48 - loss: 5.4302e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 33/156 [=====>........................] - ETA: 1:47 - loss: 5.4288e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 34/156 [=====>........................] - ETA: 1:47 - loss: 5.4646e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 35/156 [=====>........................] - ETA: 1:46 - loss: 5.3652e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 36/156 [=====>........................] - ETA: 1:45 - loss: 5.2935e-06 - accuracy: 1.0000\n",
      " 37/156 [======>.......................] - ETA: 1:44 - loss: 5.3363e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 38/156 [======>.......................] - ETA: 1:43 - loss: 5.3198e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 39/156 [======>.......................] - ETA: 1:42 - loss: 5.2416e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 40/156 [======>.......................] - ETA: 1:41 - loss: 5.1633e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 41/156 [======>.......................] - ETA: 1:40 - loss: 5.1299e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 42/156 [=======>......................] - ETA: 1:40 - loss: 5.1509e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 43/156 [=======>......................] - ETA: 1:40 - loss: 5.1599e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 44/156 [=======>......................] - ETA: 1:39 - loss: 5.1188e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 45/156 [=======>......................] - ETA: 1:39 - loss: 5.1904e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 46/156 [=======>......................] - ETA: 1:39 - loss: 5.1473e-06 - accuracy: 1.0000\n",
      " 47/156 [========>.....................] - ETA: 1:38 - loss: 5.1149e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 48/156 [========>.....................] - ETA: 1:37 - loss: 5.1319e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 49/156 [========>.....................] - ETA: 1:36 - loss: 5.1096e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 50/156 [========>.....................] - ETA: 1:35 - loss: 5.1050e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 51/156 [========>.....................] - ETA: 1:34 - loss: 5.1075e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 52/156 [=========>....................] - ETA: 1:33 - loss: 5.1162e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 53/156 [=========>....................] - ETA: 1:32 - loss: 5.1684e-06 - accuracy: 1.0000\n",
      " 54/156 [=========>....................] - ETA: 1:31 - loss: 5.1138e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 55/156 [=========>....................] - ETA: 1:30 - loss: 5.0509e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 56/156 [=========>....................] - ETA: 1:29 - loss: 5.0149e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 57/156 [=========>....................] - ETA: 1:28 - loss: 4.9557e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 58/156 [==========>...................] - ETA: 1:27 - loss: 4.9236e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 59/156 [==========>...................] - ETA: 1:27 - loss: 4.8682e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 60/156 [==========>...................] - ETA: 1:26 - loss: 4.8198e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 61/156 [==========>...................] - ETA: 1:25 - loss: 4.7825e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 62/156 [==========>...................] - ETA: 1:24 - loss: 4.7383e-06 - accuracy: 1.0000\n",
      " 63/156 [===========>..................] - ETA: 1:23 - loss: 4.7324e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 64/156 [===========>..................] - ETA: 1:22 - loss: 4.6835e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 65/156 [===========>..................] - ETA: 1:21 - loss: 4.7162e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 66/156 [===========>..................] - ETA: 1:20 - loss: 4.7179e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 67/156 [===========>..................] - ETA: 1:19 - loss: 4.6686e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 68/156 [============>.................] - ETA: 1:18 - loss: 4.6250e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 69/156 [============>.................] - ETA: 1:17 - loss: 4.5894e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 70/156 [============>.................] - ETA: 1:16 - loss: 4.6414e-06 - accuracy: 1.0000\n",
      " 71/156 [============>.................] - ETA: 1:16 - loss: 4.6226e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 72/156 [============>.................] - ETA: 1:15 - loss: 4.5863e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 73/156 [=============>................] - ETA: 1:14 - loss: 4.6759e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 74/156 [=============>................] - ETA: 1:13 - loss: 4.6476e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 75/156 [=============>................] - ETA: 1:12 - loss: 4.5952e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 76/156 [=============>................] - ETA: 1:11 - loss: 4.5738e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 77/156 [=============>................] - ETA: 1:10 - loss: 4.6033e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 78/156 [==============>...............] - ETA: 1:10 - loss: 4.5649e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 79/156 [==============>...............] - ETA: 1:09 - loss: 4.5822e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 80/156 [==============>...............] - ETA: 1:08 - loss: 4.5752e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 81/156 [==============>...............] - ETA: 1:07 - loss: 4.5535e-06 - accuracy: 1.0000\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m 82/156 [==============>...............] - ETA: 1:06 - loss: 4.5175e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 83/156 [==============>...............] - ETA: 1:05 - loss: 4.5199e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 84/156 [===============>..............] - ETA: 1:05 - loss: 4.8139e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 85/156 [===============>..............] - ETA: 1:04 - loss: 4.7761e-06 - accuracy: 1.0000\n",
      " 86/156 [===============>..............] - ETA: 1:03 - loss: 4.7388e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 87/156 [===============>..............] - ETA: 1:02 - loss: 4.7759e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 88/156 [===============>..............] - ETA: 1:01 - loss: 4.8859e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 89/156 [================>.............] - ETA: 1:00 - loss: 4.8781e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 90/156 [================>.............] - ETA: 59s - loss: 4.8485e-06 - accuracy: 1.0000 \u001b[0m\n",
      "\u001b[34m 91/156 [================>.............] - ETA: 58s - loss: 4.8356e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 92/156 [================>.............] - ETA: 57s - loss: 4.9013e-06 - accuracy: 1.0000\n",
      " 93/156 [================>.............] - ETA: 56s - loss: 4.9522e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 94/156 [=================>............] - ETA: 55s - loss: 4.9208e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 95/156 [=================>............] - ETA: 54s - loss: 5.0071e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 96/156 [=================>............] - ETA: 53s - loss: 4.9956e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 97/156 [=================>............] - ETA: 53s - loss: 5.0343e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 98/156 [=================>............] - ETA: 52s - loss: 5.0292e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 99/156 [==================>...........] - ETA: 51s - loss: 5.0228e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m100/156 [==================>...........] - ETA: 50s - loss: 4.9982e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m101/156 [==================>...........] - ETA: 49s - loss: 4.9837e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m102/156 [==================>...........] - ETA: 48s - loss: 5.0812e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m103/156 [==================>...........] - ETA: 47s - loss: 5.0501e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m104/156 [===================>..........] - ETA: 46s - loss: 5.0291e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m105/156 [===================>..........] - ETA: 45s - loss: 5.0352e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m106/156 [===================>..........] - ETA: 44s - loss: 5.0128e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m107/156 [===================>..........] - ETA: 44s - loss: 5.0132e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m108/156 [===================>..........] - ETA: 43s - loss: 5.0259e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m109/156 [===================>..........] - ETA: 42s - loss: 4.9950e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m110/156 [====================>.........] - ETA: 41s - loss: 4.9705e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m111/156 [====================>.........] - ETA: 40s - loss: 5.0150e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m112/156 [====================>.........] - ETA: 39s - loss: 5.0438e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m113/156 [====================>.........] - ETA: 38s - loss: 5.0322e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m114/156 [====================>.........] - ETA: 38s - loss: 5.0378e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m115/156 [=====================>........] - ETA: 37s - loss: 5.0868e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m116/156 [=====================>........] - ETA: 36s - loss: 5.0533e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m117/156 [=====================>........] - ETA: 35s - loss: 5.0900e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m118/156 [=====================>........] - ETA: 34s - loss: 5.1085e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m119/156 [=====================>........] - ETA: 33s - loss: 5.0865e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m120/156 [======================>.......] - ETA: 32s - loss: 5.0760e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m121/156 [======================>.......] - ETA: 31s - loss: 5.0517e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m122/156 [======================>.......] - ETA: 30s - loss: 5.0238e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m123/156 [======================>.......] - ETA: 29s - loss: 4.9999e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m124/156 [======================>.......] - ETA: 28s - loss: 4.9701e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m125/156 [=======================>......] - ETA: 28s - loss: 4.9578e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m126/156 [=======================>......] - ETA: 27s - loss: 4.9319e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m127/156 [=======================>......] - ETA: 26s - loss: 4.9310e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m128/156 [=======================>......] - ETA: 25s - loss: 4.9196e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m129/156 [=======================>......] - ETA: 24s - loss: 4.9009e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m130/156 [========================>.....] - ETA: 23s - loss: 4.8732e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m131/156 [========================>.....] - ETA: 22s - loss: 4.8654e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m132/156 [========================>.....] - ETA: 21s - loss: 4.8437e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m133/156 [========================>.....] - ETA: 20s - loss: 4.8227e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m134/156 [========================>.....] - ETA: 19s - loss: 4.8112e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m135/156 [========================>.....] - ETA: 18s - loss: 4.7992e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m136/156 [=========================>....] - ETA: 18s - loss: 4.8045e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m137/156 [=========================>....] - ETA: 17s - loss: 4.7938e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m138/156 [=========================>....] - ETA: 16s - loss: 4.7752e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m139/156 [=========================>....] - ETA: 15s - loss: 4.7480e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m140/156 [=========================>....] - ETA: 14s - loss: 4.7314e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m141/156 [==========================>...] - ETA: 13s - loss: 4.7177e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m142/156 [==========================>...] - ETA: 12s - loss: 4.7151e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m143/156 [==========================>...] - ETA: 11s - loss: 4.7159e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m144/156 [==========================>...] - ETA: 10s - loss: 4.7353e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m145/156 [==========================>...] - ETA: 9s - loss: 4.7426e-06 - accuracy: 1.0000 \u001b[0m\n",
      "\u001b[34m146/156 [===========================>..] - ETA: 9s - loss: 4.7510e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m147/156 [===========================>..] - ETA: 8s - loss: 4.7927e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m148/156 [===========================>..] - ETA: 7s - loss: 4.7824e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m149/156 [===========================>..] - ETA: 6s - loss: 4.7778e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m150/156 [===========================>..] - ETA: 5s - loss: 4.7896e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m151/156 [============================>.] - ETA: 4s - loss: 4.9489e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m152/156 [============================>.] - ETA: 3s - loss: 4.9636e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m153/156 [============================>.] - ETA: 2s - loss: 4.9697e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m154/156 [============================>.] - ETA: 1s - loss: 4.9803e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m155/156 [============================>.] - ETA: 0s - loss: 4.9775e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m156/156 [==============================] - 156s 998ms/step - loss: 4.9719e-06 - accuracy: 1.0000 - val_loss: 0.0557 - val_accuracy: 20.4596\u001b[0m\n",
      "\u001b[34mEpoch 10/10\u001b[0m\n",
      "\u001b[34m  1/156 [..............................] - ETA: 3:01 - loss: 9.9417e-07 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m  2/156 [..............................] - ETA: 2:56 - loss: 3.3364e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m  3/156 [..............................] - ETA: 2:55 - loss: 3.1953e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m  4/156 [..............................] - ETA: 3:01 - loss: 6.6475e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m  5/156 [..............................] - ETA: 2:56 - loss: 5.8611e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m  6/156 [>.............................] - ETA: 2:48 - loss: 5.1896e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m  7/156 [>.............................] - ETA: 2:41 - loss: 5.1435e-06 - accuracy: 1.0000\n",
      "  8/156 [>.............................] - ETA: 2:35 - loss: 5.1534e-06 - accuracy: 1.0000\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m  9/156 [>.............................] - ETA: 2:31 - loss: 4.8423e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 10/156 [>.............................] - ETA: 2:28 - loss: 4.7611e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 11/156 [=>............................] - ETA: 2:26 - loss: 4.5861e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 12/156 [=>............................] - ETA: 2:23 - loss: 4.7834e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 13/156 [=>............................] - ETA: 2:20 - loss: 4.6655e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 14/156 [=>............................] - ETA: 2:18 - loss: 4.6520e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 15/156 [=>............................] - ETA: 2:16 - loss: 4.4332e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 16/156 [==>...........................] - ETA: 2:15 - loss: 4.8048e-06 - accuracy: 1.0000\n",
      " 17/156 [==>...........................] - ETA: 2:13 - loss: 4.7013e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 18/156 [==>...........................] - ETA: 2:11 - loss: 4.5055e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 19/156 [==>...........................] - ETA: 2:10 - loss: 4.5253e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 20/156 [==>...........................] - ETA: 2:09 - loss: 4.7152e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 21/156 [===>..........................] - ETA: 2:07 - loss: 4.8123e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 22/156 [===>..........................] - ETA: 2:06 - loss: 4.6747e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 23/156 [===>..........................] - ETA: 2:05 - loss: 4.5856e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 24/156 [===>..........................] - ETA: 2:03 - loss: 4.4637e-06 - accuracy: 1.0000\n",
      " 25/156 [===>..........................] - ETA: 2:02 - loss: 4.3570e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 26/156 [====>.........................] - ETA: 2:01 - loss: 4.3970e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 27/156 [====>.........................] - ETA: 2:00 - loss: 4.3290e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 28/156 [====>.........................] - ETA: 1:58 - loss: 4.3913e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 29/156 [====>.........................] - ETA: 1:57 - loss: 4.5235e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 30/156 [====>.........................] - ETA: 1:56 - loss: 4.4710e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 31/156 [====>.........................] - ETA: 1:55 - loss: 4.5669e-06 - accuracy: 1.0000\n",
      " 32/156 [=====>........................] - ETA: 1:54 - loss: 4.4705e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 33/156 [=====>........................] - ETA: 1:52 - loss: 4.5174e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 34/156 [=====>........................] - ETA: 1:51 - loss: 4.4428e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 35/156 [=====>........................] - ETA: 1:50 - loss: 4.3695e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 36/156 [=====>........................] - ETA: 1:49 - loss: 4.3186e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 37/156 [======>.......................] - ETA: 1:48 - loss: 4.2532e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 38/156 [======>.......................] - ETA: 1:47 - loss: 4.2208e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 39/156 [======>.......................] - ETA: 1:46 - loss: 4.1678e-06 - accuracy: 1.0000\n",
      " 40/156 [======>.......................] - ETA: 1:45 - loss: 4.1574e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 41/156 [======>.......................] - ETA: 1:44 - loss: 4.1102e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 42/156 [=======>......................] - ETA: 1:43 - loss: 4.0544e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 43/156 [=======>......................] - ETA: 1:42 - loss: 4.1917e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 44/156 [=======>......................] - ETA: 1:41 - loss: 4.1259e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 45/156 [=======>......................] - ETA: 1:40 - loss: 4.1959e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 46/156 [=======>......................] - ETA: 1:39 - loss: 4.1409e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 47/156 [========>.....................] - ETA: 1:38 - loss: 4.1109e-06 - accuracy: 1.0000\n",
      " 48/156 [========>.....................] - ETA: 1:37 - loss: 4.1117e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 49/156 [========>.....................] - ETA: 1:36 - loss: 4.6012e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 50/156 [========>.....................] - ETA: 1:35 - loss: 4.5975e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 51/156 [========>.....................] - ETA: 1:34 - loss: 4.5419e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 52/156 [=========>....................] - ETA: 1:33 - loss: 4.5383e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 53/156 [=========>....................] - ETA: 1:32 - loss: 4.5645e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 54/156 [=========>....................] - ETA: 1:31 - loss: 4.5562e-06 - accuracy: 1.0000\n",
      " 55/156 [=========>....................] - ETA: 1:30 - loss: 4.5129e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 56/156 [=========>....................] - ETA: 1:29 - loss: 4.4512e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 57/156 [=========>....................] - ETA: 1:28 - loss: 4.4245e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 58/156 [==========>...................] - ETA: 1:27 - loss: 4.4096e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 59/156 [==========>...................] - ETA: 1:26 - loss: 4.3914e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 60/156 [==========>...................] - ETA: 1:26 - loss: 4.4023e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 61/156 [==========>...................] - ETA: 1:25 - loss: 4.5034e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 62/156 [==========>...................] - ETA: 1:24 - loss: 4.8957e-06 - accuracy: 1.0000\n",
      " 63/156 [===========>..................] - ETA: 1:23 - loss: 4.9056e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 64/156 [===========>..................] - ETA: 1:22 - loss: 4.8621e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 65/156 [===========>..................] - ETA: 1:21 - loss: 4.8144e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 66/156 [===========>..................] - ETA: 1:20 - loss: 4.9509e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 67/156 [===========>..................] - ETA: 1:19 - loss: 4.9137e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 68/156 [============>.................] - ETA: 1:18 - loss: 4.8656e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 69/156 [============>.................] - ETA: 1:18 - loss: 4.8263e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 70/156 [============>.................] - ETA: 1:17 - loss: 4.8109e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 71/156 [============>.................] - ETA: 1:16 - loss: 4.7720e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 72/156 [============>.................] - ETA: 1:15 - loss: 4.7321e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 73/156 [=============>................] - ETA: 1:15 - loss: 4.7780e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 74/156 [=============>................] - ETA: 1:14 - loss: 4.7791e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 75/156 [=============>................] - ETA: 1:13 - loss: 4.7660e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 76/156 [=============>................] - ETA: 1:12 - loss: 4.7392e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 77/156 [=============>................] - ETA: 1:11 - loss: 4.7512e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 78/156 [==============>...............] - ETA: 1:10 - loss: 4.7408e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 79/156 [==============>...............] - ETA: 1:09 - loss: 4.6961e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 80/156 [==============>...............] - ETA: 1:09 - loss: 4.6705e-06 - accuracy: 1.0000\n",
      " 81/156 [==============>...............] - ETA: 1:08 - loss: 4.9089e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 82/156 [==============>...............] - ETA: 1:07 - loss: 4.8978e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 83/156 [==============>...............] - ETA: 1:06 - loss: 4.8592e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 84/156 [===============>..............] - ETA: 1:05 - loss: 4.8215e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 85/156 [===============>..............] - ETA: 1:04 - loss: 4.8177e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 86/156 [===============>..............] - ETA: 1:03 - loss: 4.8243e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 87/156 [===============>..............] - ETA: 1:02 - loss: 4.8080e-06 - accuracy: 1.0000\n",
      " 88/156 [===============>..............] - ETA: 1:01 - loss: 4.7745e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 89/156 [================>.............] - ETA: 1:00 - loss: 4.7390e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 90/156 [================>.............] - ETA: 59s - loss: 4.6995e-06 - accuracy: 1.0000 \u001b[0m\n",
      "\u001b[34m 91/156 [================>.............] - ETA: 58s - loss: 4.6831e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 92/156 [================>.............] - ETA: 57s - loss: 4.6490e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 93/156 [================>.............] - ETA: 56s - loss: 4.6491e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 94/156 [=================>............] - ETA: 56s - loss: 4.6844e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 95/156 [=================>............] - ETA: 55s - loss: 4.6481e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 96/156 [=================>............] - ETA: 54s - loss: 4.7690e-06 - accuracy: 1.0000\n",
      " 97/156 [=================>............] - ETA: 53s - loss: 4.7613e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 98/156 [=================>............] - ETA: 52s - loss: 4.7415e-06 - accuracy: 1.0000\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m 99/156 [==================>...........] - ETA: 51s - loss: 4.7155e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m100/156 [==================>...........] - ETA: 50s - loss: 4.7934e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m101/156 [==================>...........] - ETA: 49s - loss: 4.7785e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m102/156 [==================>...........] - ETA: 48s - loss: 4.7679e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m103/156 [==================>...........] - ETA: 47s - loss: 4.7537e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m104/156 [===================>..........] - ETA: 46s - loss: 4.7235e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m105/156 [===================>..........] - ETA: 45s - loss: 4.7320e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m106/156 [===================>..........] - ETA: 45s - loss: 4.7477e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m107/156 [===================>..........] - ETA: 44s - loss: 4.7141e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m108/156 [===================>..........] - ETA: 43s - loss: 4.7137e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m109/156 [===================>..........] - ETA: 42s - loss: 4.6841e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m110/156 [====================>.........] - ETA: 41s - loss: 4.6632e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m111/156 [====================>.........] - ETA: 40s - loss: 4.6729e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m112/156 [====================>.........] - ETA: 39s - loss: 4.6700e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m113/156 [====================>.........] - ETA: 38s - loss: 4.6715e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m114/156 [====================>.........] - ETA: 37s - loss: 4.6636e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m115/156 [=====================>........] - ETA: 36s - loss: 4.6623e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m116/156 [=====================>........] - ETA: 36s - loss: 4.6616e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m117/156 [=====================>........] - ETA: 35s - loss: 4.6407e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m118/156 [=====================>........] - ETA: 34s - loss: 4.6075e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m119/156 [=====================>........] - ETA: 33s - loss: 4.6485e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m120/156 [======================>.......] - ETA: 32s - loss: 4.6262e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m121/156 [======================>.......] - ETA: 31s - loss: 5.0869e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m122/156 [======================>.......] - ETA: 30s - loss: 5.1076e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m123/156 [======================>.......] - ETA: 29s - loss: 5.0783e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m124/156 [======================>.......] - ETA: 28s - loss: 5.0497e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m125/156 [=======================>......] - ETA: 27s - loss: 5.0237e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m126/156 [=======================>......] - ETA: 26s - loss: 5.0151e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m127/156 [=======================>......] - ETA: 26s - loss: 4.9915e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m128/156 [=======================>......] - ETA: 25s - loss: 4.9654e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m129/156 [=======================>......] - ETA: 24s - loss: 4.9378e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m130/156 [========================>.....] - ETA: 23s - loss: 4.9118e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m131/156 [========================>.....] - ETA: 22s - loss: 4.9002e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m132/156 [========================>.....] - ETA: 21s - loss: 4.8785e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m133/156 [========================>.....] - ETA: 20s - loss: 4.8942e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m134/156 [========================>.....] - ETA: 19s - loss: 4.9083e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m135/156 [========================>.....] - ETA: 18s - loss: 4.8807e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m136/156 [=========================>....] - ETA: 17s - loss: 4.8532e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m137/156 [=========================>....] - ETA: 17s - loss: 4.8812e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m138/156 [=========================>....] - ETA: 16s - loss: 4.9019e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m139/156 [=========================>....] - ETA: 15s - loss: 4.9094e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m140/156 [=========================>....] - ETA: 14s - loss: 4.8797e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m141/156 [==========================>...] - ETA: 13s - loss: 4.8559e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m142/156 [==========================>...] - ETA: 12s - loss: 4.8354e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m143/156 [==========================>...] - ETA: 11s - loss: 4.8513e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m144/156 [==========================>...] - ETA: 10s - loss: 4.8265e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m145/156 [==========================>...] - ETA: 9s - loss: 4.8094e-06 - accuracy: 1.0000 \u001b[0m\n",
      "\u001b[34m146/156 [===========================>..] - ETA: 9s - loss: 4.8023e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m147/156 [===========================>..] - ETA: 8s - loss: 4.7809e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m148/156 [===========================>..] - ETA: 7s - loss: 4.7613e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m149/156 [===========================>..] - ETA: 6s - loss: 4.7392e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m150/156 [===========================>..] - ETA: 5s - loss: 4.7220e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m151/156 [============================>.] - ETA: 4s - loss: 4.7478e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m152/156 [============================>.] - ETA: 3s - loss: 4.7507e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m153/156 [============================>.] - ETA: 2s - loss: 4.7303e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m154/156 [============================>.] - ETA: 1s - loss: 4.7266e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m155/156 [============================>.] - ETA: 0s - loss: 4.7097e-06 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m156/156 [==============================] - 156s 1s/step - loss: 4.7050e-06 - accuracy: 1.0000 - val_loss: 0.0565 - val_accuracy: 21.1690\u001b[0m\n",
      "\u001b[34mINFO:root:Test loss:0.35842132568359375\u001b[0m\n",
      "\u001b[34mINFO:root:Test accuracy:0.0\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:From cifar10_keras_main.py:189: The name tf.saved_model.signature_def_utils.predict_signature_def is deprecated. Please use tf.compat.v1.saved_model.signature_def_utils.predict_signature_def instead.\n",
      "\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:From cifar10_keras_main.py:189: The name tf.saved_model.signature_def_utils.predict_signature_def is deprecated. Please use tf.compat.v1.saved_model.signature_def_utils.predict_signature_def instead.\n",
      "\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/saved_model/signature_def_utils_impl.py:201: build_tensor_info (from tensorflow.python.saved_model.utils_impl) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34mInstructions for updating:\u001b[0m\n",
      "\u001b[34mThis function will only be available through the v1 compatibility library as tf.compat.v1.saved_model.utils.build_tensor_info or tf.compat.v1.saved_model.build_tensor_info.\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/saved_model/signature_def_utils_impl.py:201: build_tensor_info (from tensorflow.python.saved_model.utils_impl) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34mInstructions for updating:\u001b[0m\n",
      "\u001b[34mThis function will only be available through the v1 compatibility library as tf.compat.v1.saved_model.utils.build_tensor_info or tf.compat.v1.saved_model.build_tensor_info.\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:From cifar10_keras_main.py:193: The name tf.saved_model.builder.SavedModelBuilder is deprecated. Please use tf.compat.v1.saved_model.builder.SavedModelBuilder instead.\n",
      "\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:From cifar10_keras_main.py:193: The name tf.saved_model.builder.SavedModelBuilder is deprecated. Please use tf.compat.v1.saved_model.builder.SavedModelBuilder instead.\n",
      "\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:From cifar10_keras_main.py:196: The name tf.saved_model.tag_constants.SERVING is deprecated. Please use tf.saved_model.SERVING instead.\n",
      "\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:From cifar10_keras_main.py:196: The name tf.saved_model.tag_constants.SERVING is deprecated. Please use tf.saved_model.SERVING instead.\n",
      "\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:From cifar10_keras_main.py:198: The name tf.saved_model.signature_constants.DEFAULT_SERVING_SIGNATURE_DEF_KEY is deprecated. Please use tf.saved_model.DEFAULT_SERVING_SIGNATURE_DEF_KEY instead.\n",
      "\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:From cifar10_keras_main.py:198: The name tf.saved_model.signature_constants.DEFAULT_SERVING_SIGNATURE_DEF_KEY is deprecated. Please use tf.saved_model.DEFAULT_SERVING_SIGNATURE_DEF_KEY instead.\n",
      "\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:No assets to save.\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:No assets to save.\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:No assets to write.\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:No assets to write.\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:SavedModel written to: /opt/ml/model/1/saved_model.pb\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:SavedModel written to: /opt/ml/model/1/saved_model.pb\u001b[0m\n",
      "\u001b[34mINFO:root:Model successfully saved at: /opt/ml/model\u001b[0m\n",
      "\u001b[34m2021-05-14 11:06:59,931 sagemaker-containers INFO     Reporting training SUCCESS\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2021-05-14 11:07:15 Uploading - Uploading generated training model\n",
      "2021-05-14 11:07:15 Completed - Training job completed\n",
      "Training seconds: 1653\n",
      "Billable seconds: 1653\n"
     ]
    }
   ],
   "source": [
    "inputs = {\n",
    "    'train': '{}/train'.format(dataset_uri),\n",
    "    'validation': '{}/validation'.format(dataset_uri),\n",
    "    'eval': '{}/eval'.format(dataset_uri),\n",
    "}\n",
    "\n",
    "estimator.fit(inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### View the job training metrics\n",
    "\n",
    "We can now view the metrics from the training job directly in the SageMaker console.  \n",
    "\n",
    "Log into the [SageMaker console](https://console.aws.amazon.com/sagemaker/home), choose the latest training job, and scroll down to the monitor section. Alternatively, the code below uses the region and training job name to generate a URL to CloudWatch metrics.\n",
    "\n",
    "Using CloudWatch metrics, you can change the period and configure the statistics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "CloudWatch metrics: [link](https://ap-southeast-2.console.aws.amazon.com/cloudwatch/home?region=ap-southeast-2#metricsV2:namespace=/aws/sagemaker/TrainingJobs;dimensions=TrainingJobName;search=cifar10-tf-2021-05-14-10-37-03-005). After you choose a metric, change the period to 1 Minute (Graphed Metrics -> Period)."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from urllib import parse\n",
    "\n",
    "from IPython.core.display import Markdown\n",
    "\n",
    "region = sagemaker_session.boto_region_name\n",
    "cw_url = parse.urlunparse((\n",
    "    'https',\n",
    "    '{}.console.aws.amazon.com'.format(region),\n",
    "    '/cloudwatch/home',\n",
    "    '',\n",
    "    'region={}'.format(region),\n",
    "    'metricsV2:namespace=/aws/sagemaker/TrainingJobs;dimensions=TrainingJobName;search={}'.format(estimator.latest_training_job.name),\n",
    "))\n",
    "\n",
    "display(Markdown('CloudWatch metrics: [link]({}). After you choose a metric, '\n",
    "                 'change the period to 1 Minute (Graphed Metrics -> Period).'.format(cw_url)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deploy the trained model\n",
    "\n",
    "After we train our model, we can deploy it to a SageMaker Endpoint, which serves prediction requests in real-time. To do so, we simply call `deploy()` on our estimator, passing in the desired number of instances and instance type for the endpoint.\n",
    "\n",
    "Because we're using TensorFlow Serving for deployment, our training script saves the model in TensorFlow's SavedModel format. For more details, see [this blog post on deploying Keras and TF models in SageMaker](https://aws.amazon.com/blogs/machine-learning/deploy-trained-keras-or-tensorflow-models-using-amazon-sagemaker)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "update_endpoint is a no-op in sagemaker>=2.\n",
      "See: https://sagemaker.readthedocs.io/en/stable/v2.html for details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------!"
     ]
    }
   ],
   "source": [
    "predictor = estimator.deploy(initial_instance_count=1, instance_type='ml.m4.xlarge')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Invoke the endpoint\n",
    "\n",
    "To verify the that the endpoint is in service, we generate some random data in the correct shape and get a prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted class: 1\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "data = np.random.randn(1, 32, 32, 3)\n",
    "print('Predicted class: {}'.format(np.argmax(predictor.predict(data)['predictions'])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's use the test dataset for predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/ec2-user/anaconda3/envs/tensorflow_p36/cpu/lib/python3.6/site-packages/tensorflow_core/__init__.py:1473: The name tf.estimator.inputs is deprecated. Please use tf.compat.v1.estimator.inputs instead.\n",
      "\n",
      "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
      "170500096/170498071 [==============================] - 24s 0us/step\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import cifar10\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the data loaded, we can use it for predictions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "def predict(data):\n",
    "    predictions = predictor.predict(data)['predictions']\n",
    "    return predictions\n",
    "\n",
    "\n",
    "predicted = []\n",
    "actual = []\n",
    "batches = 0\n",
    "batch_size = 128\n",
    "\n",
    "datagen = ImageDataGenerator()\n",
    "for data in datagen.flow(x_test, y_test, batch_size=batch_size):\n",
    "    for i, prediction in enumerate(predict(data[0])):\n",
    "        predicted.append(np.argmax(prediction))\n",
    "        actual.append(data[1][i][0])\n",
    "\n",
    "    batches += 1\n",
    "    if batches >= len(x_test) / batch_size:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the predictions, we calculate our model accuracy and create a confusion matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Average accuracy: 13.7%'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "accuracy = accuracy_score(y_pred=predicted, y_true=actual)\n",
    "display('Average accuracy: {}%'.format(round(accuracy * 100, 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7fae2f8dd940>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 842.4x595.44 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sn\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "cm = confusion_matrix(y_pred=predicted, y_true=actual)\n",
    "cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "sn.set(rc={'figure.figsize': (11.7,8.27)})\n",
    "sn.set(font_scale=1.4)  # for label size\n",
    "sn.heatmap(cm, annot=True, annot_kws={\"size\": 10})  # font size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aided by the colors of the heatmap, we can use this confusion matrix to understand how well the model performed for each label."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleanup\n",
    "\n",
    "To avoid incurring extra charges to your AWS account, let's delete the endpoint we created:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor.delete_endpoint()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_tensorflow_p36",
   "language": "python",
   "name": "conda_tensorflow_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  },
  "notice": "Copyright 2017-2020 Amazon.com, Inc. or its affiliates. All Rights Reserved. Licensed under the Apache License, Version 2.0 (the \"License\"). You may not use this file except in compliance with the License. A copy of the License is located at http://aws.amazon.com/apache2.0/ or in the \"license\" file accompanying this file. This file is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License.",
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
