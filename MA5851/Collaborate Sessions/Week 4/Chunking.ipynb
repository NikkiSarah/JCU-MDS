{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[('Tens', 'NNS'), ('of', 'IN'), ('thousands', 'NNS'), ('of', 'IN'), ('people', 'NNS'), ('are', 'VBP'), ('still', 'RB'), ('expected', 'VBN'), ('to', 'TO'), ('descend', 'VB'), ('on', 'IN'), ('Byron', 'NNP'), ('Bay', 'NNP'), ('this', 'DT'), ('weekend', 'NN'), (',', ','), ('just', 'RB'), ('days', 'NNS'), ('after', 'IN'), ('a', 'DT'), ('COVID-positive', 'JJ'), ('bachelorette', 'NN'), ('party', 'NN'), ('triggered', 'VBD'), ('alerts', 'NNS'), ('for', 'IN'), ('a', 'DT'), ('number', 'NN'), ('of', 'IN'), ('popular', 'JJ'), ('venues', 'NNS'), ('.', '.')], [('Contact', 'NNP'), ('tracing', 'VBG'), ('efforts', 'NNS'), ('have', 'VBP'), ('expanded', 'VBN'), ('wider', 'NN'), ('across', 'NN'), ('SEQ', 'NNP'), ('as', 'IN'), ('authorities', 'NNS'), ('locked-down', 'VBP'), ('the', 'DT'), ('Princess', 'NNP'), ('Alexandra', 'NNP'), ('Hospital', 'NNP'), ('and', 'CC'), ('hinted', 'VBD'), ('at', 'IN'), ('extended', 'VBN'), ('stay-at-home', 'JJ'), ('orders', 'NNS'), ('.', '.')]]\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import sent_tokenize\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk import pos_tag\n",
    "from nltk import RegexpParser\n",
    "from nltk import ne_chunk\n",
    "\n",
    "\n",
    "def text_preprocess(document):\n",
    "    sentences = sent_tokenize(document)\n",
    "    sentences = [word_tokenize(sent) for sent in sentences]\n",
    "    sentences = [pos_tag(sent) for sent in sentences]\n",
    "    return(sentences)\n",
    "\n",
    "\n",
    "input_text = \"\"\"\n",
    "Tens of thousands of people are still expected to descend on Byron Bay this weekend, just days after a COVID-positive bachelorette party triggered alerts for a number of popular venues.\n",
    "Contact tracing efforts have expanded wider across SEQ as authorities locked-down the Princess Alexandra Hospital and hinted at extended stay-at-home orders.\n",
    "\"\"\"\n",
    "print(text_preprocess(input_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S\n",
      "  (NP Chunk Tens/NNS of/IN thousands/NNS of/IN people/NNS)\n",
      "  are/VBP\n",
      "  still/RB\n",
      "  expected/VBN\n",
      "  to/TO\n",
      "  descend/VB\n",
      "  (NP Chunk on/IN Byron/NNP Bay/NNP)\n",
      "  (NP Chunk this/DT weekend/NN)\n",
      "  ,/,\n",
      "  just/RB\n",
      "  (NP Chunk days/NNS after/IN)\n",
      "  (NP Chunk a/DT COVID-positive/JJ bachelorette/NN party/NN)\n",
      "  triggered/VBD\n",
      "  (NP Chunk alerts/NNS for/IN)\n",
      "  (NP Chunk a/DT number/NN of/IN popular/JJ venues/NNS)\n",
      "  ./.)\n",
      "(NP Chunk Tens/NNS of/IN thousands/NNS of/IN people/NNS)\n",
      "(NP Chunk on/IN Byron/NNP Bay/NNP)\n",
      "(NP Chunk this/DT weekend/NN)\n",
      "(NP Chunk days/NNS after/IN)\n",
      "(NP Chunk a/DT COVID-positive/JJ bachelorette/NN party/NN)\n",
      "(NP Chunk alerts/NNS for/IN)\n",
      "(NP Chunk a/DT number/NN of/IN popular/JJ venues/NNS)\n",
      "(S\n",
      "  (NP Chunk Contact/NNP)\n",
      "  tracing/VBG\n",
      "  (NP Chunk efforts/NNS)\n",
      "  have/VBP\n",
      "  expanded/VBN\n",
      "  (NP Chunk wider/NN across/NN SEQ/NNP as/IN authorities/NNS)\n",
      "  locked-down/VBP\n",
      "  (NP Chunk the/DT Princess/NNP Alexandra/NNP Hospital/NNP)\n",
      "  and/CC\n",
      "  hinted/VBD\n",
      "  (NP Chunk at/IN)\n",
      "  extended/VBN\n",
      "  (NP Chunk stay-at-home/JJ orders/NNS)\n",
      "  ./.)\n",
      "(NP Chunk Contact/NNP)\n",
      "(NP Chunk efforts/NNS)\n",
      "(NP Chunk wider/NN across/NN SEQ/NNP as/IN authorities/NNS)\n",
      "(NP Chunk the/DT Princess/NNP Alexandra/NNP Hospital/NNP)\n",
      "(NP Chunk at/IN)\n",
      "(NP Chunk stay-at-home/JJ orders/NNS)\n"
     ]
    }
   ],
   "source": [
    "grammar = \"NP Chunk: {<DT>?(<NN.?>*<IN>*)*<JJ>*<NN.?>*}\"\n",
    "cp = RegexpParser(grammar)\n",
    "output_text = text_preprocess(input_text)\n",
    "for tagged_text in output_text:\n",
    "    result = cp.parse(tagged_text)\n",
    "    print(result)\n",
    "    #result.draw()\n",
    "    for subtree in result.subtrees():\n",
    "        if subtree.label() == 'NP Chunk': print(subtree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S\n",
      "  (NP Tens/NNS)\n",
      "  of/IN\n",
      "  (NP thousands/NNS)\n",
      "  of/IN\n",
      "  (NP people/NNS)\n",
      "  are/VBP\n",
      "  (NP still/RB)\n",
      "  expected/VBN\n",
      "  (NP to/TO)\n",
      "  descend/VB\n",
      "  on/IN\n",
      "  (NP Byron/NNP Bay/NNP this/DT weekend/NN ,/, just/RB days/NNS)\n",
      "  after/IN\n",
      "  (NP a/DT COVID-positive/JJ bachelorette/NN party/NN)\n",
      "  triggered/VBD\n",
      "  (NP alerts/NNS)\n",
      "  for/IN\n",
      "  (NP a/DT number/NN)\n",
      "  of/IN\n",
      "  (NP popular/JJ venues/NNS ./.))\n",
      "(S\n",
      "  (NP Contact/NNP)\n",
      "  tracing/VBG\n",
      "  (NP efforts/NNS)\n",
      "  have/VBP\n",
      "  expanded/VBN\n",
      "  (NP wider/NN across/NN SEQ/NNP)\n",
      "  as/IN\n",
      "  (NP authorities/NNS)\n",
      "  locked-down/VBP\n",
      "  (NP the/DT Princess/NNP Alexandra/NNP Hospital/NNP and/CC)\n",
      "  hinted/VBD\n",
      "  at/IN\n",
      "  extended/VBN\n",
      "  (NP stay-at-home/JJ orders/NNS ./.))\n"
     ]
    }
   ],
   "source": [
    "grammar = r\"\"\"\n",
    "  NP:\n",
    "    {<.*>+}          # Chunk everything\n",
    "    }<VB.?|IN>+{      # Chink sequences of VBD and IN\n",
    "  \"\"\"\n",
    "cp = RegexpParser(grammar)\n",
    "for tagged_text in output_text:\n",
    "    result = cp.parse(tagged_text)\n",
    "    print(result)\n",
    "    #result.draw()\n",
    "    for subtree in result.subtrees():\n",
    "        if subtree.label() == 'NP Chunk': print(subtree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(NE Byron/NNP Bay/NNP)\n",
      "(NE Contact/NNP)\n",
      "(NE Princess/NNP Alexandra/NNP Hospital/NNP)\n"
     ]
    }
   ],
   "source": [
    "for tagged_text in output_text:\n",
    "    result = ne_chunk(tagged_text, binary=True)\n",
    "    for subtree in result.subtrees():\n",
    "        if subtree.label() == 'NE': print(subtree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ORG: 'WHYY'] 'in' [LOC: 'Philadelphia']\n",
      "[ORG: 'McGlashan &AMP; Sarrail'] 'firm in' [LOC: 'San Mateo']\n",
      "[ORG: 'Freedom Forum'] 'in' [LOC: 'Arlington']\n",
      "[ORG: 'Brookings Institution'] ', the research group in' [LOC: 'Washington']\n",
      "[ORG: 'Idealab'] ', a self-described business incubator based in' [LOC: 'Los Angeles']\n",
      "[ORG: 'Open Text'] ', based in' [LOC: 'Waterloo']\n",
      "[ORG: 'WGBH'] 'in' [LOC: 'Boston']\n",
      "[ORG: 'Bastille Opera'] 'in' [LOC: 'Paris']\n",
      "[ORG: 'Omnicom'] 'in' [LOC: 'New York']\n",
      "[ORG: 'DDB Needham'] 'in' [LOC: 'New York']\n",
      "[ORG: 'Kaplan Thaler Group'] 'in' [LOC: 'New York']\n",
      "[ORG: 'BBDO South'] 'in' [LOC: 'Atlanta']\n",
      "[ORG: 'Georgia-Pacific'] 'in' [LOC: 'Atlanta']\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "from nltk.corpus import ieer\n",
    "from nltk.sem import extract_rels, rtuple \n",
    "\n",
    "IN = re.compile(r'.*\\bin\\b(?!\\b.+ing)')\n",
    "for doc in ieer.parsed_docs('NYT_19980315'):\n",
    "    for rel in extract_rels('ORG', 'LOC', doc, corpus='ieer', pattern = IN):\n",
    "        print(rtuple(rel))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pythonD",
   "language": "python",
   "name": "pythond"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
