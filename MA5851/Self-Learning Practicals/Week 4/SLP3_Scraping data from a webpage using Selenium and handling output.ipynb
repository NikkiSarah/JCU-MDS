{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "student_name = \"Nikki Fitzherbert\"\n",
    "student_id = \"13848336\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "import pandas as pd\n",
    "\n",
    "# create a new instance of Firefox\n",
    "driver = webdriver.Firefox()\n",
    "\n",
    "# access Firefox and open Edmunds.com\n",
    "driver.get(\"https://forums.edmunds.com/discussion/2864/general/x/entry-level-luxury-performance-sedans/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Steps 2-4\n",
    "Create the scaffold of the class and basic methods, and complete the 'run' and 'extract_data' methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CarForumCrawler(): \n",
    "    def __init__(self, start_link):\n",
    "        self.link_to_explore = start_link \n",
    "        self.comments = pd.DataFrame(columns = ['Date','user_id','comments'])\n",
    "        self.driver = webdriver.Firefox()            \n",
    "        self.pagecount = 1\n",
    "        self.next = True\n",
    "                \n",
    "    def run(self):\n",
    "        while self.next:\n",
    "            if self.pagecount >=5:\n",
    "                self.save_data_to_file()\n",
    "                self.next = False\n",
    "            try:\n",
    "                self.driver.get(self.link_to_explore+\"p\"+str(self.pagecount))\n",
    "                self.driver.implicitly_wait(15)\n",
    "                self.extract_data()      \n",
    "                self.pagecount = self.pagecount + 1\n",
    "            except:\n",
    "                print (\"Cannot get the page \" + self.link_to_explore)\n",
    "                self.next = False\n",
    "                raise\n",
    "                \n",
    "    def extract_data(self):\n",
    "        ids = self.driver.find_elements_by_xpath(\"//*[contains(@id,'Comment_')]\")\n",
    "        comment_ids = []\n",
    "        \n",
    "        for i in ids:\n",
    "            comment_ids.append(i.get_attribute('id'))\n",
    "        \n",
    "        for x in comment_ids:\n",
    "            #Extract dates from for each user on a page\n",
    "            user_date = self.driver.find_elements_by_xpath('//*[@id=\"' + x +'\"]/div/div[2]/div[2]/span[1]/a/time')[0]\n",
    "            date = user_date.get_attribute('title')\n",
    "\n",
    "            #Extract user ids from each user on a page\n",
    "            userid_element = self.driver.find_elements_by_xpath('//*[@id=\"' + x +'\"]/div/div[2]/div[1]/span[1]/a[2]')[0]\n",
    "            userid = userid_element.text\n",
    "\n",
    "            #Extract Message for each user on a page\n",
    "            user_message = self.driver.find_elements_by_xpath('//*[@id=\"' + x +'\"]/div/div[3]/div/div[1]')[0]\n",
    "            comment = user_message.text\n",
    "                               \n",
    "            #Adding date, userid and comment for each user in a dataframe    \n",
    "            self.comments.loc[len(self.comments)] = [date,userid,comment]  \n",
    "            \n",
    "    def save_data_to_file(self):\n",
    "    #we save the dataframe content to a CSV file\n",
    "        self.comments.to_csv ('comments.csv', index = None, header=True)\n",
    "    def close_spider(self):\n",
    "    #end the session\n",
    "        self.driver.quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 5\n",
    "Run the crawler."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    url = 'https://forums.edmunds.com/discussion/2864/general/x/entry-level-luxury-performance-sedans/'        \n",
    "    try:\n",
    "        mycrawler = CarForumCrawler(url)\n",
    "        mycrawler.run()\n",
    "        mycrawler.close_spider()\n",
    "    except:\n",
    "        raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pythonD",
   "language": "python",
   "name": "pythond"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
