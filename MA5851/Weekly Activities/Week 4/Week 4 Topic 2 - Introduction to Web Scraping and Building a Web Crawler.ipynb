{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Week 4 Topic 2: Introduction to Web Scraping and Building a Web Crawler\n",
    "\n",
    "##### Building a web spider with scrapy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Steps 1 & 2**\n",
    "Use the scrapy shell within the command line interface (CLI) or anaconda prompt to test assumptions on a site's behaviour, and what components a web page returns and how to use them for your own requirements.\n",
    "\n",
    "scrapy shell"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The *fetch* command initiates a web crawler or spider that will go through a webpage and download its text and metadata.\n",
    "\n",
    "fetch(\"https://rebrickable.com/sets/2019/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The *view* command allows the user to view the response and the relevant web page is opened in a web browser. Use *print* to view the raw HTML language.\n",
    "\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 3**\n",
    "Either CSS selector or Xpath can be used to extract the HTML. If CSS selectors are used, text can be extracted via the element attributes or the css selector like classes. For example, the following code extracts product names:\n",
    "\n",
    "response.css(\"h1 ::text\").extract()\n",
    "\n",
    "XPath is a query language for selecting nodes in an XML document, allowing the user to navigate through a XML document. Underneath, scrapy uses Xpath to navigate to HTML document items. The CSS selectors are also converted to XPath, but in many cases CSS is very easy to use.\n",
    "\n",
    "The following code shows you all the code under the <html> tag:\n",
    "    \n",
    "response.xpath('/html').extract()\n",
    "\n",
    "'/' means *direct child of the node* so if you wanted to get the <div> tags under the <html> tag, you would write:\n",
    "\n",
    "response.xpath('/html//div').extract()\n",
    "\n",
    "In order to use XPath, you will need to understand the use of '/' and '//' to know how to navigate through child and descendent nodes. https://www.w3schools.com/xml/xpath_intro.asp is the start of a useful tutorial.\n",
    "\n",
    "The following code shows how you'd get all the <div> tags under the <html> tag:\n",
    "\n",
    "response.xpath('/html//div').extract()\n",
    "\n",
    "You can filter nodes you start with to reach desired nodes using attributes and their values. For example, the syntax to use classes and their values is demonstrated below:\n",
    "\n",
    "response.xpath(\"//div[@class='quote']/span[@class='text']\".extract()\n",
    "response.xpath(\"//div[@class='quote']/span[@class='text']/text()\").extract()\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
